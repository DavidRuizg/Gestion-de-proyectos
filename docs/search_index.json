[["index.html", "Data Analysis in Software Engineering using R Welcome", " Data Analysis in Software Engineering using R Daniel Rodriguez and Javier Dolado 2022-08-04 Welcome This Data Analysis in Software Engineering (DASE) book/notes will try teach you how to do data science with R in Software Engineering. It is a work in progress. Acknowledgments Projects: PRESI: TIN2013-46928-C3 amuSE TIN2013-46928-C3-2-R PERTEST TIN2013-46928-C3-1-R QARE: TIN2016-76956-C3 BadgePeople: TIN2016-76956-C3-3-R TESTEAMOS: TIN2016-76956-C3-1-R Network SBSE (SEBASENet): TIN2015-71841-REDT TestBUS PID2019-105455GB-C32 This work is licensed under the Creative Commons Attribution-NonCommtercial-NoDerivs 3.0 United States License. "],["r-intro.html", "Chapter 1 Introduction to R 1.1 Installation 1.2 R and RStudio 1.3 Basic Data Types 1.4 Vectors 1.5 Arrays and Matrices 1.6 Factors 1.7 Lists", " Chapter 1 Introduction to R The goal of the first part of this book is to get you up to speed with the basics of R as quickly as possible. 1.1 Installation Install the latest preview version for getting all features. Follow the procedures according to your operating system. Linux: You need to have blas and gfortran installed on your Linux, for installing the coin package. Rgraphviz requires installation from source(\"http://bioconductor.org/biocLite.R\"), then biocLite(\"Rgraphviz\"). Run the following lines for installing all needed packages (this may take some time): ## listofpackages &lt;- c(&quot;arules&quot;,&quot;arulesViz&quot;, &quot;bookdown&quot;, &quot;ggplot2&quot;, &quot;vioplot&quot;, &quot;UsingR&quot;, &quot;fpc&quot;, &quot;reshape&quot;, &quot;party&quot;, &quot;C50&quot;, &quot;utils&quot;, &quot;rpart&quot;, &quot;rpart.plot&quot;, &quot;class&quot;, &quot;klaR&quot;, &quot;e1071&quot;, &quot;popbio&quot;, &quot;boot&quot;, &quot;dplyr&quot;, &quot;doParallel&quot;, &quot;gbm&quot;, &quot;DMwR&quot;, &quot;pROC&quot;, &quot;neuralnet&quot;, &quot;igraph&quot;, &quot;RMySQL&quot;, &quot;caret&quot;, &quot;randomForest&quot;, &quot;tm&quot;, &quot;wordcloud&quot;, &quot;xts&quot;, &quot;lubridate&quot;, &quot;forecast&quot;, &quot;urca&quot;, &quot;glmnet&quot;, &quot;FSelector&quot;, &quot;pls&quot;, &quot;emoa&quot;, &quot;foreign&quot; ) # newpackages &lt;- listofpackages[!(listofpackages %in% installed.packages()[,&quot;Package&quot;])] # if(length(newpackages)&gt;0) install.packages(newpackages,dependencies = TRUE) # # install from archive (RPG is no maintained anymore) # if (!is.element(&quot;rgp&quot;, installed.packages()[,1])) # { install.packages(&quot;https://cran.r-project.org/src/contrib/Archive/rgp/rgp_0.4-1.tar.gz&quot;, # repos = NULL) # } ## end of installing packages # in Linux you may need to run several commands (in the terminal) and install additional libraries, e.g. # sudo R CMD javareconf # sudo apt-get install build-essential # sudo apt-get install libxml2-dev # sudo apt-get install libpq # sudo apt-get install libpq-dev # sudo apt-get install -y libmariadb-client-lgpl-dev # sudo apt-get install texlive-xetex # sudo apt-get install r-cran-rmysql 1.2 R and RStudio R is a programming language for statistical computing and data analysis that supports a variety of programming styles. See R in Wikipedia R has multiple online resources and books. R coding style R-Bloggers Getting help in R RStudio cheat sheet Base R cheat sheet Advanced R cheat sheet Data Visualization cheat sheet R Markdown cheatsheet [R Markdown Basics] (http://rmarkdown.rstudio.com/authoring_basics.html) Python with R and Reticulate Cheatsheet caret All cheatsheets and translations help(\" \") command R as a calculator. Console: It uses the command-line interface. This document is an RMarkdown document. See bookdown.org Examples: x &lt;- c(1,2,3,4,5,6) # Create ordered collection (vector) y &lt;- x^2 # Square the elements of x print(y) # print (vector) y ## [1] 1 4 9 16 25 36 mean(y) # Calculate average (arithmetic mean) of (vector) y; result is scalar ## [1] 15.16667 var(y) # Calculate sample variance ## [1] 178.9667 lm_1 &lt;- lm(y ~ x) # Fit a linear regression model &quot;y = f(x)&quot; or &quot;y = B0 + (B1 * x)&quot; # store the results as lm_1 print(lm_1) # Print the model from the (linear model object) lm_1 ## ## Call: ## lm(formula = y ~ x) ## ## Coefficients: ## (Intercept) x ## -9.333 7.000 summary(lm_1) # Compute and print statistics for the fit ## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## 1 2 3 4 5 6 ## 3.3333 -0.6667 -2.6667 -2.6667 -0.6667 3.3333 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -9.3333 2.8441 -3.282 0.030453 * ## x 7.0000 0.7303 9.585 0.000662 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.055 on 4 degrees of freedom ## Multiple R-squared: 0.9583, Adjusted R-squared: 0.9478 ## F-statistic: 91.88 on 1 and 4 DF, p-value: 0.000662 # of the (linear model object) lm_1 par(mfrow=c(2, 2)) # Request 2x2 plot layout plot(lm_1) # Diagnostic plot of regression model help(lm) ?lm apropos(&quot;lm&quot;) ## [1] &quot;.colMeans&quot; &quot;.lm.fit&quot; &quot;colMeans&quot; &quot;confint.lm&quot; ## [5] &quot;contr.helmert&quot; &quot;dummy.coef.lm&quot; &quot;glm&quot; &quot;glm.control&quot; ## [9] &quot;glm.fit&quot; &quot;KalmanForecast&quot; &quot;KalmanLike&quot; &quot;KalmanRun&quot; ## [13] &quot;KalmanSmooth&quot; &quot;kappa.lm&quot; &quot;lm&quot; &quot;lm_1&quot; ## [17] &quot;lm.fit&quot; &quot;lm.influence&quot; &quot;lm.wfit&quot; &quot;model.matrix.lm&quot; ## [21] &quot;nlm&quot; &quot;nlminb&quot; &quot;predict.glm&quot; &quot;predict.lm&quot; ## [25] &quot;residuals.glm&quot; &quot;residuals.lm&quot; &quot;summary.glm&quot; &quot;summary.lm&quot; example(lm) ## ## lm&gt; require(graphics) ## ## lm&gt; ## Annette Dobson (1990) &quot;An Introduction to Generalized Linear Models&quot;. ## lm&gt; ## Page 9: Plant Weight Data. ## lm&gt; ctl &lt;- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14) ## ## lm&gt; trt &lt;- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69) ## ## lm&gt; group &lt;- gl(2, 10, 20, labels = c(&quot;Ctl&quot;,&quot;Trt&quot;)) ## ## lm&gt; weight &lt;- c(ctl, trt) ## ## lm&gt; lm.D9 &lt;- lm(weight ~ group) ## ## lm&gt; lm.D90 &lt;- lm(weight ~ group - 1) # omitting intercept ## ## lm&gt; ## No test: ## lm&gt; ##D anova(lm.D9) ## lm&gt; ##D summary(lm.D90) ## lm&gt; ## End(No test) ## lm&gt; opar &lt;- par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0)) ## ## lm&gt; plot(lm.D9, las = 1) # Residuals, Fitted, ... ## ## lm&gt; par(opar) ## ## lm&gt; ## Don&#39;t show: ## lm&gt; ## model frame : ## lm&gt; stopifnot(identical(lm(weight ~ group, method = &quot;model.frame&quot;), ## lm+ model.frame(lm.D9))) ## ## lm&gt; ## End(Don&#39;t show) ## lm&gt; ### less simple examples in &quot;See Also&quot; above ## lm&gt; ## lm&gt; ## lm&gt; R script. # A file with R commands # comments source(\"filewithcommands.R\") sink(\"recordmycommands.lis\") savehistory() From command line: Rscript Rscript file with -e (e.g. Rscript -e 2+2) To exit R: quit() Variables. R is case sensitive var1 &lt;- 1:10 vAr1 &lt;- 11:20 var1 ## [1] 1 2 3 4 5 6 7 8 9 10 vAr1 ## [1] 11 12 13 14 15 16 17 18 19 20 Operators assign operator &lt;- sequence operator, for example: mynums &lt;- 0:20 arithmetic operators: + - = / ^ %/% (integer division) %% (modulus operator) The Workspace. Objects. ls() objects() ls.str() lists and describes the objects rm(x) delete a variable. E.g., rm(totalCost) s.str() objects() str() The structure function provides information about the variable RStudio, RCommander and RKWard are the well-known IDEs for R (more later). Four # (‘####’) create an environment in RStudio. An environment binds a set of names to a set of values. You can think of an environment as a bag of names. Environment basics Working directories: # set your working directory # setwd(&quot;~/workingDir/&quot;) getwd() ## [1] &quot;/home/drg/Projects/DASE&quot; # record R commands: # sink(&quot;recordmycommands.txt&quot;, append = TRUE) 1.3 Basic Data Types class( ) logical: TRUE, FALSE numeric, integer: is.numeric( ) is.integer( ) character Examples: TRUE ## [1] TRUE class(TRUE) ## [1] &quot;logical&quot; FALSE ## [1] FALSE NA # missing ## [1] NA class(NA) ## [1] &quot;logical&quot; T ## [1] TRUE F ## [1] FALSE NaN ## [1] NaN class(NaN) ## [1] &quot;numeric&quot; # numeric data type 2 ## [1] 2 class(2) ## [1] &quot;numeric&quot; 2.5 ## [1] 2.5 2L # integer ## [1] 2 class(2L) ## [1] &quot;integer&quot; is.numeric(2) ## [1] TRUE is.numeric(2L) ## [1] TRUE is.integer(2) ## [1] FALSE is.integer(2L) ## [1] TRUE is.numeric(NaN) ## [1] TRUE data type coercion: as.numeric( ) as.character( ) as.integer( ) Examples: truenum &lt;- as.numeric(TRUE) truenum ## [1] 1 class(truenum) ## [1] &quot;numeric&quot; falsenum &lt;- as.numeric(FALSE) falsenum ## [1] 0 num2char &lt;- as.character(55) num2char ## [1] &quot;55&quot; char2num &lt;- as.numeric(&quot;55.3&quot;) char2int &lt;- as.integer(&quot;55.3&quot;) 1.3.1 Mising values NA stands for Not Available, which is not a number as well. It applies to missing values. NaN means ‘Not a Number’ Examples: NA + 1 ## [1] NA mean(c(5,NA,7)) ## [1] NA mean(c(5,NA,7), na.rm=TRUE) # some functions allow to remove NAs ## [1] 6 1.4 Vectors Examples: phases &lt;- c(&quot;reqs&quot;, &quot;dev&quot;, &quot;test1&quot;, &quot;test2&quot;, &quot;maint&quot;) str(phases) ## chr [1:5] &quot;reqs&quot; &quot;dev&quot; &quot;test1&quot; &quot;test2&quot; &quot;maint&quot; is.vector(phases) ## [1] TRUE thevalues &lt;- c(15, 60, 30, 35, 22) names(thevalues) &lt;- phases str(thevalues) ## Named num [1:5] 15 60 30 35 22 ## - attr(*, &quot;names&quot;)= chr [1:5] &quot;reqs&quot; &quot;dev&quot; &quot;test1&quot; &quot;test2&quot; ... thevalues ## reqs dev test1 test2 maint ## 15 60 30 35 22 A single value is a vector! Example: aphase &lt;- 44 is.vector(aphase) ## [1] TRUE length(aphase) ## [1] 1 length(thevalues) ## [1] 5 1.4.1 Coercion for vectors thevalues1 &lt;- c(15, 60, &quot;30&quot;, 35, 22) class(thevalues1) ## [1] &quot;character&quot; thevalues1 ## [1] &quot;15&quot; &quot;60&quot; &quot;30&quot; &quot;35&quot; &quot;22&quot; # &lt;- is equivalent to assign ( ) assign(&quot;costs&quot;, c(50, 100, 30)) 1.4.2 Vector arithmetic The operation is carried out in all the elements of the vector. For example: assign(&quot;costs&quot;, c(50, 100, 30)) costs/3 ## [1] 16.66667 33.33333 10.00000 costs - 5 ## [1] 45 95 25 costs &lt;- costs - 5 incomes &lt;- c(200, 800, 10) earnings &lt;- incomes - costs sum(earnings) ## [1] 845 # R recycles values in vectors! vector1 &lt;- c(1,2,3) vector2 &lt;- c(10,11,12,13,14,15,16) vector1 + vector2 ## Warning in vector1 + vector2: longer object length is not a multiple of shorter ## object length ## [1] 11 13 15 14 16 18 17 Subsetting vectors ### Subsetting vectors [] phase1 &lt;- phases[1] phase1 ## [1] &quot;reqs&quot; phase3 &lt;- phases[3] phase3 ## [1] &quot;test1&quot; thevalues[phase1] ## reqs ## 15 thevalues[&quot;reqs&quot;] ## reqs ## 15 testphases &lt;- phases[c(3,4)] thevalues[testphases] ## test1 test2 ## 30 35 ### Negative indexes phases1 &lt;- phases[-5] phases ## [1] &quot;reqs&quot; &quot;dev&quot; &quot;test1&quot; &quot;test2&quot; &quot;maint&quot; phases1 ## [1] &quot;reqs&quot; &quot;dev&quot; &quot;test1&quot; &quot;test2&quot; #phases2 &lt;- phases[-testphases] ## error in argument phases2 &lt;- phases[-c(3,4)] phases2 ## [1] &quot;reqs&quot; &quot;dev&quot; &quot;maint&quot; ### subset using logical vector phases3 &lt;- phases[c(FALSE, TRUE, TRUE, FALSE)] #recicled first value phases3 ## [1] &quot;dev&quot; &quot;test1&quot; selectionv &lt;- c(FALSE, TRUE, TRUE, FALSE) phases3 &lt;- phases[selectionv] phases3 ## [1] &quot;dev&quot; &quot;test1&quot; selectionvec2 &lt;- c(TRUE, FALSE) thevalues2 &lt;- thevalues[selectionvec2] thevalues2 ## reqs test1 maint ## 15 30 22 ### Generating regular sequences with `:` and `seq` aseqofvalues &lt;- 1:20 aseqofvalues2 &lt;- seq(from=-3, to=3, by=0.5 ) aseqofvalues2 ## [1] -3.0 -2.5 -2.0 -1.5 -1.0 -0.5 0.0 0.5 1.0 1.5 2.0 2.5 3.0 aseqofvalues3 &lt;- seq(0, 100, by=10) aseqofvalues4 &lt;- aseqofvalues3[c(2, 4, 6, 8)] aseqofvalues4 ## [1] 10 30 50 70 aseqofvalues4 &lt;- aseqofvalues3[-c(2, 4, 6, 8)] aseqofvalues4 ## [1] 0 20 40 60 80 90 100 aseqofvalues3[c(1,2)] &lt;- c(666,888) aseqofvalues3 ## [1] 666 888 20 30 40 50 60 70 80 90 100 ### Logical values in vectors TRUE/FALSE aseqofvalues3 &gt; 50 ## [1] TRUE TRUE FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE aseqofvalues5 &lt;- aseqofvalues3[aseqofvalues3 &gt; 50] aseqofvalues5 ## [1] 666 888 60 70 80 90 100 aseqofvalues6 &lt;- aseqofvalues3[!(aseqofvalues3 &gt; 50)] aseqofvalues6 ## [1] 20 30 40 50 ### Comparison functions aseqofvalues7 &lt;- aseqofvalues3[aseqofvalues3 == 50] aseqofvalues7 ## [1] 50 aseqofvalues8 &lt;- aseqofvalues3[aseqofvalues3 == 22] aseqofvalues8 ## numeric(0) aseqofvalues9 &lt;- aseqofvalues3[aseqofvalues3 != 50] aseqofvalues9 ## [1] 666 888 20 30 40 60 70 80 90 100 logicalcond &lt;- aseqofvalues3 &gt;= 50 aseqofvalues10 &lt;- aseqofvalues3[logicalcond] aseqofvalues10 ## [1] 666 888 50 60 70 80 90 100 ### Remove Missing Values (NAs) aseqofvalues3[c(1,2)] &lt;- c(NA,NA) aseqofvalues3 ## [1] NA NA 20 30 40 50 60 70 80 90 100 aseqofvalues3 &lt;- aseqofvalues3[!is.na(aseqofvalues3)] aseqofvalues3 ## [1] 20 30 40 50 60 70 80 90 100 1.5 Arrays and Matrices Matrices are actually long vectors. mymat &lt;- matrix(1:12, nrow =2) mymat ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 1 3 5 7 9 11 ## [2,] 2 4 6 8 10 12 mymat &lt;- matrix(1:12, ncol =3) mymat ## [,1] [,2] [,3] ## [1,] 1 5 9 ## [2,] 2 6 10 ## [3,] 3 7 11 ## [4,] 4 8 12 mymat &lt;- matrix(1:12, nrow=2, byrow = TRUE) mymat ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 1 2 3 4 5 6 ## [2,] 7 8 9 10 11 12 mymat &lt;- matrix(1:12, nrow=3, ncol=4) mymat ## [,1] [,2] [,3] [,4] ## [1,] 1 4 7 10 ## [2,] 2 5 8 11 ## [3,] 3 6 9 12 mymat &lt;- matrix(1:12, nrow=3, ncol=4, byrow=TRUE) mymat ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 ## [2,] 5 6 7 8 ## [3,] 9 10 11 12 ### recycling mymat &lt;- matrix(1:5, nrow=3, ncol=4, byrow=TRUE) ## Warning in matrix(1:5, nrow = 3, ncol = 4, byrow = TRUE): data length [5] is not ## a sub-multiple or multiple of the number of rows [3] mymat ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 ## [2,] 5 1 2 3 ## [3,] 4 5 1 2 ### rbind cbind cbind(1:3, 1:3) ## [,1] [,2] ## [1,] 1 1 ## [2,] 2 2 ## [3,] 3 3 rbind(1:3, 1:3) ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 1 2 3 mymat &lt;- matrix(1) mymat &lt;- matrix(1:8, nrow=2, ncol=4, byrow=TRUE) mymat ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 ## [2,] 5 6 7 8 rbind(mymat, 9:12) ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 ## [2,] 5 6 7 8 ## [3,] 9 10 11 12 mymat &lt;- cbind(mymat, c(5,9)) mymat ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 2 3 4 5 ## [2,] 5 6 7 8 9 mymat &lt;- matrix(1:8, byrow = TRUE, nrow=2) mymat ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 ## [2,] 5 6 7 8 rownames(mymat) &lt;- c(&quot;row1&quot;, &quot;row2&quot;) mymat ## [,1] [,2] [,3] [,4] ## row1 1 2 3 4 ## row2 5 6 7 8 colnames(mymat) &lt;- c(&quot;col1&quot;, &quot;col2&quot;, &quot;col3&quot;, &quot;col4&quot;) mymat ## col1 col2 col3 col4 ## row1 1 2 3 4 ## row2 5 6 7 8 mymat2 &lt;- matrix(1:12, byrow=TRUE, nrow=3, dimnames=list(c(&quot;row1&quot;, &quot;row2&quot;, &quot;row3&quot;), c(&quot;col1&quot;, &quot;col2&quot;, &quot;col3&quot;, &quot;col4&quot;))) mymat2 ## col1 col2 col3 col4 ## row1 1 2 3 4 ## row2 5 6 7 8 ## row3 9 10 11 12 ### Coercion in Arrays matnum &lt;- matrix(1:8, ncol = 2) matnum ## [,1] [,2] ## [1,] 1 5 ## [2,] 2 6 ## [3,] 3 7 ## [4,] 4 8 matchar &lt;- matrix(LETTERS[1:6], nrow = 4, ncol = 3) matchar ## [,1] [,2] [,3] ## [1,] &quot;A&quot; &quot;E&quot; &quot;C&quot; ## [2,] &quot;B&quot; &quot;F&quot; &quot;D&quot; ## [3,] &quot;C&quot; &quot;A&quot; &quot;E&quot; ## [4,] &quot;D&quot; &quot;B&quot; &quot;F&quot; matchars &lt;- cbind(matnum, matchar) matchars ## [,1] [,2] [,3] [,4] [,5] ## [1,] &quot;1&quot; &quot;5&quot; &quot;A&quot; &quot;E&quot; &quot;C&quot; ## [2,] &quot;2&quot; &quot;6&quot; &quot;B&quot; &quot;F&quot; &quot;D&quot; ## [3,] &quot;3&quot; &quot;7&quot; &quot;C&quot; &quot;A&quot; &quot;E&quot; ## [4,] &quot;4&quot; &quot;8&quot; &quot;D&quot; &quot;B&quot; &quot;F&quot; ### Subsetting mymat3 &lt;- matrix(sample(-8:15, 12), nrow=3) #sample 12 numbers between -8 and 15 mymat3 ## [,1] [,2] [,3] [,4] ## [1,] 0 5 -3 -2 ## [2,] 2 7 3 13 ## [3,] -1 1 9 11 mymat3[2,3] ## [1] 3 mymat3[1,4] ## [1] -2 mymat3[3,] ## [1] -1 1 9 11 mymat3[,4] ## [1] -2 13 11 mymat3[5] # counts elements by column ## [1] 7 mymat3[9] ## [1] 9 ## Subsetting multiple elements mymat3[2, c(1,3)] ## [1] 2 3 mymat3[c(2,3), c(1,3,4)] ## [,1] [,2] [,3] ## [1,] 2 3 13 ## [2,] -1 9 11 rownames(mymat3) &lt;- c(&quot;r1&quot;, &quot;r2&quot;, &quot;r3&quot;) colnames(mymat3) &lt;- c(&quot;c1&quot;, &quot;c2&quot;, &quot;c3&quot;, &quot;c4&quot;) mymat3[&quot;r2&quot;, c(&quot;c1&quot;, &quot;c3&quot;)] ## c1 c3 ## 2 3 ### Subset by logical vector mymat3[c(FALSE, TRUE, FALSE), c(TRUE, FALSE, TRUE, FALSE)] ## c1 c3 ## 2 3 mymat3[c(FALSE, TRUE, TRUE), c(TRUE, FALSE, TRUE, TRUE)] ## c1 c3 c4 ## r2 2 3 13 ## r3 -1 9 11 ### matrix arithmetic row1 &lt;- c(220, 137) row2 &lt;- c(345, 987) row3 &lt;- c(111, 777) mymat4 &lt;- rbind(row1, row2, row3) rownames(mymat4) &lt;- c(&quot;row_1&quot;, &quot;row_2&quot;, &quot;row_3&quot;) colnames(mymat4) &lt;- c(&quot;col_1&quot;, &quot;col_2&quot;) mymat4 ## col_1 col_2 ## row_1 220 137 ## row_2 345 987 ## row_3 111 777 mymat4/10 ## col_1 col_2 ## row_1 22.0 13.7 ## row_2 34.5 98.7 ## row_3 11.1 77.7 mymat4 -100 ## col_1 col_2 ## row_1 120 37 ## row_2 245 887 ## row_3 11 677 mymat5 &lt;- rbind(c(50,50), c(10,10), c(100,100)) mymat5 ## [,1] [,2] ## [1,] 50 50 ## [2,] 10 10 ## [3,] 100 100 mymat4 - mymat5 ## col_1 col_2 ## row_1 170 87 ## row_2 335 977 ## row_3 11 677 mymat4 * (mymat5/100) ## col_1 col_2 ## row_1 110.0 68.5 ## row_2 34.5 98.7 ## row_3 111.0 777.0 ### index matrices m1 &lt;- array(1:20, dim=c(4,5)) m1 ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 5 9 13 17 ## [2,] 2 6 10 14 18 ## [3,] 3 7 11 15 19 ## [4,] 4 8 12 16 20 index &lt;- array(c(1:3, 3:1), dim=c(3,2)) index ## [,1] [,2] ## [1,] 1 3 ## [2,] 2 2 ## [3,] 3 1 #use the &quot;index matrix&quot; as the index for the other matrix m1[index] &lt;-0 m1 ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 5 0 13 17 ## [2,] 2 0 10 14 18 ## [3,] 0 7 11 15 19 ## [4,] 4 8 12 16 20 1.6 Factors Factors are variables in R which take on a limited number of different values; such variables are often referred to as ‘categorical variables’ and ‘enumerated type’. Factors in R are stored as a vector of integer values with a corresponding set of character values to use when the factor is displayed. The function factor is used to encode a vector as a factor personnel &lt;- c(&quot;Analyst1&quot;, &quot;ManagerL2&quot;, &quot;Analyst1&quot;, &quot;Analyst2&quot;, &quot;Boss&quot;, &quot;ManagerL1&quot;, &quot;ManagerL2&quot;, &quot;Programmer1&quot;, &quot;Programmer2&quot;, &quot;Programmer3&quot;, &quot;Designer1&quot;,&quot;Designer2&quot;, &quot;OtherStaff&quot;) # staff in a company personnel_factors &lt;- factor(personnel) personnel_factors #sorted alphabetically ## [1] Analyst1 ManagerL2 Analyst1 Analyst2 Boss ManagerL1 ## [7] ManagerL2 Programmer1 Programmer2 Programmer3 Designer1 Designer2 ## [13] OtherStaff ## 11 Levels: Analyst1 Analyst2 Boss Designer1 Designer2 ManagerL1 ... Programmer3 str(personnel_factors) ## Factor w/ 11 levels &quot;Analyst1&quot;,&quot;Analyst2&quot;,..: 1 7 1 2 3 6 7 9 10 11 ... personnel2 &lt;- factor(personnel, levels = c(&quot;Boss&quot;, &quot;ManagerL1&quot;, &quot;ManagerL2&quot;, &quot;Analyst1&quot;, &quot;Analyst2&quot;, &quot;Designer1&quot;, &quot;Designer2&quot;, &quot;Programmer1&quot;, &quot;Programmer2&quot;, &quot;Programmer3&quot;, &quot;OtherStaff&quot;)) #do not duplicate the same factors personnel2 ## [1] Analyst1 ManagerL2 Analyst1 Analyst2 Boss ManagerL1 ## [7] ManagerL2 Programmer1 Programmer2 Programmer3 Designer1 Designer2 ## [13] OtherStaff ## 11 Levels: Boss ManagerL1 ManagerL2 Analyst1 Analyst2 Designer1 ... OtherStaff str(personnel2) ## Factor w/ 11 levels &quot;Boss&quot;,&quot;ManagerL1&quot;,..: 4 3 4 5 1 2 3 8 9 10 ... # a factor&#39;s levels will always be character values. levels(personnel2) &lt;- c(&quot;B&quot;, &quot;M1&quot;, &quot;M2&quot;, &quot;A1&quot;, &quot;A2&quot;, &quot;D1&quot;, &quot;D2&quot;, &quot;P1&quot;, &quot;P2&quot;, &quot;P3&quot;, &quot;OS&quot;) personnel2 ## [1] A1 M2 A1 A2 B M1 M2 P1 P2 P3 D1 D2 OS ## Levels: B M1 M2 A1 A2 D1 D2 P1 P2 P3 OS personnel3 &lt;- factor(personnel, levels = c(&quot;Boss&quot;, &quot;ManagerL1&quot;, &quot;ManagerL2&quot;, &quot;Analyst1&quot;, &quot;Analyst2&quot;, &quot;Designer1&quot;, &quot;Designer2&quot;, &quot;Programmer1&quot;, &quot;Programmer2&quot;, &quot;Programmer3&quot;, &quot;OtherStaff&quot;), c(&quot;B&quot;, &quot;M1&quot;, &quot;M2&quot;, &quot;A1&quot;, &quot;A2&quot;, &quot;D1&quot;, &quot;D2&quot;, &quot;P1&quot;, &quot;P2&quot;, &quot;P3&quot;, &quot;OS&quot;)) personnel3 ## [1] A1 M2 A1 A2 B M1 M2 P1 P2 P3 D1 D2 OS ## Levels: B M1 M2 A1 A2 D1 D2 P1 P2 P3 OS ### Nominal versus ordinal, ordered factors personnel3[1] &lt; personnel3[2] # error, factors not ordered ## Warning in Ops.factor(personnel3[1], personnel3[2]): &#39;&lt;&#39; not meaningful for ## factors ## [1] NA tshirts &lt;- c(&quot;M&quot;, &quot;L&quot;, &quot;S&quot;, &quot;S&quot;, &quot;L&quot;, &quot;M&quot;, &quot;L&quot;, &quot;M&quot;) tshirt_factor &lt;- factor(tshirts, ordered = TRUE, levels = c(&quot;S&quot;, &quot;M&quot;, &quot;L&quot;)) tshirt_factor ## [1] M L S S L M L M ## Levels: S &lt; M &lt; L tshirt_factor[1] &lt; tshirt_factor[2] ## [1] TRUE 1.7 Lists Lists are the R objects which contain elements of different types: numbers, strings, vectors and other lists. A list can also contain a matrix or a function as one of their elements. A list is created using list() function. Operators for subsetting lists include: - ‘[’ returns a list - ’[[’ returns the list element - ‘$’ returns the content of that element in the list]&lt;-1 cbo &lt;- jdt\\(cbo bugs &lt;- jdt\\)bugs "],["split-data-into-training-and-test-datasets.html", "Chapter 2 Split data into training and test datasets 2.1 The caret package", " Chapter 2 Split data into training and test datasets jdt2 = data.frame(cbo, bugs) inTrain &lt;- createDataPartition(y=jdt2$bugs,p=.8,list=FALSE) jdtTrain &lt;- jdt2[inTrain,] jdtTest &lt;- jdt2[-inTrain,] BLR models fault-proneness are as follows $fp(X) = \\frac{e^{logit()}}{1 + e^{logit(X)}}$ where the simplest form for logit is $logit(X) = c_{0} + c_{1}X$ ```r # logit regression # glmLogit &lt;- train (bugs ~ ., data=jdt.train, method=&quot;glm&quot;, family=binomial(link = logit)) glmLogit &lt;- glm (bugs ~ ., data=jdtTrain, family=binomial(link = logit)) summary(glmLogit) ## ## Call: ## glm(formula = bugs ~ ., family = binomial(link = logit), data = jdtTrain) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -3.654 -0.591 -0.515 -0.471 2.150 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -2.20649 0.13900 -15.87 &lt;2e-16 *** ## cbo 0.06298 0.00765 8.23 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 807.98 on 797 degrees of freedom ## Residual deviance: 691.80 on 796 degrees of freedom ## AIC: 695.8 ## ## Number of Fisher Scoring iterations: 5 Predict a single point: newData = data.frame(cbo = 3) predict(glmLogit, newData, type = &quot;response&quot;) ## 1 ## 0.117 Draw the results, modified from: http://www.shizukalab.com/toolkits/plotting-logistic-regression-in-r results &lt;- predict(glmLogit, jdtTest, type = &quot;response&quot;) range(jdtTrain$cbo) ## [1] 0 156 range(results) ## [1] 0.0992 0.9993 plot(jdt2$cbo,jdt2$bugs) curve(predict(glmLogit, data.frame(cbo=x), type = &quot;response&quot;),add=TRUE) # points(jdtTrain$cbo,fitted(glmLogit)) Another type of graph: library(popbio) ## ## Attaching package: &#39;popbio&#39; ## The following object is masked from &#39;package:caret&#39;: ## ## sensitivity logi.hist.plot(jdt2$cbo,jdt2$bugs,boxp=FALSE,type=&quot;hist&quot;,col=&quot;gray&quot;) 2.1 The caret package There are hundreds of packages to perform classification task in R, but many of those can be used throught the ‘caret’ package which helps with many of the data mining process task as described next. The caret packagehttp://topepo.github.io/caret/ provides a unified interface for modeling and prediction with around 150 different models with tools for: data splitting pre-processing feature selection model tuning using resampling variable importance estimation, etc. Website: http://caret.r-forge.r-project.org JSS Paper: www.jstatsoft.org/v28/i05/paper Book: Applied Predictive Modeling "],["regression.html", "Chapter 3 Regression 3.1 Linear Regression modeling 3.2 Linear Regression Diagnostics 3.3 Multiple Linear Regression 3.4 Linear regression in Software Effort estimation 3.5 References", " Chapter 3 Regression 3.1 Linear Regression modeling Linear Regression is one of the oldest and most known predictive methods. As its name says, the idea is to try to fit a linear equation between a dependent variable and an independent, or explanatory, variable. The idea is that the independent variable \\(x\\) is something the experimenter controls and the dependent variable \\(y\\) is something that the experimenter measures. The line is used to predict the value of \\(y\\) for a known value of \\(x\\). The variable \\(x\\) is the predictor variable and \\(y\\) the response variable. Multiple linear regression uses 2 or more independent variables for building a model. See https://www.wikipedia.org/wiki/Linear_regression. First proposed many years ago but still very useful… Galton Data The equation takes the form \\(\\hat{y}=b_0+b_1 * x\\) The method used to choose the values \\(b_0\\) and \\(b_1\\) is to minimize the sum of the squares of the residual errors. 3.1.1 Regression: Galton Data Not related to Software Engineering but … library(UsingR) data(galton) par(mfrow=c(1,2)) hist(galton$child,col=&quot;blue&quot;,breaks=100) hist(galton$parent,col=&quot;blue&quot;,breaks=100) plot(galton$parent,galton$child,pch=1,col=&quot;blue&quot;, cex=0.4) lm1 &lt;- lm(galton$child ~ galton$parent) lines(galton$parent,lm1$fitted,col=&quot;red&quot;,lwd=3) plot(galton$parent,lm1$residuals,col=&quot;blue&quot;,pch=1, cex=0.4) abline(c(0,0),col=&quot;red&quot;,lwd=3) qqnorm(galton$child) 3.1.2 Simple Linear Regression Given two variables \\(Y\\) (response) and \\(X\\) (predictor), the assumption is that there is an approximate (\\(\\approx\\)) linear relation between those variables. The mathematical model of the observed data is described as (for the case of simple linear regression): \\[ Y \\approx \\beta_0 + \\beta_1 X\\] the parameter \\(\\beta_0\\) is named the intercept and \\(\\beta_1\\) is the slope Each observation can be modeled as \\[y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i; \\epsilon_i \\sim N(0,\\sigma^2)\\] - \\(\\epsilon_i\\) is the error - This means that the variable \\(y\\) is normally distributed: \\[ y_i \\sim N( \\beta_0 + \\beta_1 x_i, \\sigma^2) \\] The predictions or estimations of this model are obtained by a linear equation of the form \\(\\hat{Y}=\\hat{\\beta_0} + \\hat{\\beta}_1X\\), that is, each new prediction is computed with \\[\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1x_i \\]. The actual parameters \\(\\beta_0\\) and \\(\\beta_1\\) are unknown The parameters \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) of the linear equation can be estimated with different methods. 3.1.3 Least Squares One of the most used methods for computing \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) is the criterion of “least squares” minimization. The data is composed of \\(n\\) pairs of observations \\((x_i, y_i)\\) Given an observation \\(y_i\\) and its corresponding estimation \\(\\hat{y_i})\\) the residual \\(e_i\\) is defined as \\[e_i= y_i - \\hat{y_i}\\] the Residual Sum of Squares is defined as \\[RSS=e_1^2+\\dots + e_i^2+\\dots+e_n^2\\] the Least Squares Approach minimizes the RSS as result of that minimizitation, it can be obtained, by means of calculus, the estimation of \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) as \\[\\hat{\\beta}_1=\\frac{\\sum_{i=1}^{n}{(x_i-\\bar{x})(y_i-\\bar{y})}}{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}\\] and \\[\\hat{\\beta}_0=\\bar{y}-\\hat{\\beta}_1\\bar{x} \\] where \\(\\bar{y}\\) and \\(\\bar{x}\\) are the sample means. the variance \\(\\sigma^2\\) is estimated by \\[\\hat\\sigma^2 = {RSS}/{(n-2)}\\] where n is the number of observations The Residual Standard Error is defined as \\[RSE = \\sqrt{{RSS}/{(n-2)}}\\] The equation \\[ Y = \\beta_0 + \\beta_1 X + \\epsilon\\] defines the linear model, i.e., the population regression line The least squares line is \\(\\hat{Y}=\\hat{\\beta_0} + \\hat{\\beta}_1X\\) Confidence intervals are computed using the standard errors of the intercept and the slope. The \\(95\\%\\) confidence interval for the slope is computed as \\[[\\hat{\\beta}_1 - 2 \\cdot SE(\\hat{\\beta}_1), \\hat{\\beta}_1+SE(\\hat{\\beta}_1)]\\] where \\[ SE(\\hat{\\beta}_1) = \\sqrt{\\frac{\\sigma^2}{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}}\\] 3.1.4 Linear regression in R The following are the basic commands in R: The basic function is lm(), that returns an object with the model. Other commands: summary prints out information about the regression, coef gives the coefficients for the linear model, fitted gives the predictd value of \\(y\\) for each value of \\(x\\), residuals contains the differences between observed and fitted values. predict will generate predicted values of the response for the values of the explanatory variable. 3.2 Linear Regression Diagnostics Several plots help to evaluate the suitability of the linear regression Residuals vs fitted: The residuals should be randomly distributed around the horizontal line representing a residual error of zero; that is, there should not be a distinct trend in the distribution of points. Standard Q-Q plot: residual errors are normally distributed Square root of the standardized residuals vs the fitted values: there should be no obvious trend. This plot is similar to the residuals versus fitted values plot, but it uses the square root of the standardized residuals. Leverage: measures the importance of each point in determining the regression result. Smaller values means that removing the observation has little effect on the regression result. 3.2.1 Simulation example 3.2.1.1 Simulate a dataset set.seed(3456) # equation is y = -6.6 + 0.13 x +e # range x 100,400 a &lt;- -6.6 b &lt;- 0.13 num_obs &lt;- 60 xmin &lt;- 100 xmax &lt;- 400 x &lt;- sample(seq(from=xmin, to = xmax, by =1), size= num_obs, replace=FALSE) sderror &lt;- 9 # sigma for the error term in the model e &lt;- rnorm(num_obs, 0, sderror) y &lt;- a + b * x + e newlm &lt;- lm(y~x) summary(newlm) ## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -26.518 -5.645 0.363 5.695 18.392 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -7.9060 3.3922 -2.33 0.023 * ## x 0.1331 0.0132 10.05 2.6e-14 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 8.48 on 58 degrees of freedom ## Multiple R-squared: 0.635, Adjusted R-squared: 0.629 ## F-statistic: 101 on 1 and 58 DF, p-value: 2.57e-14 cfa1 &lt;- coef(newlm)[1] cfb2 &lt;- coef(newlm)[2] plot(x,y, xlab=&quot;x axis&quot;, ylab= &quot;y axis&quot;, xlim = c(xmin, xmax), ylim = c(0,60), sub = &quot;Line in black is the actual model&quot;) title(main = paste(&quot;Line in blue is the Regression Line for &quot;, num_obs, &quot; points.&quot;)) abline(a = cfa1, b = cfb2, col= &quot;blue&quot;, lwd=3) abline(a = a, b = b, col= &quot;black&quot;, lwd=1) #original line 3.2.1.1.1 Subset a set of points from the same sample # sample from the same x to compare least squares lines # change the denominator in newsample to see how the least square lines changes accordingly. newsample &lt;- as.integer(num_obs/8) # number of pairs x,y idxs_x1 &lt;- sample(1:num_obs, size = newsample, replace = FALSE) #sample indexes x1 &lt;- x[idxs_x1] e1 &lt;- e[idxs_x1] y1 &lt;- a + b * x1 + e1 xy_obs &lt;- data.frame(x1, y1) names(xy_obs) &lt;- c(&quot;x_obs&quot;, &quot;y_obs&quot;) newlm1 &lt;- lm(y1~x1) summary(newlm1) ## ## Call: ## lm(formula = y1 ~ x1) ## ## Residuals: ## 1 2 3 4 5 6 7 ## 3.968 -8.537 3.141 -8.723 7.294 -0.235 3.092 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.9107 7.7166 0.38 0.722 ## x1 0.0913 0.0328 2.79 0.039 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.89 on 5 degrees of freedom ## Multiple R-squared: 0.609, Adjusted R-squared: 0.53 ## F-statistic: 7.77 on 1 and 5 DF, p-value: 0.0385 cfa21 &lt;- coef(newlm1)[1] cfb22 &lt;- coef(newlm1)[2] plot(x1,y1, xlab=&quot;x axis&quot;, ylab= &quot;y axis&quot;, xlim = c(xmin, xmax), ylim = c(0,60)) title(main = paste(&quot;New line in red with &quot;, newsample, &quot; points in sample&quot;)) abline(a = a, b = b, col= &quot;black&quot;, lwd=1) # True line abline(a = cfa1, b = cfb2, col= &quot;blue&quot;, lwd=1) #sample abline(a = cfa21, b = cfb22, col= &quot;red&quot;, lwd=2) #new line 3.2.1.1.2 Compute a confidence interval on the original sample regression line newx &lt;- seq(xmin, xmax) ypredicted &lt;- predict(newlm, newdata=data.frame(x=newx), interval= &quot;confidence&quot;, level= 0.90, se = TRUE) plot(x,y, xlab=&quot;x axis&quot;, ylab= &quot;y axis&quot;, xlim = c(xmin, xmax), ylim = c(0,60)) # points(x1, fitted(newlm1)) abline(newlm) lines(newx,ypredicted$fit[,2],col=&quot;red&quot;,lty=2) lines(newx,ypredicted$fit[,3],col=&quot;red&quot;,lty=2) # Plot the residuals or errors ypredicted_x &lt;- predict(newlm, newdata=data.frame(x=x)) plot(x,y, xlab=&quot;x axis&quot;, ylab= &quot;y axis&quot;, xlim = c(xmin, xmax), ylim = c(0,60), sub = &quot;&quot;, pch=19, cex=0.75) title(main = paste(&quot;Residuals or errors&quot;, num_obs, &quot; points.&quot;)) abline(newlm) segments(x, y, x, ypredicted_x) 3.2.1.1.3 Take another sample from the model and explore # equation is y = -6.6 + 0.13 x +e # range x 100,400 num_obs &lt;- 35 xmin &lt;- 100 xmax &lt;- 400 x3 &lt;- sample(seq(from=xmin, to = xmax, by =1), size= num_obs, replace=FALSE) sderror &lt;- 14 # sigma for the error term in the model e3 &lt;- rnorm(num_obs, 0, sderror) y3 &lt;- a + b * x3 + e3 newlm3 &lt;- lm(y3~x3) summary(newlm3) ## ## Call: ## lm(formula = y3 ~ x3) ## ## Residuals: ## Min 1Q Median 3Q Max ## -40.87 -9.20 -2.28 12.08 47.17 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.9284 8.7458 -0.11 0.9161 ## x3 0.1193 0.0345 3.45 0.0015 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 17.2 on 33 degrees of freedom ## Multiple R-squared: 0.266, Adjusted R-squared: 0.243 ## F-statistic: 11.9 on 1 and 33 DF, p-value: 0.00153 cfa31 &lt;- coef(newlm3)[1] cfb32 &lt;- coef(newlm3)[2] plot(x3,y3, xlab=&quot;x axis&quot;, ylab= &quot;y axis&quot;, xlim = c(xmin, xmax), ylim = c(0,60)) title(main = paste(&quot;Line in red is the Regression Line for &quot;, num_obs, &quot; points.&quot;)) abline(a = cfa31, b = cfb32, col= &quot;red&quot;, lwd=3) abline(a = a, b = b, col= &quot;black&quot;, lwd=2) #original line abline(a = cfa1, b = cfb2, col= &quot;blue&quot;, lwd=1) #first sample # confidence intervals for the new sample newx &lt;- seq(xmin, xmax) ypredicted &lt;- predict(newlm3, newdata=data.frame(x3=newx), interval= &quot;confidence&quot;, level= 0.90, se = TRUE) lines(newx,ypredicted$fit[,2],col=&quot;red&quot;,lty=2, lwd=2) lines(newx,ypredicted$fit[,3],col=&quot;red&quot;,lty=2, lwd=2) 3.2.2 Diagnostics fro assessing the regression line 3.2.2.1 Residual Standard Error It gives us an idea of the typical or average error of the model. It is the estimated standard deviation of the residuals. 3.2.2.2 \\(R^2\\) statistic This is the proportion of variability in the data that is explained by the model. Best values are those close to 1. 3.3 Multiple Linear Regression 3.3.1 Partial Least Squares If several predictors are highly correlated, the least squares approach has high variability. PLS finds linear combinations of the predictors, that are called components or latent variables. 3.4 Linear regression in Software Effort estimation Fitting a linear model to log-log - the predictive power equation is \\(y= e^{b_0}*x^{b_1}\\), ignoring the bias corrections. Note: depending how the error term behaves we could try another general linear model (GLM) or other model that does not rely on the normality of the residuals (quantile regression, etc.) - First, we are fitting the model to the whole dataset. But it is not the right way to do it, because of overfitting. library(foreign) china &lt;- read.arff(&quot;./datasets/effortEstimation/china.arff&quot;) china_size &lt;- china$AFP summary(china_size) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 9 100 215 487 438 17518 china_effort &lt;- china$Effort summary(china_effort) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 26 704 1829 3921 3826 54620 par(mfrow=c(1,2)) hist(china_size, col=&quot;blue&quot;, xlab=&quot;Adjusted Function Points&quot;, main=&quot;Distribution of AFP&quot;) hist(china_effort, col=&quot;blue&quot;,xlab=&quot;Effort&quot;, main=&quot;Distribution of Effort&quot;) boxplot(china_size) boxplot(china_effort) qqnorm(china_size) qqline(china_size) qqnorm(china_effort) qqline(china_effort) Applying the log function (it computes natural logarithms, base \\(e\\)) linmodel_logchina &lt;- lm(logchina_effort ~ logchina_size) par(mfrow=c(1,1)) plot(logchina_size, logchina_effort) abline(linmodel_logchina, lwd=3, col=3) par(mfrow=c(1,2)) plot(linmodel_logchina, ask = FALSE) linmodel_logchina ## ## Call: ## lm(formula = logchina_effort ~ logchina_size) ## ## Coefficients: ## (Intercept) logchina_size ## 3.301 0.768 3.5 References The New Statistics with R, Andy Hector, 2015 An Introduction to R, W.N. Venables and D.M. Smith and the R Development Core Team Practical Data Science with R, Nina Zumel and John Mount G. James et al, An Introduction to Statistical Learning with Applications in R, Springer, 2013 "],["unsupervised-or-descriptive-modeling.html", "Chapter 4 Unsupervised or Descriptive modeling 4.1 Clustering 4.2 Association rules", " Chapter 4 Unsupervised or Descriptive modeling From the descriptive (unsupervised) point of view, patterns are found to predict future behaviour or estimate. This include association rules, clustering, or tree clustering which aim at grouping together objects (e.g., animals) into successively larger clusters, using some measure of similarity or distance. The dataset will be as the previous table without the \\(C\\) class attribute Att1 Attn a11 … a1n a21 … a2n … … … am1 … amn 4.1 Clustering library(foreign) library(fpc) kc1 &lt;- read.arff(&quot;./datasets/defectPred/D1/KC1.arff&quot;) # Split into training and test datasets set.seed(1) ind &lt;- sample(2, nrow(kc1), replace = TRUE, prob = c(0.7, 0.3)) kc1.train &lt;- kc1[ind==1, ] kc1.test &lt;- kc1[ind==2, ] # No class kc1.train$Defective &lt;- NULL ds &lt;- dbscan(kc1.train, eps = 0.42, MinPts = 5) kc1.kmeans &lt;- kmeans(kc1.train, 2) 4.1.1 k-Means library(reshape, quietly=TRUE) library(graphics) kc1kmeans &lt;- kmeans(sapply(na.omit(kc1.train), rescaler, &quot;range&quot;), 10) #plot(kc1kmeans, col = kc1kmeans$cluster) #points(kc1kmeans$centers, col = 1:5, pch = 8) 4.2 Association rules library(arules) # x &lt;- as.numeric(kc1$LOC_TOTAL) # str(x) # summary(x) # hist(x, breaks=30, main=&quot;LoC Total&quot;) # xDisc &lt;- discretize(x, categories=5) # table(xDisc) for(i in 1:21) kc1[,i] &lt;- discretize(kc1[,i], method = &quot;interval&quot;, breaks = 5) rules &lt;- apriori(kc1, parameter = list(minlen=3, supp=0.05, conf=0.35), appearance = list(rhs=c(&quot;Defective=Y&quot;), default=&quot;lhs&quot;), control = list(verbose=F)) #rules &lt;- apriori(kc1, # parameter = list(minlen=2, supp=0.05, conf=0.3), # appearance = list(rhs=c(&quot;Defective=Y&quot;, &quot;Defective=N&quot;), # default=&quot;lhs&quot;)) inspect(rules) ## lhs rhs support confidence coverage lift count ## [1] {HALSTEAD_CONTENT=[38.6,77.2), ## HALSTEAD_LEVEL=[0,0.4)} =&gt; {Defective=Y} 0.0539 0.370 0.146 2.39 113 ## [2] {LOC_CODE_AND_COMMENT=[0,2.4), ## HALSTEAD_CONTENT=[38.6,77.2)} =&gt; {Defective=Y} 0.0525 0.377 0.139 2.43 110 ## [3] {LOC_CODE_AND_COMMENT=[0,2.4), ## HALSTEAD_CONTENT=[38.6,77.2), ## HALSTEAD_LEVEL=[0,0.4)} =&gt; {Defective=Y} 0.0515 0.374 0.138 2.41 108 library(arulesViz) plot(rules) "],["evaluation-of-models.html", "Chapter 5 Evaluation of Models 5.1 Building and Validating a Model 5.2 Evaluation of Classification Models 5.3 Other Metrics used in Software Engineering with Classification 5.4 Graphical Evaluation 5.5 Numeric Prediction Evaluation", " Chapter 5 Evaluation of Models Once we obtain the model with the training data, we need to evaluate it with some new data (testing data). No Free Lunch theorem In the absence of any knowledge about the prediction problem, no model can be said to be uniformly better than any other 5.1 Building and Validating a Model We cannot use the the same data for training and testing (it is like evaluating a student with the exercises previously solved in class, the student’s marks will be “optimistic” and we do not know about student capability to generalise the learned concepts). Therefore, we should, at a minimum, divide the dataset into training and testing, learn the model with the training data and test it with the rest of data as explained next. 5.1.1 Holdout approach Holdout approach consists of dividing the dataset into training (typically approx. 2/3 of the data) and testing (approx 1/3 of the data). + Problems: Data can be skewed, missing classes, etc. if randomly divided. Stratification ensures that each class is represented with approximately equal proportions (e.g., if data contains approximately 45% of positive cases, the training and testing datasets should maintain similar proportion of positive cases). Holdout estimate can be made more reliable by repeating the process with different subsamples (repeated holdout method). The error rates on the different iterations are averaged (overall error rate). Usually, part of the data points are used for building the model and the remaining points are used for validating the model. There are several approaches to this process. Validation Set approach: it is the simplest method. It consists of randomly dividing the available set of observations into two parts, a training set and a validation set or hold-out set. Usually 2/3 of the data points are used for training and 1/3 is used for testing purposes. Hold out validation 5.1.2 Cross Validation (CV) k-fold Cross-Validation involves randomly dividing the set of observations into \\(k\\) groups, or folds, of approximately equal size. One fold is treated as a validation set and the method is trained on the remaining \\(k-1\\) folds. This procedure is repeated \\(k\\) times. If \\(k\\) is equal to \\(n\\) we are in the previous method. 1st step: split dataset (\\(\\cal D\\)) into \\(k\\) subsets of approximately equal size \\(C_1, \\dots, C_k\\) 2nd step: we construct a dataset \\(D_i = D-C_i\\) used for training and test the accuracy of the classifier \\(D_i\\) on \\(C_i\\) subset for testing Having done this for all \\(k\\) we estimate the accuracy of the method by averaging the accuracy over the \\(k\\) cross-validation trials k-fold 5.1.3 Leave-One-Out Cross-Validation (LOO-CV) Leave-One-Out Cross-Validation (LOO-CV): This is a special case of CV. Instead of creating two subsets for training and testing, a single observation is used for the validation set, and the remaining observations make up the training set. This approach is repeated \\(n\\) times (the total number of observations) and the estimate for the test mean squared error is the average of the \\(n\\) test estimates. Leave One Out 5.2 Evaluation of Classification Models The confusion matrix (which can be extended to multiclass problems) is a table that presents the results of a classification algorithm. The following table shows the possible outcomes for binary classification problems: \\(Act Pos\\) \\(Act Neg\\) \\(Pred Pos\\) \\(TP\\) \\(FP\\) \\(Pred Neg\\) \\(FN\\) \\(TN\\) where True Positives (\\(TP\\)) and True Negatives (\\(TN\\)) are respectively the number of positive and negative instances correctly classified, False Positives (\\(FP\\)) is the number of negative instances misclassified as positive (also called Type I errors), and False Negatives (\\(FN\\)) is the number of positive instances misclassified as negative (Type II errors). Confusion Matrix in Wikipedia From the confusion matrix, we can calculate: True positive rate, or recall (\\(TP_r = recall = TP/TP+FN\\)) is the proportion of positive cases correctly classified as belonging to the positive class. False negative rate (\\(FN_r=FN/TP+FN\\)) is the proportion of positive cases misclassified as belonging to the negative class. False positive rate (\\(FP_r=FP/FP+TN\\)) is the proportion of negative cases misclassified as belonging to the positive class. True negative rate (\\(TN_r=TN/FP+TN\\)) is the proportion of negative cases correctly classified as belonging to the negative class. There is a trade-off between \\(FP_r\\) and \\(FN_r\\) as the objective is minimize both metrics (or conversely, maximize the true negative and positive rates). It is possible to combine both metrics into a single figure, predictive \\(accuracy\\): \\[accuracy = \\frac{TP + TN}{TP + TN + FP + FN}\\] to measure performance of classifiers (or the complementary value, the error rate which is defined as \\(1-accuracy\\)) Precision, fraction of relevant instances among the retrieved instances, \\[\\frac{TP}{TP+FP}\\] Recall$ (\\(sensitivity\\) probability of detection, \\(PD\\)) is the fraction of relevant instances that have been retrieved over total relevant instances, \\(\\frac{TP}{TP+FN}\\) f-measure is the harmonic mean of precision and recall, \\(2 \\cdot \\frac{precision \\cdot recall}{precision + recall}\\) G-mean: \\(\\sqrt{PD \\times Precision}\\) G-mean2: \\(\\sqrt{PD \\times Specificity}\\) J coefficient, \\(j-coeff = sensitivity + specificity - 1 = PD-PF\\) A suitable and interesting performance metric for binary classification when data are imbalanced is the Matthew’s Correlation Coefficient (\\(MCC\\))~: \\[MCC=\\frac{TP\\times TN - FP\\times FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}\\] \\(MCC\\) can also be calculated from the confusion matrix. Its range goes from -1 to +1; the closer to one the better as it indicates perfect prediction whereas a value of 0 means that classification is not better than random prediction and negative values mean that predictions are worst than random. 5.2.1 Prediction in probabilistic classifiers A probabilistic classifier estimates the probability of each of the posible class values given the attribute values of the instance \\(P(c|{x})\\). Then, given a new instance, \\({x}\\), the class value with the highest a posteriori probability will be assigned to that new instance (the winner takes all approach): \\(\\psi({x}) = argmax_c (P(c|{x}))\\) 5.3 Other Metrics used in Software Engineering with Classification In the domain of defect prediction and when two classes are considered, it is also customary to refer to the probability of detection, (\\(pd\\)) which corresponds to the True Positive rate (\\(TP_{rate}\\) or ) as a measure of the goodness of the model, and probability of false alarm (\\(pf\\)) as performance measures~. The objective is to find which techniques that maximise \\(pd\\) and minimise \\(pf\\). As stated by Menzies et al., the balance between these two measures depends on the project characteristics (e.g. real-time systems vs. information management systems) it is formulated as the Euclidean distance from the sweet spot \\(pf=0\\) and \\(pd=1\\) to a pair of \\((pf,pd)\\). \\[balance=1-\\frac{\\sqrt{(0-pf^2)+(1-pd^2)}}{\\sqrt{2}}\\] It is normalized by the maximum possible distance across the ROC square (\\(\\sqrt{2}, 2\\)), subtracted this value from 1, and expressed it as a percentage. 5.4 Graphical Evaluation 5.4.1 Receiver Operating Characteristic (ROC) The Receiver Operating Characteristic (\\(ROC\\))(Fawcett 2006) curve which provides a graphical visualisation of the results. Receiver Operating Characteristic The Area Under the ROC Curve (AUC) also provides a quality measure between positive and negative rates with a single value. A simple way to approximate the AUC is with the following equation: \\(AUC=\\frac{1+TP_{r}-FP_{r}}{2}\\) 5.4.2 Precision-Recall Curve (PRC) Similarly to ROC, another widely used evaluation technique is the Precision-Recall Curve (PRC), which depicts a trade off between precision and recall and can also be summarised into a single value as the Area Under the Precision-Recall Curve (AUPRC)~. %AUPCR is more accurate than the ROC for testing performances when dealing with imbalanced datasets as well as optimising ROC values does not necessarily optimises AUPR values, i.e., a good classifier in AUC space may not be so good in PRC space. %The weighted average uses weights proportional to class frequencies in the data. %The weighted average is computed by weighting the measure of class (TP rate, precision, recall …) by the proportion of instances there are in that class. Computing the average can be sometimes be misleading. For instance, if class 1 has 100 instances and you achieve a recall of 30%, and class 2 has 1 instance and you achieve recall of 100% (you predicted the only instance correctly), then when taking the average (65%) you will inflate the recall score because of the one instance you predicted correctly. Taking the weighted average will give you 30.7%, which is much more realistic measure of the performance of the classifier. 5.5 Numeric Prediction Evaluation In the case of defect prediction, it matters the difference between the predicted value and the actual value. Common performance metrics used for numeric prediction are as follows, where \\(\\hat{y_n}\\) represents the predicted value and \\(y_n\\) the actual one. Mean Square Error (\\(MSE\\)) \\(MSE = \\frac{(\\hat{y_1} - y_1)^2 + \\ldots +(\\hat{y_n} - y_n)^2}{n} = \\frac{1}{n}\\sum_{i=1}^n(\\hat{y_i} - y_i)^2\\) Root mean-squared error (\\(RMSE\\)) \\({RMSE} = \\sqrt{\\frac{\\sum_{t=1}^n (\\hat y_t - y)^2}{n}}\\) Mean Absolute Error (\\(MAE\\)) \\(MAE = \\frac{|\\hat{y_1} - y_1| + \\ldots +|\\hat{y_n} - y_n|}{n} = \\sqrt{\\frac{\\sum_{t=1}^n |\\hat y_t - y|}{n}}\\) Relative Absolute Error (\\(RAE\\)) \\(RAE = \\frac{ \\sum^N_{i=1} | \\hat{\\theta}_i - \\theta_i | } { \\sum^N_{i=1} | \\overline{\\theta} - \\theta_i |}\\) Root Relative-Squared Error (\\(RRSE\\)) \\(RRSE = \\sqrt{ \\frac{ \\sum^N_{i=1} | \\hat{\\theta}_i - \\theta_i | } { \\sum^N_{i=1} | \\overline{\\theta} - \\theta_i | } }\\) where \\(\\hat{\\theta}\\) is a mean value of \\(\\theta\\). Relative-Squared r (\\(RSE\\)) \\(\\frac{(p_1-a_1)^2 + \\ldots +(p_n-a_n)^2}{(a_1-\\hat{a})^2 + \\ldots + (a_n-\\hat{a})^2}\\) where (\\(\\hat{a}\\) is the mean value over the training data) Relative Absolute Error (\\(RAE\\)) Correlation Coefficient Correlation coefficient between two random variables \\(X\\) and \\(Y\\) is defined as \\(\\rho(X,Y) = \\frac{{\\bf Cov}(X,Y)}{\\sqrt{{\\bf Var}(X){\\bf Var}(Y)}}\\). The sample correlation coefficient} \\(r\\) between two samples \\(x_i\\) and \\(y_j\\) is vvdefined as \\(r = S_{xy}/\\sqrt{S_{xx}S_{yy}}\\) Example: Is there any linear relationship between the effort estimates (\\(p_i\\)) and actual effort (\\(a_i\\))? \\(a\\|39,43,21,64,57,47,28,75,34,52\\) \\(p\\|65,78,52,82,92,89,73,98,56,75\\) p&lt;-c(39,43,21,64,57,47,28,75,34,52) a&lt;-c(65,78,52,82,92,89,73,98,56,75) # cor(p,a) ## [1] 0.84 \\(R^2\\) References "],["evaluationSE.html", "Chapter 6 Measures of Evaluation in Software Engineering 6.1 Effort estimation evaluation metrics 6.2 Evaluation of the Model in the Testing data 6.3 Building a Linear Model on the Telecom1 dataset 6.4 Building a Linear Model on the Telecom1 dataset with all observations 6.5 Standardised Accuracy Examples 6.6 Exact MARP0 6.7 Computing the bootstraped confidence interval of the mean for the Test observations of the China dataset: 6.8 Defect prediction evaluation metrics", " Chapter 6 Measures of Evaluation in Software Engineering 6.1 Effort estimation evaluation metrics There are several measures typically used in software engineering. In particular for effort estimation, the following metrics are extensively used in addition or instead of statistical measures. Mean of the Absolute Error (MAR): compute the absolute errors and take the mean Geometric Mean of the Absolute Error (gMAR): more appropriate when the distribution is skewed Mean Magnitude of the Relative Error (MMRE): this measure has been critisized many times as a biased measure (\\(\\frac{\\sum_{i=1}^{n}{|{\\hat{y}_i-y_i}|}/y_i}{n}\\)) Median Magnitude of the Relative Error (MdMRE): using the median instead of the mean Level of Prediction (\\(Pred(l)\\)) defined as the percentage of estimates that are within the percentage level \\(l\\) of the actual values. The level of prediction is typically set at 25% below and above the actual value and an estimation method is considered good if it gives a result of more than 75%. Standardised Accuracy (SA) (proposed by Shepperd and MacDonnell): this measure overcomes all the problems of the MMRE. It is defined as the MAR relative to random guessing (\\(SA=1-{\\frac{MAR}{\\overline{MAR}_{P_0}}\\times100}\\)) Random guessing: \\(\\overline{MAR}_{P_0}\\) is defined as: predict a \\(\\hat{y}_t\\) for the target case t by randomly sampling (with equal probability) over all the remaining n-1 cases and take \\(\\hat{y}_t=y_r\\) where \\(r\\) is drawn randomly from \\(1\\) to \\(n\\) and \\(r\\neq t\\). Exact \\(\\overline{MAR}_{P_0}\\): it is an improvement over \\(\\overline{MAR}_{P_0}\\). For small datasets the “random guessing” can be computed exactly by iterating over all data points. 6.2 Evaluation of the Model in the Testing data library(foreign) gm_mean = function(x, na.rm=TRUE){ exp(sum(log(x[x &gt; 0]), na.rm=na.rm) / length(x))} chinaTrain &lt;- read.arff(&quot;./datasets/effortEstimation/china3AttSelectedAFPTrain.arff&quot;) logchina_size &lt;- log(chinaTrain$AFP) logchina_effort &lt;- log(chinaTrain$Effort) linmodel_logchina_train &lt;- lm(logchina_effort ~ logchina_size) chinaTest &lt;- read.arff(&quot;./datasets/effortEstimation/china3AttSelectedAFPTest.arff&quot;) b0 &lt;- linmodel_logchina_train$coefficients[1] b1 &lt;- linmodel_logchina_train$coefficients[2] china_size_test &lt;- chinaTest$AFP actualEffort &lt;- chinaTest$Effort # predEffort &lt;- exp(b0+b1*log(china_size_test)) wr predEffort &lt;- exp(b0)*china_size_test^b1 err &lt;- actualEffort - predEffort #error or residual ae &lt;- abs(err) hist(ae, main=&quot;Absolute Error in the China Test data&quot;) mar &lt;- mean(ae) mre &lt;- ae/actualEffort mmre &lt;- mean(mre) mdmre &lt;- median(mre) gmar &lt;- gm_mean(ae) mar ## [1] 1867 mmre ## [1] 1.15 mdmre ## [1] 0.551 gmar ## [1] 833 level_pred &lt;- 0.25 #below and above (both) lowpred &lt;- actualEffort*(1-level_pred) uppred &lt;- actualEffort*(1+level_pred) pred &lt;- predEffort &lt;= uppred &amp; predEffort &gt;= lowpred #pred is a vector with logical values Lpred &lt;- sum(pred)/length(pred) Lpred ## [1] 0.186 6.3 Building a Linear Model on the Telecom1 dataset Although there are few data points we split the file into Train (2/3) and Test (1/3) telecom1 &lt;- read.table(&quot;./datasets/effortEstimation/Telecom1.csv&quot;, sep=&quot;,&quot;,header=TRUE, stringsAsFactors=FALSE, dec = &quot;.&quot;) #read data samplesize &lt;- floor(0.66*nrow(telecom1)) set.seed(012) # to make the partition reproducible train_idx &lt;- sample(seq_len(nrow(telecom1)), size = samplesize) telecom1_train &lt;- telecom1[train_idx, ] telecom1_test &lt;- telecom1[-train_idx, ] par(mfrow=c(1,1)) # transformation of variables to log-log xtrain &lt;- log(telecom1_train$size) ytrain &lt;- log(telecom1_train$effort) lmtelecom1 &lt;- lm( ytrain ~ xtrain) plot(xtrain, ytrain) abline(lmtelecom1, lwd=2, col=&quot;blue&quot;) b0_tel1 &lt;- lmtelecom1$coefficients[1] b1_tel1 &lt;- lmtelecom1$coefficients[2] # calculate residuals and predicted values res &lt;- signif(residuals(lmtelecom1), 5) xtest &lt;- telecom1_test$size ytest &lt;- telecom1_test$effort # pre_tel1 &lt;- exp(b0_tel1+b1_tel1*log(xtest)) pre_tel1 &lt;- exp(b0_tel1)*xtest^b1_tel1 # plot distances between points and the regression line plot(xtest, ytest) curve(exp(b0_tel1+b1_tel1*log(x)), from=0, to=300, add=TRUE, col=&quot;blue&quot;, lwd=2) segments(xtest, ytest, xtest, pre_tel1, col=&quot;red&quot;) 6.4 Building a Linear Model on the Telecom1 dataset with all observations Just to visualize results par(mfrow=c(1,1)) effort_telecom1 &lt;- telecom1$effort size_telecom1 &lt;- telecom1$size lmtelecom &lt;- lm(effort_telecom1 ~ size_telecom1) plot(size_telecom1, effort_telecom1) abline(lmtelecom, lwd=3, col=&quot;blue&quot;) # calculate residuals and predicted values res &lt;- signif(residuals(lmtelecom), 5) predicted &lt;- predict(lmtelecom) # plot distances between points and the regression line segments(size_telecom1, effort_telecom1, size_telecom1, predicted, col=&quot;red&quot;) level_pred &lt;- 0.25 #below and above (both) lowpred &lt;- effort_telecom1*(1-level_pred) uppred &lt;- effort_telecom1*(1+level_pred) predict_inrange &lt;- predicted &lt;= uppred &amp; predicted &gt;= lowpred #pred is a vector with logical values Lpred &lt;- sum(predict_inrange)/length(predict_inrange) Lpred ## [1] 0.444 #Visually plot lpred segments(size_telecom1, lowpred, size_telecom1, uppred, col=&quot;red&quot;, lwd=3) err_telecom1 &lt;- abs(effort_telecom1 - predicted) mar_tel1 &lt;- mean(err_telecom1) mar_tel1 ## [1] 125 6.5 Standardised Accuracy Examples 6.5.1 Standardised Accuracy MARP0 using the China Test dataset Computing \\(MARP_0\\) in the China Test data estimEffChinaTest &lt;- predEffort # This will be overwritten, no problem numruns &lt;- 9999 randguessruns &lt;- rep(0, numruns) for (i in 1:numruns) { for (j in 1:length(estimEffChinaTest)) { estimEffChinaTest[j] &lt;- sample(actualEffort[-j],1)}#replacement with random guessingt randguessruns[i] &lt;- mean(abs(estimEffChinaTest-actualEffort)) } marp0Chinatest &lt;- mean(randguessruns) marp0Chinatest ## [1] 3949 hist(randguessruns, main=&quot;MARP0 distribution of the China dataset&quot;) saChina = (1- mar/marp0Chinatest)*100 saChina ## [1] 52.7 6.5.2 Standardised Accuracy. MARP0 using the Telecom1 dataset Computing \\(MARP_0\\) telecom1 &lt;- read.table(&quot;./datasets/effortEstimation/Telecom1.csv&quot;, sep=&quot;,&quot;,header=TRUE, stringsAsFactors=FALSE, dec = &quot;.&quot;) #read data #par(mfrow=c(1,2)) #size &lt;- telecom1[1]$size not needed now actualEffTelecom1 &lt;- telecom1[2]$effort estimEffTelecom1 &lt;- telecom1[3]$EstTotal # this will be overwritten numruns &lt;- 9999 randguessruns &lt;- rep(0, numruns) for (i in 1:numruns) { for (j in 1:length(estimEffTelecom1)) { estimEffTelecom1[j] &lt;- sample(actualEffTelecom1[-j],1)}#replacement with random guessingt randguessruns[i] &lt;- mean(abs(estimEffTelecom1-actualEffTelecom1)) } marp0telecom1 &lt;- mean(randguessruns) marp0telecom1 ## [1] 271 hist(randguessruns, main=&quot;MARP0 distribution of the Telecom1 dataset&quot;) saTelecom1 &lt;- (1- mar_tel1/marp0telecom1)*100 saTelecom1 ## [1] 53.9 6.5.3 Standard Accuracy MARP0 using the Atkinson Dataset For checking results you may use figure Atkinson in Shepperd &amp; MacDonnell ## [1] 281 6.6 Exact MARP0 Langdon et al(2016) provide a solution to calculate Shepperd and MacDonell’s \\(MAR\\)_{P_0}$ exactly. An R code implementation is as follows. #example dataset atkinson_actual_effort &lt;- c(670,912,218,595,267,344,229,190,869,109,289,616,557,416,578,438) myabs &lt;- function(x,y) abs(x-y) #diffs is square array whose i,jth element = abs(actual_i - actual_j) #in practice this is good enough but could be made more efficient by not #explicitly storing the matrix and only using the values below the diagonal. diffs &lt;- outer(atkinson_actual_effort,atkinson_actual_effort,myabs) marp0 &lt;- mean(diffs) marp0 ## [1] 264 #### same procedure without using the outer function act_effort &lt;- c(670,912,218,595,267,344,229,190,869,109,289,616,557,416,578,438) n &lt;- length(act_effort) diffs_guess &lt;- matrix(nrow=n, ncol=n) colnames(diffs_guess) &lt;- act_effort rownames(diffs_guess) &lt;- act_effort for (i in 1:n){ diffs_guess[i,] &lt;- act_effort - act_effort[i] } diffs_guess &lt;- abs(diffs_guess) means_per_point &lt;- apply(diffs_guess, 2, mean) marp0 &lt;- mean(means_per_point) marp0 ## [1] 264 6.7 Computing the bootstraped confidence interval of the mean for the Test observations of the China dataset: library(boot) ## ## Attaching package: &#39;boot&#39; ## The following object is masked from &#39;package:survival&#39;: ## ## aml ## The following object is masked from &#39;package:lattice&#39;: ## ## melanoma ## The following object is masked from &#39;package:sm&#39;: ## ## dogs hist(ae, main=&quot;Absolute Errors of the China Test data&quot;) level_confidence &lt;- 0.95 repetitionsboot &lt;- 9999 samplemean &lt;- function(x, d){return(mean(x[d]))} b_mean &lt;- boot(ae, samplemean, R=repetitionsboot) confint_mean_China &lt;- boot.ci(b_mean) ## Warning in boot.ci(b_mean): bootstrap variances needed for studentized intervals confint_mean_China ## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS ## Based on 9999 bootstrap replicates ## ## CALL : ## boot.ci(boot.out = b_mean) ## ## Intervals : ## Level Normal Basic ## 95% (1420, 2316 ) (1386, 2284 ) ## ## Level Percentile BCa ## 95% (1450, 2348 ) (1496, 2419 ) ## Calculations and Intervals on Original Scale Computing the bootstraped geometric mean boot_geom_mean &lt;- function(error_vec){ log_error &lt;- log(error_vec[error_vec &gt; 0]) log_error &lt;-log_error[is.finite(log_error)] #remove the -Inf value before calculating the mean, just in case samplemean &lt;- function(x, d){return(mean(x[d]))} b &lt;- boot(log_error, samplemean, R=repetitionsboot) # with package boot # this is a boot for the logs return(b) } # BCAconfidence interval for the geometric mean BCAciboot4geommean &lt;- function(b){ conf_int &lt;- boot.ci(b, conf=level_confidence, type=&quot;bca&quot;)$bca #following 10.9 of Ugarte et al.&#39;s book conf_int[5] &lt;- exp(conf_int[5]) # the boot was computed with log. Now take the measure back to its previous units conf_int[4] &lt;- exp(conf_int[4]) return (conf_int) } # this is a boot object b_gm &lt;- boot_geom_mean(ae) #&quot;ae&quot; is the absolute error in the China Test data print(paste0(&quot;Geometric Mean of the China Test data: &quot;, round(exp(b_gm$t0), digits=3))) ## [1] &quot;Geometric Mean of the China Test data: 832.55&quot; b_ci_gm &lt;- BCAciboot4geommean(b_gm) print(paste0(&quot;Confidence Interval: &quot;, round(b_ci_gm[4], digits=3), &quot; - &quot;, round(b_ci_gm[5], digits=3))) ## [1] &quot;Confidence Interval: 679.439 - 1016.691&quot; # Make a % confidence interval bca # BCAciboot &lt;- function(b){ # conf_int &lt;- boot.ci(b, conf=level_confidence, type=&quot;bca&quot;)$bca #following 10.9 of Ugarte et al.&#39;s book # return (conf_int) # } 6.8 Defect prediction evaluation metrics In addition to the machine learning metrics for classification, Jiang et al. provide a survey (Jiang, Cukic, and Ma 2008). References "],["feature-selection.html", "Chapter 7 Feature Selection 7.1 Instance Selection 7.2 Missing Data Imputation", " Chapter 7 Feature Selection This technique consists in selecting the most relevant attributes. The need of applying FS includes the following points: A reduced volume of data allows different data mining or searching techniques to be applied. Irrelevant and redundant attributes can generate less accurate and more complex models. Furthermore, data mining algorithms can be executed faster. It is possible to avoid the collection of data for those irrelevant and redundant attributes in the future. FS algorithms designed with different evaluation criteria broadly fall into two categories: The filter model relies on general characteristics of the data to evaluate and select feature subsets without involving any data mining algorithm. The wrapper model requires one predetermined mining algorithm and uses its performance as the evaluation criterion. It searches for features better suited to the mining algorithm aiming to improve mining performance, but it also tends to be more computationally expensive than filter model [11, 12]. 7.1 Instance Selection TBD 7.2 Missing Data Imputation TBD "],["feature-selection-example.html", "Chapter 8 Feature Selection Example", " Chapter 8 Feature Selection Example Feature Selection in R and Caret library(caret) library(doParallel) # parallel processing ## Loading required package: foreach ## Loading required package: iterators ## Loading required package: parallel library(dplyr) # Used by caret library(pROC) # plot the ROC curve ## Type &#39;citation(&quot;pROC&quot;)&#39; for a citation. ## ## Attaching package: &#39;pROC&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## cov, smooth, var library(foreign) ### Use the segmentationData from caret # Load the data and construct indices to divided it into training and test data sets. #set.seed(10) kc1 &lt;- read.arff(&quot;./datasets/defectPred/D1/KC1.arff&quot;) inTrain &lt;- createDataPartition(y = kc1$Defective, ## the outcome data are needed p = .75, ## The percentage of data in the ## training set list = FALSE) The function createDataPartition does a stratified partitions. training &lt;- kc1[inTrain,] nrow(training) ## [1] 1573 testing &lt;- kc1[-inTrain, ] nrow(testing) ## [1] 523 The train function can be used to + evaluate, using resampling, the effect of model tuning parameters on performance + choose the “optimal” model across these parameters + estimate model performance from a training set fitControl &lt;- trainControl(## 10-fold CV method = &quot;repeatedcv&quot;, number = 10, ## repeated ten times repeats = 10) gbmFit1 &lt;- train(Defective ~ ., data = training, method = “gbm”, trControl = fitControl, ## This last option is actually one ## for gbm() that passes through verbose = FALSE) gbmFit1 plsFit &lt;- train(Defective ~ ., data = training, method = &quot;pls&quot;, ## Center and scale the predictors for the training ## set and all future samples. preProc = c(&quot;center&quot;, &quot;scale&quot;) ) # To fix # testPred &lt;- predict(plsFit, testing) # postResample(testPred, testing$Defective) # sensitivity(testPred, testing$Defective) # confusionMatrix(testPred, testing$Defective) When there are three or more classes, confusion matrix will show the confusion matrix and a set of “one-versus-all” results. "],["further-classification-models.html", "Chapter 9 Further Classification Models 9.1 Multilabel classification 9.2 Semi-supervised Learning", " Chapter 9 Further Classification Models 9.1 Multilabel classification Some datasets, for example, reviews of applications and mobile applications repositories such as App Store or Google play contain reviews that can have several labels at the same time (e.g. bugs, feature requests, etc.) 9.2 Semi-supervised Learning Self train a model on semi-supervised data http://www.inside-r.org/packages/cran/dmwr/docs/SelfTrain library(DMwR2) ## Small example with the Iris classification data set data(iris) ## Dividing the data set into train and test sets idx &lt;- sample(150,100) tr &lt;- iris[idx,] ts &lt;- iris[-idx,] ## Learn a tree with the full train set and test it stdTree &lt;- rpartXse(Species~ .,tr,se=0.5) table(predict(stdTree,ts,type=&#39;class&#39;),ts$Species) ## Now let us create another training set with most of the target ## variable values unknown trSelfT &lt;- tr nas &lt;- sample(100,70) trSelfT[nas,&#39;Species&#39;] &lt;- NA ## Learn a tree using only the labelled cases and test it baseTree &lt;- rpartXse(Species~ .,trSelfT[-nas,],se=0.5) table(predict(baseTree,ts,type=&#39;class&#39;),ts$Species) ## The user-defined function that will be used in the self-training process f &lt;- function(m,d) { l &lt;- predict(m,d,type=&#39;class&#39;) c &lt;- apply(predict(m,d),1,max) data.frame(cl=l,p=c) } ## Self train the same model using the semi-superside data and test the ## resulting model treeSelfT &lt;- SelfTrain(Species~ .,trSelfT,learner(&#39;rpartXse&#39;,list(se=0.5)),&#39;f&#39;) table(predict(treeSelfT,ts,type=&#39;class&#39;),ts$Species) "],["social-network-analysis-in-se.html", "Chapter 10 Social Network Analysis in SE", " Chapter 10 Social Network Analysis in SE In this example, we will data from the MSR14 challenge. Further information and datasets: http://openscience.us/repo/msr/msr14.html Similar databases can be obtained using MetricsGrimoire or other tools. In this simple example, we create a network form the users and following extracted from GitHub and stored in a MySQL database. We can read a file directely from MySQL dump library(RMySQL) # Connecting to MySQL mydb = dbConnect(MySQL(), user=&#39;msr14&#39;, password=&#39;msr14&#39;, dbname=&#39;msr14&#39;, host=&#39;localhost&#39;) # Retrieving data from MySQL sql &lt;- &quot;select user_id, follower_id from followers limit 100;&quot; rs = dbSendQuery(mydb, sql) data &lt;- fetch(rs, n=-1) Alternatively, we can create e CSV file directly from MySQL and load it $mysql -u msr14 -pmsr14 msr14 &gt; SELECT &#39;user&#39;,&#39;follower&#39; UNION ALL SELECT user_id,follower_id FROM followers LIMIT 1000 INTO OUTFILE &quot;/tmp/followers.csv&quot; FIELDS TERMINATED BY &#39;,&#39; LINES TERMINATED BY &#39;\\n&#39;; # Data already extracted and stored as CSV file (for demo purposes) dat = read.csv(&quot;./datasets/sna/followers.csv&quot;, header = FALSE, sep = &quot;,&quot;) dat &lt;- head(dat,100) We can now create the graph library(igraph) ## ## Attaching package: &#39;igraph&#39; ## The following object is masked from &#39;package:arules&#39;: ## ## union ## The following object is masked from &#39;package:class&#39;: ## ## knn ## The following object is masked from &#39;package:modeltools&#39;: ## ## clusters ## The following objects are masked from &#39;package:lubridate&#39;: ## ## %--%, union ## The following objects are masked from &#39;package:dplyr&#39;: ## ## as_data_frame, groups, union ## The following objects are masked from &#39;package:stats&#39;: ## ## decompose, spectrum ## The following object is masked from &#39;package:base&#39;: ## ## union # Create a graph g &lt;- graph.data.frame(dat, directed = TRUE) Some values: summary(g); ## IGRAPH c0e8711 DN-- 95 100 -- ## + attr: name (v/c) Plotting the graph: layout1 &lt;- layout.fruchterman.reingold(g) plot(g, layout1) Other layout plot(g, layout=layout.kamada.kawai) A tk application can launched to show the plot interactively: plot(g, layout = layout.fruchterman.reingold) Some metrics: metrics &lt;- data.frame( deg = degree(g), bet = betweenness(g), clo = closeness(g), eig = evcent(g)$vector, cor = graph.coreness(g) ) # head(metrics) ## deg bet clo eig cor ## 6183 1 0 1.000 0.00000 1 ## 49199 1 0 1.000 0.00000 1 ## 71080 1 0 1.000 0.00000 1 ## 162983 1 0 1.000 0.00000 1 ## 772 3 0 0.333 0.10409 2 ## 907 1 0 1.000 0.00814 1 To fix and to do: Explain metrics and better graphs library(ggplot2) ggplot( metrics, aes(x=bet, y=eig, label=rownames(metrics), colour=res, size=abs(res)) )+ xlab(&quot;Betweenness Centrality&quot;)+ ylab(&quot;Eigenvector Centrality&quot;)+ geom_text() + theme(title=&quot;Key Actor Analysis&quot;) V(g)$label.cex &lt;- 2.2 * V(g)$degree / max(V(g)$degree)+ .2 V(g)$label.color &lt;- rgb(0, 0, .2, .8) V(g)$frame.color &lt;- NA egam &lt;- (log(E(g)$weight)+.4) / max(log(E(g)$weight)+.4) E(g)$color &lt;- rgb(.5, .5, 0, egam) E(g)$width &lt;- egam # plot the graph in layout1 plot(g, layout=layout1) Further information: http://sna.stanford.edu/lab.php?l=1 "],["text-mining-software-engineering-data.html", "Chapter 11 Text Mining Software Engineering Data 11.1 Terminology 11.2 Example of classifying bugs from Bugzilla 11.3 Extracting data from Twitter", " Chapter 11 Text Mining Software Engineering Data In software engineering, there is a lot of information in plain text such as requirements, bug reports, mails, reviews from applicatons, etc. Typically that information can be extracted from Software Configuration Management Systems (SCM), Bug Tracking Systems (BTS) such as Bugzilla or application stores such as Google Play or Apple’s AppStore, etc. can be mined to extract relevant information. Here we briefly explain the text mining process and how this can be done with R. A well-known package for text mining is tm Feinerer, Hornik, and Meyer (2008). Another popular package is wordcloud. 11.1 Terminology The workflow that we follow for analyzing a set of text documents are: Importing data. A Corpus is a collection of text documents, implemented as VCorpus (corpora are R object held in memory). The tm provides several corpus constructors: DirSource, VectorSource, or DataframeSource (getSources()). There are several parameters that control the creation of a Corpus. ((The parameter readerControl of the corpus constructor has to be a list with the named components reader and language)) Preprocessing: in this step we may remove common words, punctuation and we may perform other operations. We may do this operations after creating the DocumentTermMatrix. Inspecting and exploring data: Individual documents can be accessed via [[ Transformations: Transformations are done via the tm_map() function. + tm_map(_____, stripWhitespace) + tm_map(_____, content_transformer(tolower)) + tm_map(_____, removeWords, stopwords(\"english\")) + tm_map(_____, stemDocument) Creating Term-Document Matrices: TermDocumentMatrix and DocumentTermMatrix + A document term matrix is a matrix with documents as the rows and terms as the columns. Each cell of the matrix contains the count of the frequency of words. We use DocumentTermMatrix() to create the matrix. + inspect(DocumentTermMatrix( newsreuters, list(dictionary = c(\"term1\", \"term2\", \"term3\")))). It displays detailed information on a corpus or a term-document matrix. Relationships between terms. + findFreqTerms(_____, anumber) + findAssocs(Mydtm, \"aterm\", anumbercorrelation) + A dictionary is a (multi-)set of strings. It is often used to denote relevant terms in text mining. Clustering and Classification 11.2 Example of classifying bugs from Bugzilla Bugzilla is Issue Tracking System that allow us to follow the evolution of a project. The following example shows how to work with entries from Bugzilla. It is assumed that the data has been extracted and we have the records in a flat file (this can be done using Web crawlers or directly using the SQL database). library(foreign) # path_name &lt;- file.path(&quot;C:&quot;, &quot;datasets&quot;, &quot;textMining&quot;) # path_name # dir(path_name) #Import data options(stringsAsFactors = FALSE) d &lt;- read.arff(&quot;./datasets/textMining/reviewsBugs.arff&quot; ) str(d) #print out information about d ## &#39;data.frame&#39;: 789 obs. of 2 variables: ## $ revContent: chr &quot;Can&#39;t see traffic colors now With latest updates I can&#39;t see the traffic green/red/yellow - I have to pull over&quot;| __truncated__ &quot;Google Map I like it so far, it has not steered me wrong.&quot; &quot;Could be 100X better Google should start listening to customers then they&#39;d actually build a proper product.&quot; &quot;I like that! Easily more helpful than the map app that comes with your phone.&quot; ... ## $ revBug : Factor w/ 2 levels &quot;N&quot;,&quot;Y&quot;: 2 1 1 1 1 1 2 1 2 1 ... head(d,2) # the first two rows of d. ## revContent ## 1 Can&#39;t see traffic colors now With latest updates I can&#39;t see the traffic green/red/yellow - I have to pull over and zoom in the map so that one road fills the entire screen. Traffic checks are (were) the only reason I use google maps! ## 2 Google Map I like it so far, it has not steered me wrong. ## revBug ## 1 Y ## 2 N # fifth entry d$revContent[5] ## [1] &quot;Just deleted No I don&#39;t want to sign in or sign up for anything stop asking&quot; d$revBug[5] ## [1] N ## Levels: N Y Creating a Document-Term Matrix (DTM) Now, we can explore things such as “which words are associated with”feature”?” # which words are associated with &quot;bug&quot;? findAssocs(dtm, &#39;bug&#39;, .3) # minimum correlation of 0.3. Change accordingly. ## $bug ## it? mini major users causing ipad ## 1.00 0.92 0.91 0.80 0.62 0.57 And find frequent terms. findFreqTerms(dtm, 15) #terms that appear 15 or more times, in this case ## [1] &quot;google&quot; &quot;map&quot; &quot;like&quot; &quot;app&quot; &quot;just&quot; &quot;good&quot; ## [7] &quot;crashes&quot; &quot;maps&quot; &quot;time&quot; &quot;get&quot; &quot;much&quot; &quot;really&quot; ## [13] &quot;update&quot; &quot;great&quot; &quot;nice&quot; &quot;best&quot; &quot;ever&quot; &quot;fun&quot; ## [19] &quot;review&quot; &quot;love&quot; &quot;awesome&quot; &quot;cool&quot; &quot;amazing&quot; &quot;game&quot; ## [25] &quot;clans&quot; &quot;clash&quot; &quot;game.&quot; &quot;game!&quot; &quot;addicting&quot; &quot;play&quot; ## [31] &quot;playing&quot; &quot;addictive&quot; Remove some terms sparseparam &lt;- 0.90 # will make the matrix 90% empty space, maximum. Change this, as you like. dtm_sprs &lt;- removeSparseTerms(dtm,sparse=sparseparam) inspect(dtm_sprs) ## &lt;&lt;DocumentTermMatrix (documents: 789, terms: 9)&gt;&gt; ## Non-/sparse entries: 1233/5868 ## Sparsity : 83% ## Maximal term length: 7 ## Weighting : term frequency - inverse document frequency (normalized) (tf-idf) ## Sample : ## Terms ## Docs app awesome best clash fun game good great love ## 159 0 0.00 0 1.6 0 0 0.0 0 1.46 ## 163 0 3.12 0 0.0 0 0 0.0 0 0.00 ## 178 0 3.12 0 0.0 0 0 0.0 0 0.00 ## 400 0 0.00 0 0.0 0 0 3.1 0 0.00 ## 421 0 0.00 0 0.0 0 0 3.1 0 0.00 ## 472 0 0.00 0 0.0 0 0 3.1 0 0.00 ## 50 0 0.00 0 0.0 0 0 3.1 0 0.00 ## 525 0 1.56 0 0.0 0 0 0.0 0 1.46 ## 527 0 0.00 0 0.0 0 0 3.1 0 0.00 ## 532 0 0.00 0 1.6 0 0 0.0 0 1.46 maintitle &lt;-paste0(&quot;Most frequent terms (sparseness=&quot; ,sparseparam , &quot; )&quot;) barplot(as.matrix(dtm_sprs),xlab=&quot;terms&quot;,ylab=&quot;number of occurrences&quot;, main=maintitle) # organize terms by their frequency freq_dtm_sprs &lt;- colSums(as.matrix(dtm_sprs)) length(freq_dtm_sprs) ## [1] 9 sorted_freq_dtm_sprs &lt;- sort(freq_dtm_sprs, decreasing = TRUE) sorted_freq_dtm_sprs ## good great game awesome fun best love clash app ## 77.8 68.8 68.7 64.6 55.8 54.1 45.4 42.5 31.3 Create a data frame that will be the input to the classifier. Last column will be the label. As data frame: #dtmdf &lt;- as.data.frame(dtm.90) #dtmdf &lt;- as.data.frame(inspect(dtm_sprs)) dtmdf &lt;- as.data.frame(as.matrix(dtm_sprs)) # rownames(dtm)&lt;- 1:nrow(dtm) class &lt;- d$revBug dtmdf &lt;- cbind(dtmdf,class) head(dtmdf, 3) Use any classifier now: - split the dataframe into training and testing - Build the classification model using the training subset - apply the model to the testing subset and obtain the Confusion Matrix - Analise the results library(caret) library(randomForest) inTraining &lt;- createDataPartition(dtmdf$class, p = .75, list = FALSE) training &lt;- dtmdf[ inTraining,] testing &lt;- dtmdf[-inTraining,] fitControl &lt;- trainControl(## 5-fold CV method = &quot;repeatedcv&quot;, number = 5, ## repeated ten times repeats = 5) gbmFit1 &lt;- train(class ~ ., data = training, method = &quot;gbm&quot;, trControl = fitControl, ## This last option is actually one ## for gbm() that passes through verbose = FALSE) gbmFit1 ## Stochastic Gradient Boosting ## ## 593 samples ## 9 predictor ## 2 classes: &#39;N&#39;, &#39;Y&#39; ## ## No pre-processing ## Resampling: Cross-Validated (5 fold, repeated 5 times) ## Summary of sample sizes: 475, 474, 474, 474, 475, 475, ... ## Resampling results across tuning parameters: ## ## interaction.depth n.trees Accuracy Kappa ## 1 50 0.798 0.000 ## 1 100 0.801 0.081 ## 1 150 0.806 0.189 ## 2 50 0.805 0.149 ## 2 100 0.802 0.219 ## 2 150 0.798 0.211 ## 3 50 0.806 0.215 ## 3 100 0.802 0.236 ## 3 150 0.801 0.233 ## ## Tuning parameter &#39;shrinkage&#39; was held constant at a value of 0.1 ## ## Tuning parameter &#39;n.minobsinnode&#39; was held constant at a value of 10 ## Accuracy was used to select the optimal model using the largest value. ## The final values used for the model were n.trees = 50, interaction.depth = ## 3, shrinkage = 0.1 and n.minobsinnode = 10. # trellis.par.set(caretTheme()) # plot(gbmFit1) # # trellis.par.set(caretTheme()) # plot(gbmFit1, metric = &quot;Kappa&quot;) head(predict(gbmFit1, testing, type = &quot;prob&quot;)) ## N Y ## 1 0.690 0.3105 ## 2 0.583 0.4166 ## 3 0.690 0.3105 ## 4 0.908 0.0919 ## 5 0.353 0.6472 ## 6 0.690 0.3105 conf_mat &lt;- confusionMatrix(testing$class, predict(gbmFit1, testing)) conf_mat ## Confusion Matrix and Statistics ## ## Reference ## Prediction N Y ## N 152 5 ## Y 27 12 ## ## Accuracy : 0.837 ## 95% CI : (0.777, 0.886) ## No Information Rate : 0.913 ## P-Value [Acc &gt; NIR] : 0.999819 ## ## Kappa : 0.35 ## ## Mcnemar&#39;s Test P-Value : 0.000205 ## ## Sensitivity : 0.849 ## Specificity : 0.706 ## Pos Pred Value : 0.968 ## Neg Pred Value : 0.308 ## Prevalence : 0.913 ## Detection Rate : 0.776 ## Detection Prevalence : 0.801 ## Balanced Accuracy : 0.778 ## ## &#39;Positive&#39; Class : N ## We may compute manually all derived variables from the Confusion Matrix. See Section – with the description of the Confusion Matrix # str(conf_mat) TruePositive &lt;- conf_mat$table[1,1] TruePositive ## [1] 152 FalsePositive &lt;- conf_mat$table[1,2] FalsePositive ## [1] 5 FalseNegative &lt;- conf_mat$table[2,1] FalseNegative ## [1] 27 TrueNegative &lt;- conf_mat$table[2,2] TrueNegative ## [1] 12 # Sum columns in the confusion matrix ConditionPositive &lt;- TruePositive + FalseNegative ConditionNegative &lt;- FalsePositive + TrueNegative TotalPopulation &lt;- ConditionPositive + ConditionNegative TotalPopulation ## [1] 196 #Sum rows in the confusion matrix PredictedPositive &lt;- TruePositive + FalsePositive PredictedNegative &lt;- FalseNegative + TrueNegative # Total Predicted must be equal to the total population PredictedPositive+PredictedNegative ## [1] 196 SensitivityRecall_TPR &lt;- TruePositive / ConditionPositive SensitivityRecall_TPR ## [1] 0.849 Specificity_TNR_SPC &lt;- TrueNegative / ConditionNegative Specificity_TNR_SPC ## [1] 0.706 Precision_PPV &lt;- TruePositive / PredictedPositive Precision_PPV ## [1] 0.968 NegativePredictedValue_NPV &lt;- TrueNegative / PredictedNegative NegativePredictedValue_NPV ## [1] 0.308 Prevalence &lt;- ConditionPositive / TotalPopulation Prevalence ## [1] 0.913 Accuracy_ACC &lt;- (TruePositive + TrueNegative) / TotalPopulation Accuracy_ACC ## [1] 0.837 FalseDiscoveryRate_FDR &lt;- FalsePositive / PredictedPositive FalseDiscoveryRate_FDR ## [1] 0.0318 FalseOmisionRate_FOR &lt;- FalseNegative / PredictedNegative FalseOmisionRate_FOR ## [1] 0.692 FallOut_FPR &lt;- FalsePositive / ConditionNegative FallOut_FPR ## [1] 0.294 MissRate_FNR &lt;- FalseNegative / ConditionPositive MissRate_FNR ## [1] 0.151 And finally, a word cloud as an example that appears everywhere these days. library(wordcloud) # calculate the frequency of words and sort in descending order. wordFreqs=sort(colSums(as.matrix(dtm_sprs)),decreasing=TRUE) wordcloud(words=names(wordFreqs),freq=wordFreqs) 11.3 Extracting data from Twitter The hardest bit is to link with Twitter. Using the TwitteR package is explained following this example. References "],["time-series.html", "Chapter 12 Time Series 12.1 Web tutorials about Time Series:", " Chapter 12 Time Series Many sources of information are time related. For example, data from Software Configuration Management (SCM) such as Git, GitHub) systems or Dashboards such as Metrics Grimoire from Bitergia or SonarQube With MetricsGrimore or SonarQube we can extract datasets or dump of databases. For example, a dashboard for the OpenStack project is located at http://activity.openstack.org/dash/browser/ and provides datasets as MySQL dumps or JSON files. With R we can read a JSON file as follows: library(jsonlite) # Get the JSON data # gm &lt;- fromJSON(&quot;http://activity.openstack.org/dash/browser/data/json/nova.git-scm-rep-evolutionary.json&quot;) gm &lt;- fromJSON(&#39;./datasets/timeSeries/nova.git-scm-rep-evolutionary.json&#39;) str(gm) ## List of 13 ## $ added_lines : num [1:287] 431874 406 577 697 7283 ... ## $ authors : int [1:287] 1 1 4 2 7 5 4 9 8 11 ... ## $ branches : int [1:287] 1 1 1 1 1 1 1 1 1 1 ... ## $ commits : int [1:287] 3 4 16 11 121 38 35 90 66 97 ... ## $ committers : int [1:287] 1 1 4 2 7 5 4 9 8 11 ... ## $ date : chr [1:287] &quot;May 2010&quot; &quot;May 2010&quot; &quot;Jun 2010&quot; &quot;Jun 2010&quot; ... ## $ files : int [1:287] 1878 9 13 7 144 111 28 1900 89 101 ... ## $ id : int [1:287] 0 1 2 3 4 5 6 7 8 9 ... ## $ newauthors : int [1:287] 1 1 2 0 4 1 0 4 2 3 ... ## $ removed_lines: num [1:287] 864 530 187 326 2619 ... ## $ repositories : int [1:287] 1 1 1 1 1 1 1 1 1 1 ... ## $ unixtime : chr [1:287] &quot;1274659200&quot; &quot;1275264000&quot; &quot;1275868800&quot; &quot;1276473600&quot; ... ## $ week : int [1:287] 201021 201022 201023 201024 201025 201026 201027 201028 201029 201030 ... Now we can use time series packages. First, after loading the libraries, we need to create a time series object. # TS libraries library(xts) ## ## Attaching package: &#39;xts&#39; ## The following objects are masked from &#39;package:dplyr&#39;: ## ## first, last library(forecast) # Library to deal with dates library(lubridate) # Ceate a time series object gmts &lt;- xts(gm$commits,seq(ymd(&#39;2010-05-22&#39;),ymd(&#39;2015-11-16&#39;), by = &#39;1 week&#39;)) # TS Object str(gmts) ## An &#39;xts&#39; object on 2010-05-22/2015-11-14 containing: ## Data: int [1:287, 1] 3 4 16 11 121 38 35 90 66 97 ... ## Indexed by objects of class: [Date] TZ: UTC ## xts Attributes: ## NULL head(gmts, 3) ## [,1] ## 2010-05-22 3 ## 2010-05-29 4 ## 2010-06-05 16 Visualise the time series object plot(gmts) Arima model: fit &lt;- auto.arima(gmts) fit ## Series: gmts ## ARIMA(0,1,2) ## ## Coefficients: ## ma1 ma2 ## -0.312 -0.307 ## s.e. 0.058 0.064 ## ## sigma^2 = 1341: log likelihood = -1435 ## AIC=2876 AICc=2876 BIC=2887 forecast(fit, 5) ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## 2010 7.75 -39.2 54.7 -64.0 79.5 ## 2017 15.16 -41.8 72.1 -72.0 102.3 ## 2024 15.16 -44.6 74.9 -76.2 106.5 ## 2031 15.16 -47.2 77.5 -80.2 110.5 ## 2038 15.16 -49.7 80.0 -84.0 114.3 plot(forecast(fit, 5)) 12.1 Web tutorials about Time Series: http://www.statoek.wiso.uni-goettingen.de/veranstaltungen/zeitreihen/sommer03/ts_r_intro.pdf http://www.statmethods.net/advstats/timeseries.html http://a-little-book-of-r-for-time-series.readthedocs.org/en/latest/ https://media.readthedocs.org/pdf/a-little-book-of-r-for-time-series/latest/a-little-book-of-r-for-time-series.pdf http://www.stat.pitt.edu/stoffer/tsa3/ "],["references-1.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
