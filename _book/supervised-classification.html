<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Supervised Classification | Data Analysis in Software Engineering using R</title>
  <meta name="description" content="DASE Data Analysis in Software Engineering" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Supervised Classification | Data Analysis in Software Engineering using R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="DASE Data Analysis in Software Engineering" />
  <meta name="github-repo" content="danrodgar/DASE" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Supervised Classification | Data Analysis in Software Engineering using R" />
  
  <meta name="twitter:description" content="DASE Data Analysis in Software Engineering" />
  

<meta name="author" content="Daniel Rodriguez and Javier Dolado" />


<meta name="date" content="2021-10-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="preprocessing.html"/>
<link rel="next" href="regression.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Analysis in Software Engineering with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="part"><span><b>I Introduction to the R Language</b></span></li>
<li class="chapter" data-level="1" data-path="r-intro.html"><a href="r-intro.html"><i class="fa fa-check"></i><b>1</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="r-intro.html"><a href="r-intro.html#installation"><i class="fa fa-check"></i><b>1.1</b> Installation</a></li>
<li class="chapter" data-level="1.2" data-path="r-intro.html"><a href="r-intro.html#r-and-rstudio"><i class="fa fa-check"></i><b>1.2</b> R and RStudio</a></li>
<li class="chapter" data-level="1.3" data-path="r-intro.html"><a href="r-intro.html#basic-data-types"><i class="fa fa-check"></i><b>1.3</b> Basic Data Types</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="r-intro.html"><a href="r-intro.html#mising-values"><i class="fa fa-check"></i><b>1.3.1</b> Mising values</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="r-intro.html"><a href="r-intro.html#vectors"><i class="fa fa-check"></i><b>1.4</b> Vectors</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="r-intro.html"><a href="r-intro.html#coercion-for-vectors"><i class="fa fa-check"></i><b>1.4.1</b> Coercion for vectors</a></li>
<li class="chapter" data-level="1.4.2" data-path="r-intro.html"><a href="r-intro.html#vector-arithmetic"><i class="fa fa-check"></i><b>1.4.2</b> Vector arithmetic</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="r-intro.html"><a href="r-intro.html#arrays-and-matrices"><i class="fa fa-check"></i><b>1.5</b> Arrays and Matrices</a></li>
<li class="chapter" data-level="1.6" data-path="r-intro.html"><a href="r-intro.html#factors"><i class="fa fa-check"></i><b>1.6</b> Factors</a></li>
<li class="chapter" data-level="1.7" data-path="r-intro.html"><a href="r-intro.html#lists"><i class="fa fa-check"></i><b>1.7</b> Lists</a></li>
<li class="chapter" data-level="1.8" data-path="r-intro.html"><a href="r-intro.html#data-frames"><i class="fa fa-check"></i><b>1.8</b> Data frames</a></li>
<li class="chapter" data-level="1.9" data-path="r-intro.html"><a href="r-intro.html#r---functions-apply-lapply-sapply-tapply-mapply-vapply"><i class="fa fa-check"></i><b>1.9</b> R - Functions <code>apply()</code>, <code>lapply()</code>, <code>sapply()</code>, <code>tapply()</code>, <code>mapply()</code>, <code>vapply()</code></a></li>
<li class="chapter" data-level="1.10" data-path="r-intro.html"><a href="r-intro.html#environments"><i class="fa fa-check"></i><b>1.10</b> Environments</a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="r-intro.html"><a href="r-intro.html#global-variables-local-variables-and-programming-scope"><i class="fa fa-check"></i><b>1.10.1</b> Global variables, local variables and programming scope</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="r-intro.html"><a href="r-intro.html#reading-data"><i class="fa fa-check"></i><b>1.11</b> Reading Data</a></li>
<li class="chapter" data-level="1.12" data-path="r-intro.html"><a href="r-intro.html#plots"><i class="fa fa-check"></i><b>1.12</b> Plots</a></li>
<li class="chapter" data-level="1.13" data-path="r-intro.html"><a href="r-intro.html#flow-of-control"><i class="fa fa-check"></i><b>1.13</b> Flow of Control</a></li>
<li class="chapter" data-level="1.14" data-path="r-intro.html"><a href="r-intro.html#rattle"><i class="fa fa-check"></i><b>1.14</b> Rattle</a></li>
<li class="chapter" data-level="1.15" data-path="r-intro.html"><a href="r-intro.html#datasets"><i class="fa fa-check"></i><b>1.15</b> Datasets</a></li>
</ul></li>
<li class="part"><span><b>II Introduction to Data Mining</b></span></li>
<li class="chapter" data-level="2" data-path="what-is-data-mining-knowledge-discovery-in-databases-kdd.html"><a href="what-is-data-mining-knowledge-discovery-in-databases-kdd.html"><i class="fa fa-check"></i><b>2</b> What is Data Mining / Knowledge Discovery in Databases (KDD)</a>
<ul>
<li class="chapter" data-level="2.1" data-path="what-is-data-mining-knowledge-discovery-in-databases-kdd.html"><a href="what-is-data-mining-knowledge-discovery-in-databases-kdd.html#the-aim-of-data-analysis-and-statistical-learning"><i class="fa fa-check"></i><b>2.1</b> The Aim of Data Analysis and Statistical Learning</a></li>
<li class="chapter" data-level="2.2" data-path="what-is-data-mining-knowledge-discovery-in-databases-kdd.html"><a href="what-is-data-mining-knowledge-discovery-in-databases-kdd.html#data-science"><i class="fa fa-check"></i><b>2.2</b> Data Science</a></li>
<li class="chapter" data-level="2.3" data-path="what-is-data-mining-knowledge-discovery-in-databases-kdd.html"><a href="what-is-data-mining-knowledge-discovery-in-databases-kdd.html#some-references"><i class="fa fa-check"></i><b>2.3</b> Some References</a></li>
<li class="chapter" data-level="2.4" data-path="what-is-data-mining-knowledge-discovery-in-databases-kdd.html"><a href="what-is-data-mining-knowledge-discovery-in-databases-kdd.html#data-mining-and-data-science-with-r"><i class="fa fa-check"></i><b>2.4</b> Data Mining and Data Science with R</a></li>
<li class="chapter" data-level="2.5" data-path="what-is-data-mining-knowledge-discovery-in-databases-kdd.html"><a href="what-is-data-mining-knowledge-discovery-in-databases-kdd.html#data-mining-with-weka"><i class="fa fa-check"></i><b>2.5</b> Data Mining with Weka</a></li>
</ul></li>
<li class="part"><span><b>III Data Sources and Metrics and Standards in Software Engineering Defect Prediction</b></span></li>
<li class="chapter" data-level="3" data-path="data-sources-in-software-engineering.html"><a href="data-sources-in-software-engineering.html"><i class="fa fa-check"></i><b>3</b> Data Sources in Software Engineering</a></li>
<li class="chapter" data-level="4" data-path="repositories.html"><a href="repositories.html"><i class="fa fa-check"></i><b>4</b> Repositories</a></li>
<li class="chapter" data-level="5" data-path="open-toolsdashboards-to-extract-data.html"><a href="open-toolsdashboards-to-extract-data.html"><i class="fa fa-check"></i><b>5</b> Open Tools/Dashboards to extract data</a>
<ul>
<li class="chapter" data-level="5.1" data-path="open-toolsdashboards-to-extract-data.html"><a href="open-toolsdashboards-to-extract-data.html#issues"><i class="fa fa-check"></i><b>5.1</b> Issues</a></li>
<li class="chapter" data-level="5.2" data-path="open-toolsdashboards-to-extract-data.html"><a href="open-toolsdashboards-to-extract-data.html#effort-estimation-data-in-software-engineering"><i class="fa fa-check"></i><b>5.2</b> Effort Estimation Data in Software Engineering</a></li>
</ul></li>
<li class="part"><span><b>IV Exploratory and Descriptive Data analysis</b></span></li>
<li class="chapter" data-level="6" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html"><i class="fa fa-check"></i><b>6</b> Exploratory Data Analysis</a>
<ul>
<li class="chapter" data-level="6.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#descriptive-statistics"><i class="fa fa-check"></i><b>6.1</b> Descriptive statistics</a></li>
<li class="chapter" data-level="6.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#basic-plots"><i class="fa fa-check"></i><b>6.2</b> Basic Plots</a></li>
<li class="chapter" data-level="6.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#normality"><i class="fa fa-check"></i><b>6.3</b> Normality</a></li>
<li class="chapter" data-level="6.4" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#using-a-running-example-to-visualise-the-different-plots"><i class="fa fa-check"></i><b>6.4</b> Using a running Example to visualise the different plots</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#example-with-the-china-dataset"><i class="fa fa-check"></i><b>6.4.1</b> Example with the China dataset</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#correlation"><i class="fa fa-check"></i><b>6.5</b> Correlation</a></li>
<li class="chapter" data-level="6.6" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#confidence-intervals.-bootstrap"><i class="fa fa-check"></i><b>6.6</b> Confidence Intervals. Bootstrap</a></li>
<li class="chapter" data-level="6.7" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#nonparametric-bootstrap"><i class="fa fa-check"></i><b>6.7</b> Nonparametric Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="classical-hypothesis-testing.html"><a href="classical-hypothesis-testing.html"><i class="fa fa-check"></i><b>7</b> Classical Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="7.1" data-path="classical-hypothesis-testing.html"><a href="classical-hypothesis-testing.html#p-values"><i class="fa fa-check"></i><b>7.1</b> p-values</a></li>
</ul></li>
<li class="part"><span><b>V Preprocessing</b></span></li>
<li class="chapter" data-level="8" data-path="preprocessing.html"><a href="preprocessing.html"><i class="fa fa-check"></i><b>8</b> Preprocessing</a>
<ul>
<li class="chapter" data-level="8.1" data-path="preprocessing.html"><a href="preprocessing.html#data"><i class="fa fa-check"></i><b>8.1</b> Data</a></li>
<li class="chapter" data-level="8.2" data-path="preprocessing.html"><a href="preprocessing.html#missing-values"><i class="fa fa-check"></i><b>8.2</b> Missing values</a></li>
<li class="chapter" data-level="8.3" data-path="preprocessing.html"><a href="preprocessing.html#noise"><i class="fa fa-check"></i><b>8.3</b> Noise</a></li>
<li class="chapter" data-level="8.4" data-path="preprocessing.html"><a href="preprocessing.html#outliers"><i class="fa fa-check"></i><b>8.4</b> Outliers</a></li>
<li class="chapter" data-level="8.5" data-path="preprocessing.html"><a href="preprocessing.html#feature-selection"><i class="fa fa-check"></i><b>8.5</b> Feature selection</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="preprocessing.html"><a href="preprocessing.html#fselector-package-in-r"><i class="fa fa-check"></i><b>8.5.1</b> FSelector package in R</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="preprocessing.html"><a href="preprocessing.html#instance-selection"><i class="fa fa-check"></i><b>8.6</b> Instance selection</a></li>
<li class="chapter" data-level="8.7" data-path="preprocessing.html"><a href="preprocessing.html#discretization"><i class="fa fa-check"></i><b>8.7</b> Discretization</a></li>
<li class="chapter" data-level="8.8" data-path="preprocessing.html"><a href="preprocessing.html#correlation-coefficient-and-covariance-for-numeric-data"><i class="fa fa-check"></i><b>8.8</b> Correlation Coefficient and Covariance for Numeric Data</a></li>
<li class="chapter" data-level="8.9" data-path="preprocessing.html"><a href="preprocessing.html#normalization-1"><i class="fa fa-check"></i><b>8.9</b> Normalization</a>
<ul>
<li class="chapter" data-level="8.9.1" data-path="preprocessing.html"><a href="preprocessing.html#min-max-normalization"><i class="fa fa-check"></i><b>8.9.1</b> Min-Max Normalization</a></li>
<li class="chapter" data-level="8.9.2" data-path="preprocessing.html"><a href="preprocessing.html#z-score-normalization"><i class="fa fa-check"></i><b>8.9.2</b> Z-score normalization</a></li>
</ul></li>
<li class="chapter" data-level="8.10" data-path="preprocessing.html"><a href="preprocessing.html#transformations"><i class="fa fa-check"></i><b>8.10</b> Transformations</a>
<ul>
<li class="chapter" data-level="8.10.1" data-path="preprocessing.html"><a href="preprocessing.html#linear-transformations-and-quadratic-trans-formations"><i class="fa fa-check"></i><b>8.10.1</b> Linear Transformations and Quadratic Trans formations</a></li>
<li class="chapter" data-level="8.10.2" data-path="preprocessing.html"><a href="preprocessing.html#box-cox-transformation"><i class="fa fa-check"></i><b>8.10.2</b> Box-cox transformation</a></li>
<li class="chapter" data-level="8.10.3" data-path="preprocessing.html"><a href="preprocessing.html#nominal-to-binary-tranformations"><i class="fa fa-check"></i><b>8.10.3</b> Nominal to Binary tranformations</a></li>
</ul></li>
<li class="chapter" data-level="8.11" data-path="preprocessing.html"><a href="preprocessing.html#preprocessing-in-r"><i class="fa fa-check"></i><b>8.11</b> Preprocessing in R</a>
<ul>
<li class="chapter" data-level="8.11.1" data-path="preprocessing.html"><a href="preprocessing.html#the-dplyr-package"><i class="fa fa-check"></i><b>8.11.1</b> The <code>dplyr</code> package</a></li>
</ul></li>
<li class="chapter" data-level="8.12" data-path="preprocessing.html"><a href="preprocessing.html#other-libraries-and-tricks"><i class="fa fa-check"></i><b>8.12</b> Other libraries and tricks</a></li>
</ul></li>
<li class="part"><span><b>VI Supervised Models</b></span></li>
<li class="chapter" data-level="9" data-path="supervised-classification.html"><a href="supervised-classification.html"><i class="fa fa-check"></i><b>9</b> Supervised Classification</a>
<ul>
<li class="chapter" data-level="9.1" data-path="supervised-classification.html"><a href="supervised-classification.html#classification-trees"><i class="fa fa-check"></i><b>9.1</b> Classification Trees</a></li>
<li class="chapter" data-level="9.2" data-path="supervised-classification.html"><a href="supervised-classification.html#rules"><i class="fa fa-check"></i><b>9.2</b> Rules</a></li>
<li class="chapter" data-level="9.3" data-path="supervised-classification.html"><a href="supervised-classification.html#distanced-based-methods"><i class="fa fa-check"></i><b>9.3</b> Distanced-based Methods</a></li>
<li class="chapter" data-level="9.4" data-path="supervised-classification.html"><a href="supervised-classification.html#neural-networks"><i class="fa fa-check"></i><b>9.4</b> Neural Networks</a></li>
<li class="chapter" data-level="9.5" data-path="supervised-classification.html"><a href="supervised-classification.html#support-vector-machine"><i class="fa fa-check"></i><b>9.5</b> Support Vector Machine</a></li>
<li class="chapter" data-level="9.6" data-path="supervised-classification.html"><a href="supervised-classification.html#probabilistic-methods"><i class="fa fa-check"></i><b>9.6</b> Probabilistic Methods</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="supervised-classification.html"><a href="supervised-classification.html#naive-bayes"><i class="fa fa-check"></i><b>9.6.1</b> Naive Bayes</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="supervised-classification.html"><a href="supervised-classification.html#linear-discriminant-analysis-lda"><i class="fa fa-check"></i><b>9.7</b> Linear Discriminant Analysis (LDA)</a>
<ul>
<li class="chapter" data-level="9.7.1" data-path="supervised-classification.html"><a href="supervised-classification.html#predicting-the-number-of-defects-numerical-class"><i class="fa fa-check"></i><b>9.7.1</b> Predicting the number of defects (numerical class)</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="supervised-classification.html"><a href="supervised-classification.html#binary-logistic-regression-blr"><i class="fa fa-check"></i><b>9.8</b> Binary Logistic Regression (BLR)</a></li>
<li class="chapter" data-level="9.9" data-path="supervised-classification.html"><a href="supervised-classification.html#the-caret-package"><i class="fa fa-check"></i><b>9.9</b> The caret package</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>10</b> Regression</a>
<ul>
<li class="chapter" data-level="10.1" data-path="regression.html"><a href="regression.html#linear-regression-modeling"><i class="fa fa-check"></i><b>10.1</b> Linear Regression modeling</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="regression.html"><a href="regression.html#regression-galton-data"><i class="fa fa-check"></i><b>10.1.1</b> Regression: Galton Data</a></li>
<li class="chapter" data-level="10.1.2" data-path="regression.html"><a href="regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>10.1.2</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="10.1.3" data-path="regression.html"><a href="regression.html#least-squares"><i class="fa fa-check"></i><b>10.1.3</b> Least Squares</a></li>
<li class="chapter" data-level="10.1.4" data-path="regression.html"><a href="regression.html#linear-regression-in-r"><i class="fa fa-check"></i><b>10.1.4</b> Linear regression in R</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="regression.html"><a href="regression.html#linear-regression-diagnostics"><i class="fa fa-check"></i><b>10.2</b> Linear Regression Diagnostics</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="regression.html"><a href="regression.html#simulation-example"><i class="fa fa-check"></i><b>10.2.1</b> Simulation example</a></li>
<li class="chapter" data-level="10.2.2" data-path="regression.html"><a href="regression.html#diagnostics-fro-assessing-the-regression-line"><i class="fa fa-check"></i><b>10.2.2</b> Diagnostics fro assessing the regression line</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="regression.html"><a href="regression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>10.3</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="regression.html"><a href="regression.html#partial-least-squares"><i class="fa fa-check"></i><b>10.3.1</b> Partial Least Squares</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="regression.html"><a href="regression.html#linear-regression-in-software-effort-estimation"><i class="fa fa-check"></i><b>10.4</b> Linear regression in Software Effort estimation</a></li>
<li class="chapter" data-level="10.5" data-path="regression.html"><a href="regression.html#references"><i class="fa fa-check"></i><b>10.5</b> References</a></li>
</ul></li>
<li class="part"><span><b>VII Unsupervised Models</b></span></li>
<li class="chapter" data-level="11" data-path="unsupervised-or-descriptive-modeling.html"><a href="unsupervised-or-descriptive-modeling.html"><i class="fa fa-check"></i><b>11</b> Unsupervised or Descriptive modeling</a>
<ul>
<li class="chapter" data-level="11.1" data-path="unsupervised-or-descriptive-modeling.html"><a href="unsupervised-or-descriptive-modeling.html#clustering"><i class="fa fa-check"></i><b>11.1</b> Clustering</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="unsupervised-or-descriptive-modeling.html"><a href="unsupervised-or-descriptive-modeling.html#k-means"><i class="fa fa-check"></i><b>11.1.1</b> k-Means</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="unsupervised-or-descriptive-modeling.html"><a href="unsupervised-or-descriptive-modeling.html#association-rules"><i class="fa fa-check"></i><b>11.2</b> Association rules</a></li>
</ul></li>
<li class="part"><span><b>VIII Evaluation</b></span></li>
<li class="chapter" data-level="12" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html"><i class="fa fa-check"></i><b>12</b> Evaluation of Models</a>
<ul>
<li class="chapter" data-level="12.1" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#building-and-validating-a-model"><i class="fa fa-check"></i><b>12.1</b> Building and Validating a Model</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#holdout-approach"><i class="fa fa-check"></i><b>12.1.1</b> Holdout approach</a></li>
<li class="chapter" data-level="12.1.2" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#cross-validation-cv"><i class="fa fa-check"></i><b>12.1.2</b> Cross Validation (CV)</a></li>
<li class="chapter" data-level="12.1.3" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#leave-one-out-cross-validation-loo-cv"><i class="fa fa-check"></i><b>12.1.3</b> Leave-One-Out Cross-Validation (LOO-CV)</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#evaluation-of-classification-models"><i class="fa fa-check"></i><b>12.2</b> Evaluation of Classification Models</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#prediction-in-probabilistic-classifiers"><i class="fa fa-check"></i><b>12.2.1</b> Prediction in probabilistic classifiers</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#other-metrics-used-in-software-engineering-with-classification"><i class="fa fa-check"></i><b>12.3</b> Other Metrics used in Software Engineering with Classification</a></li>
<li class="chapter" data-level="12.4" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#graphical-evaluation"><i class="fa fa-check"></i><b>12.4</b> Graphical Evaluation</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#receiver-operating-characteristic-roc"><i class="fa fa-check"></i><b>12.4.1</b> Receiver Operating Characteristic (ROC)</a></li>
<li class="chapter" data-level="12.4.2" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#precision-recall-curve-prc"><i class="fa fa-check"></i><b>12.4.2</b> Precision-Recall Curve (PRC)</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#numeric-prediction-evaluation"><i class="fa fa-check"></i><b>12.5</b> Numeric Prediction Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="evaluationSE.html"><a href="evaluationSE.html"><i class="fa fa-check"></i><b>13</b> Measures of Evaluation in Software Engineering</a>
<ul>
<li class="chapter" data-level="13.1" data-path="evaluationSE.html"><a href="evaluationSE.html#effort-estimation-evaluation-metrics"><i class="fa fa-check"></i><b>13.1</b> Effort estimation evaluation metrics</a></li>
<li class="chapter" data-level="13.2" data-path="evaluationSE.html"><a href="evaluationSE.html#evaluation-of-the-model-in-the-testing-data"><i class="fa fa-check"></i><b>13.2</b> Evaluation of the Model in the Testing data</a></li>
<li class="chapter" data-level="13.3" data-path="evaluationSE.html"><a href="evaluationSE.html#building-a-linear-model-on-the-telecom1-dataset"><i class="fa fa-check"></i><b>13.3</b> Building a Linear Model on the Telecom1 dataset</a></li>
<li class="chapter" data-level="13.4" data-path="evaluationSE.html"><a href="evaluationSE.html#building-a-linear-model-on-the-telecom1-dataset-with-all-observations"><i class="fa fa-check"></i><b>13.4</b> Building a Linear Model on the Telecom1 dataset with all observations</a></li>
<li class="chapter" data-level="13.5" data-path="evaluationSE.html"><a href="evaluationSE.html#standardised-accuracy.-marp0-using-the-china-test-dataset"><i class="fa fa-check"></i><b>13.5</b> Standardised Accuracy. MARP0 using the China Test dataset</a></li>
<li class="chapter" data-level="13.6" data-path="evaluationSE.html"><a href="evaluationSE.html#standardised-accuracy.-marp0-using-the-telecom1-dataset"><i class="fa fa-check"></i><b>13.6</b> Standardised Accuracy. MARP0 using the Telecom1 dataset</a>
<ul>
<li class="chapter" data-level="13.6.1" data-path="evaluationSE.html"><a href="evaluationSE.html#marp0-using-the-atkinson-dataset"><i class="fa fa-check"></i><b>13.6.1</b> MARP0 using the Atkinson dataset</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="evaluationSE.html"><a href="evaluationSE.html#exact-marp0"><i class="fa fa-check"></i><b>13.7</b> Exact MARP0</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="wbl-simple-r-code-to-calculate-shepperd-and-macdonells-marp0-exactly.html"><a href="wbl-simple-r-code-to-calculate-shepperd-and-macdonells-marp0-exactly.html"><i class="fa fa-check"></i><b>14</b> WBL simple R code to calculate Shepperd and MacDonell’s MARP0 exactly</a>
<ul>
<li class="chapter" data-level="14.1" data-path="wbl-simple-r-code-to-calculate-shepperd-and-macdonells-marp0-exactly.html"><a href="wbl-simple-r-code-to-calculate-shepperd-and-macdonells-marp0-exactly.html#computing-the-bootstraped-confidence-interval-of-the-mean-for-the-test-observations-of-the-china-dataset"><i class="fa fa-check"></i><b>14.1</b> Computing the bootstraped confidence interval of the mean for the Test observations of the China dataset:</a></li>
<li class="chapter" data-level="14.2" data-path="wbl-simple-r-code-to-calculate-shepperd-and-macdonells-marp0-exactly.html"><a href="wbl-simple-r-code-to-calculate-shepperd-and-macdonells-marp0-exactly.html#defect-prediction-evaluation-metrics"><i class="fa fa-check"></i><b>14.2</b> Defect prediction evaluation metrics</a></li>
</ul></li>
<li class="part"><span><b>IX Advanced Topics</b></span></li>
<li class="chapter" data-level="15" data-path="feature-selection-1.html"><a href="feature-selection-1.html"><i class="fa fa-check"></i><b>15</b> Feature Selection</a>
<ul>
<li class="chapter" data-level="15.1" data-path="feature-selection-1.html"><a href="feature-selection-1.html#instance-selection-1"><i class="fa fa-check"></i><b>15.1</b> Instance Selection</a></li>
<li class="chapter" data-level="15.2" data-path="feature-selection-1.html"><a href="feature-selection-1.html#missing-data-imputation"><i class="fa fa-check"></i><b>15.2</b> Missing Data Imputation</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="feature-selection-example.html"><a href="feature-selection-example.html"><i class="fa fa-check"></i><b>16</b> Feature Selection Example</a></li>
<li class="chapter" data-level="17" data-path="advanced-models.html"><a href="advanced-models.html"><i class="fa fa-check"></i><b>17</b> Advanced Models</a>
<ul>
<li class="chapter" data-level="17.1" data-path="advanced-models.html"><a href="advanced-models.html#genetic-programming-for-symbolic-regression"><i class="fa fa-check"></i><b>17.1</b> Genetic Programming for Symbolic Regression</a></li>
<li class="chapter" data-level="17.2" data-path="advanced-models.html"><a href="advanced-models.html#genetic-programming-example"><i class="fa fa-check"></i><b>17.2</b> Genetic Programming Example</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="advanced-models.html"><a href="advanced-models.html#load-data"><i class="fa fa-check"></i><b>17.2.1</b> Load Data</a></li>
<li class="chapter" data-level="17.2.2" data-path="advanced-models.html"><a href="advanced-models.html#genetic-programming-for-symbolic-regression-china-dataset."><i class="fa fa-check"></i><b>17.2.2</b> Genetic Programming for Symbolic Regression: China dataset.</a></li>
<li class="chapter" data-level="17.2.3" data-path="advanced-models.html"><a href="advanced-models.html#genetic-programming-for-symbolic-regression.-telecom1-dataset."><i class="fa fa-check"></i><b>17.2.3</b> Genetic Programming for Symbolic Regression. Telecom1 dataset.</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="advanced-models.html"><a href="advanced-models.html#neural-networks-1"><i class="fa fa-check"></i><b>17.3</b> Neural Networks</a></li>
<li class="chapter" data-level="17.4" data-path="advanced-models.html"><a href="advanced-models.html#support-vector-machines"><i class="fa fa-check"></i><b>17.4</b> Support Vector Machines</a></li>
<li class="chapter" data-level="17.5" data-path="advanced-models.html"><a href="advanced-models.html#ensembles"><i class="fa fa-check"></i><b>17.5</b> Ensembles</a>
<ul>
<li class="chapter" data-level="17.5.1" data-path="advanced-models.html"><a href="advanced-models.html#bagging"><i class="fa fa-check"></i><b>17.5.1</b> Bagging</a></li>
<li class="chapter" data-level="17.5.2" data-path="advanced-models.html"><a href="advanced-models.html#boosting"><i class="fa fa-check"></i><b>17.5.2</b> Boosting</a></li>
<li class="chapter" data-level="17.5.3" data-path="advanced-models.html"><a href="advanced-models.html#rotation-forests"><i class="fa fa-check"></i><b>17.5.3</b> Rotation Forests</a></li>
<li class="chapter" data-level="17.5.4" data-path="advanced-models.html"><a href="advanced-models.html#boosting-in-r"><i class="fa fa-check"></i><b>17.5.4</b> Boosting in R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="further-classification-models.html"><a href="further-classification-models.html"><i class="fa fa-check"></i><b>18</b> Further Classification Models</a>
<ul>
<li class="chapter" data-level="18.1" data-path="further-classification-models.html"><a href="further-classification-models.html#multilabel-classification"><i class="fa fa-check"></i><b>18.1</b> Multilabel classification</a></li>
<li class="chapter" data-level="18.2" data-path="further-classification-models.html"><a href="further-classification-models.html#semi-supervised-learning"><i class="fa fa-check"></i><b>18.2</b> Semi-supervised Learning</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="social-network-analysis-in-se.html"><a href="social-network-analysis-in-se.html"><i class="fa fa-check"></i><b>19</b> Social Network Analysis in SE</a></li>
<li class="chapter" data-level="20" data-path="text-mining-software-engineering-data.html"><a href="text-mining-software-engineering-data.html"><i class="fa fa-check"></i><b>20</b> Text Mining Software Engineering Data</a>
<ul>
<li class="chapter" data-level="20.1" data-path="text-mining-software-engineering-data.html"><a href="text-mining-software-engineering-data.html#terminology"><i class="fa fa-check"></i><b>20.1</b> Terminology</a></li>
<li class="chapter" data-level="20.2" data-path="text-mining-software-engineering-data.html"><a href="text-mining-software-engineering-data.html#example-of-classifying-bugs-from-bugzilla"><i class="fa fa-check"></i><b>20.2</b> Example of classifying bugs from Bugzilla</a></li>
<li class="chapter" data-level="20.3" data-path="text-mining-software-engineering-data.html"><a href="text-mining-software-engineering-data.html#extracting-data-from-twitter"><i class="fa fa-check"></i><b>20.3</b> Extracting data from Twitter</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="time-series.html"><a href="time-series.html"><i class="fa fa-check"></i><b>21</b> Time Series</a>
<ul>
<li class="chapter" data-level="21.1" data-path="time-series.html"><a href="time-series.html#web-tutorials-about-time-series"><i class="fa fa-check"></i><b>21.1</b> Web tutorials about Time Series:</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references-1.html"><a href="references-1.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Analysis in Software Engineering using R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="supervised-classification" class="section level1" number="9">
<h1><span class="header-section-number">Chapter 9</span> Supervised Classification</h1>
<p>A classification problem can be defined as the induction, from a dataset <span class="math inline">\(\cal D\)</span>, of a classification function <span class="math inline">\(\psi\)</span> that, given the attribute vector of an instance/example, returns a class <span class="math inline">\({c}\)</span>. A regression problem, on the other hand, returns an numeric value.</p>
<p>Dataset, <span class="math inline">\(\cal D\)</span>, is typically composed of <span class="math inline">\(n\)</span> attributes and a class attribute <span class="math inline">\(C\)</span>.</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(Att_1\)</span></th>
<th>…</th>
<th><span class="math inline">\(Att_n\)</span></th>
<th><span class="math inline">\(Class\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(a_{11}\)</span></td>
<td>…</td>
<td><span class="math inline">\(a_{1n}\)</span></td>
<td><span class="math inline">\(c_1\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(a_{21}\)</span></td>
<td>…</td>
<td><span class="math inline">\(a_{2n}\)</span></td>
<td><span class="math inline">\(c_2\)</span></td>
</tr>
<tr class="odd">
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
<tr class="even">
<td><span class="math inline">\(a_{m1}\)</span></td>
<td>…</td>
<td><span class="math inline">\(a_{mn}\)</span></td>
<td><span class="math inline">\(c_m\)</span></td>
</tr>
</tbody>
</table>
<p>Columns are usually called <em>attributes</em> or <em>features</em>. Typically, there is a <em>class</em> attribute, which can be numeric or discrete. When the class is numeric, it is a regression problem. With discrete values, we can talk about binary classification or multiclass (multinomial classification) when we have more than three values. There are variants such <em>multi-label</em> classification (we will cover these in the advanced models section).</p>
<p>Once we learn a model, new instances are classified. As shown in the next figure.</p>
<div class="figure">
<img src="figures/supervClass1.png" alt="" />
<p class="caption">Supervised Classification</p>
</div>
<p>We have multiple types of models such as <em>classification trees</em>, <em>rules</em>, <em>neural networks</em>, and <em>probabilistic classifiers</em> that can be used to classify instances.</p>
<p>Fernandez et al provide an extensive comparison of 176 classifiers using the UCI dataset <span class="citation">(<a href="#ref-FernandezCBA14" role="doc-biblioref">Fernández-Delgado et al. 2014</a>)</span>.</p>
<p>We will show the use of different classification techniques in the problem of defect prediction as running example. In this example,the different datasets are composed of classical metrics (<em>Halstead</em> or <em>McCabe</em> metrics) based on counts of operators/operands and like or object-oriented metrics (e.g. Chidamber and Kemerer) and the class attribute indicating whether the module or class was defective.</p>
<div id="classification-trees" class="section level2" number="9.1">
<h2><span class="header-section-number">9.1</span> Classification Trees</h2>
<p>There are several packages for inducing classification trees, for example with the <a href="https://cran.r-project.org/web/packages/party/index.html">party package</a> (recursive partitioning):</p>
<div class="sourceCode" id="cb485"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb485-1"><a href="supervised-classification.html#cb485-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(foreign) <span class="co"># To load arff file</span></span>
<span id="cb485-2"><a href="supervised-classification.html#cb485-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(party) <span class="co"># Build a decision tree</span></span>
<span id="cb485-3"><a href="supervised-classification.html#cb485-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret) </span>
<span id="cb485-4"><a href="supervised-classification.html#cb485-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb485-5"><a href="supervised-classification.html#cb485-5" aria-hidden="true" tabindex="-1"></a>jm1 <span class="ot">&lt;-</span> <span class="fu">read.arff</span>(<span class="st">&quot;./datasets/defectPred/D1/JM1.arff&quot;</span>)</span>
<span id="cb485-6"><a href="supervised-classification.html#cb485-6" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(jm1)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    9593 obs. of  22 variables:
##  $ LOC_BLANK            : num  447 37 11 106 101 67 105 18 39 143 ...
##  $ BRANCH_COUNT         : num  826 29 405 240 464 187 344 47 163 67 ...
##  $ LOC_CODE_AND_COMMENT : num  12 8 0 7 11 4 9 0 1 7 ...
##  $ LOC_COMMENTS         : num  157 42 17 344 75 1 40 10 6 49 ...
##  $ CYCLOMATIC_COMPLEXITY: num  470 19 404 127 263 94 207 24 94 34 ...
##  $ DESIGN_COMPLEXITY    : num  385 19 2 105 256 63 171 13 67 25 ...
##  $ ESSENTIAL_COMPLEXITY : num  113 6 1 33 140 27 58 1 3 1 ...
##  $ LOC_EXECUTABLE       : num  2824 133 814 952 1339 ...
##  $ HALSTEAD_CONTENT     : num  210 108 101 218 106 ...
##  $ HALSTEAD_DIFFICULTY  : num  384.4 46.3 206 215.2 337.4 ...
##  $ HALSTEAD_EFFORT      : num  31079782 232044 4294926 10100867 12120796 ...
##  $ HALSTEAD_ERROR_EST   : num  26.95 1.67 6.95 15.65 11.98 ...
##  $ HALSTEAD_LENGTH      : num  8441 685 2033 5669 4308 ...
##  $ HALSTEAD_LEVEL       : num  0 0.02 0 0 0 0.02 0 0.03 0.01 0.02 ...
##  $ HALSTEAD_PROG_TIME   : num  1726655 12891 238607 561159 673378 ...
##  $ HALSTEAD_VOLUME      : num  80843 5009 20848 46944 35928 ...
##  $ NUM_OPERANDS         : num  3021 295 813 2301 1556 ...
##  $ NUM_OPERATORS        : num  5420 390 1220 3368 2752 ...
##  $ NUM_UNIQUE_OPERANDS  : num  609 121 811 262 226 167 279 47 117 355 ...
##  $ NUM_UNIQUE_OPERATORS : num  155 38 411 49 98 27 105 18 52 23 ...
##  $ LOC_TOTAL            : num  3442 222 844 1411 1532 ...
##  $ Defective            : Factor w/ 2 levels &quot;N&quot;,&quot;Y&quot;: 2 2 2 2 2 2 2 2 1 2 ...</code></pre>
<div class="sourceCode" id="cb487"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb487-1"><a href="supervised-classification.html#cb487-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Stratified partition (training and test sets)</span></span>
<span id="cb487-2"><a href="supervised-classification.html#cb487-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb487-3"><a href="supervised-classification.html#cb487-3" aria-hidden="true" tabindex="-1"></a>inTrain <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="at">y=</span>jm1<span class="sc">$</span>Defective,<span class="at">p=</span>.<span class="dv">60</span>,<span class="at">list=</span><span class="cn">FALSE</span>)</span>
<span id="cb487-4"><a href="supervised-classification.html#cb487-4" aria-hidden="true" tabindex="-1"></a>jm1.train <span class="ot">&lt;-</span> jm1[inTrain,]</span>
<span id="cb487-5"><a href="supervised-classification.html#cb487-5" aria-hidden="true" tabindex="-1"></a>jm1.test <span class="ot">&lt;-</span> jm1[<span class="sc">-</span>inTrain,]</span>
<span id="cb487-6"><a href="supervised-classification.html#cb487-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb487-7"><a href="supervised-classification.html#cb487-7" aria-hidden="true" tabindex="-1"></a>jm1.formula <span class="ot">&lt;-</span> jm1<span class="sc">$</span>Defective <span class="sc">~</span> . <span class="co"># formula approach: defect as dependent variable and the rest as independent variables</span></span>
<span id="cb487-8"><a href="supervised-classification.html#cb487-8" aria-hidden="true" tabindex="-1"></a>jm1.ctree <span class="ot">&lt;-</span> <span class="fu">ctree</span>(jm1.formula, <span class="at">data =</span> jm1.train)</span>
<span id="cb487-9"><a href="supervised-classification.html#cb487-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb487-10"><a href="supervised-classification.html#cb487-10" aria-hidden="true" tabindex="-1"></a><span class="co"># predict on test data</span></span>
<span id="cb487-11"><a href="supervised-classification.html#cb487-11" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(jm1.ctree, <span class="at">newdata =</span> jm1.test)</span>
<span id="cb487-12"><a href="supervised-classification.html#cb487-12" aria-hidden="true" tabindex="-1"></a><span class="co"># check prediction result</span></span>
<span id="cb487-13"><a href="supervised-classification.html#cb487-13" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(pred, jm1.test<span class="sc">$</span>Defective)</span></code></pre></div>
<pre><code>##     
## pred    N    Y
##    N  168   11
##    Y 2965  692</code></pre>
<div class="sourceCode" id="cb489"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb489-1"><a href="supervised-classification.html#cb489-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(jm1.ctree)</span></code></pre></div>
<p><img src="DASE_files/figure-html/unnamed-chunk-53-1.png" width="672" /></p>
<p>Using the C50 package, there are two ways, specifying train and testing</p>
<div class="sourceCode" id="cb490"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb490-1"><a href="supervised-classification.html#cb490-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(C50)</span>
<span id="cb490-2"><a href="supervised-classification.html#cb490-2" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(utils)</span>
<span id="cb490-3"><a href="supervised-classification.html#cb490-3" aria-hidden="true" tabindex="-1"></a><span class="co"># c50t &lt;- C5.0(jm1.train[,-ncol(jm1.train)], jm1.train[,ncol(jm1.train)])</span></span>
<span id="cb490-4"><a href="supervised-classification.html#cb490-4" aria-hidden="true" tabindex="-1"></a>c50t <span class="ot">&lt;-</span> <span class="fu">C5.0</span>(Defective <span class="sc">~</span> ., jm1.train)</span>
<span id="cb490-5"><a href="supervised-classification.html#cb490-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(c50t)</span>
<span id="cb490-6"><a href="supervised-classification.html#cb490-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(c50t)</span>
<span id="cb490-7"><a href="supervised-classification.html#cb490-7" aria-hidden="true" tabindex="-1"></a>c50tPred <span class="ot">&lt;-</span> <span class="fu">predict</span>(c50t, jm1.train)</span>
<span id="cb490-8"><a href="supervised-classification.html#cb490-8" aria-hidden="true" tabindex="-1"></a><span class="co"># table(c50tPred, jm1.train$Defective)</span></span></code></pre></div>
<p>Using the <a href="https://cran.r-project.org/web/packages/rpart/index.html">‘rpart’</a> package</p>
<div class="sourceCode" id="cb491"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb491-1"><a href="supervised-classification.html#cb491-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Using the &#39;rpart&#39; package</span></span>
<span id="cb491-2"><a href="supervised-classification.html#cb491-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb491-3"><a href="supervised-classification.html#cb491-3" aria-hidden="true" tabindex="-1"></a>jm1.rpart <span class="ot">&lt;-</span> <span class="fu">rpart</span>(Defective <span class="sc">~</span> ., <span class="at">data=</span>jm1.train, <span class="at">parms =</span> <span class="fu">list</span>(<span class="at">prior =</span> <span class="fu">c</span>(.<span class="dv">65</span>,.<span class="dv">35</span>), <span class="at">split =</span> <span class="st">&quot;information&quot;</span>))</span>
<span id="cb491-4"><a href="supervised-classification.html#cb491-4" aria-hidden="true" tabindex="-1"></a><span class="co"># par(mfrow = c(1,2), xpd = NA)</span></span>
<span id="cb491-5"><a href="supervised-classification.html#cb491-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(jm1.rpart)</span>
<span id="cb491-6"><a href="supervised-classification.html#cb491-6" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(jm1.rpart, <span class="at">use.n =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="DASE_files/figure-html/unnamed-chunk-55-1.png" width="672" /></p>
<div class="sourceCode" id="cb492"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb492-1"><a href="supervised-classification.html#cb492-1" aria-hidden="true" tabindex="-1"></a>jm1.rpart</span></code></pre></div>
<pre><code>## n= 5757 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##  1) root 5757 2010.0 N (0.650 0.350)  
##    2) LOC_TOTAL&lt; 38.5 4172  969.0 N (0.751 0.249) *
##    3) LOC_TOTAL&gt;=38.5 1585  825.0 Y (0.441 0.559)  
##      6) LOC_TOTAL&lt; 87.5 1027  540.0 N (0.523 0.477)  
##       12) LOC_BLANK&lt; 7.5 580  263.0 N (0.572 0.428) *
##       13) LOC_BLANK&gt;=7.5 447  240.0 Y (0.465 0.535)  
##         26) HALSTEAD_DIFFICULTY&gt;=34.9 62   15.3 N (0.738 0.262) *
##         27) HALSTEAD_DIFFICULTY&lt; 34.9 385  197.0 Y (0.430 0.570) *
##      7) LOC_TOTAL&gt;=87.5 558  233.0 Y (0.316 0.684) *</code></pre>
<div class="sourceCode" id="cb494"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb494-1"><a href="supervised-classification.html#cb494-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb494-2"><a href="supervised-classification.html#cb494-2" aria-hidden="true" tabindex="-1"></a><span class="co"># asRules(jm1.rpart)</span></span>
<span id="cb494-3"><a href="supervised-classification.html#cb494-3" aria-hidden="true" tabindex="-1"></a><span class="co"># fancyRpartPlot(jm1.rpart)</span></span></code></pre></div>
</div>
<div id="rules" class="section level2" number="9.2">
<h2><span class="header-section-number">9.2</span> Rules</h2>
<p>C5 Rules</p>
<div class="sourceCode" id="cb495"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb495-1"><a href="supervised-classification.html#cb495-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(C50)</span>
<span id="cb495-2"><a href="supervised-classification.html#cb495-2" aria-hidden="true" tabindex="-1"></a>c50r <span class="ot">&lt;-</span> <span class="fu">C5.0</span>(jm1.train[,<span class="sc">-</span><span class="fu">ncol</span>(jm1.train)], jm1.train[,<span class="fu">ncol</span>(jm1.train)], <span class="at">rules =</span> <span class="cn">TRUE</span>)</span>
<span id="cb495-3"><a href="supervised-classification.html#cb495-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(c50r)</span></code></pre></div>
<pre><code>## 
## Call:
## C5.0.default(x = jm1.train[, -ncol(jm1.train)], y =
##  jm1.train[, ncol(jm1.train)], rules = TRUE)
## 
## 
## C5.0 [Release 2.07 GPL Edition]      Sat Oct  9 17:13:50 2021
## -------------------------------
## 
## Class specified by attribute `outcome&#39;
## 
## Read 5757 cases (22 attributes) from undefined.data
## 
## Rules:
## 
## Rule 1: (5682/1005, lift 1.0)
##  NUM_OPERANDS &lt;= 376
##  -&gt;  class N  [0.823]
## 
## Rule 2: (75/24, lift 3.7)
##  NUM_OPERANDS &gt; 376
##  -&gt;  class Y  [0.675]
## 
## Default class: N
## 
## 
## Evaluation on training data (5757 cases):
## 
##          Rules     
##    ----------------
##      No      Errors
## 
##       2 1029(17.9%)   &lt;&lt;
## 
## 
##     (a)   (b)    &lt;-classified as
##    ----  ----
##    4677    24    (a): class N
##    1005    51    (b): class Y
## 
## 
##  Attribute usage:
## 
##  100.00% NUM_OPERANDS
## 
## 
## Time: 0.1 secs</code></pre>
<div class="sourceCode" id="cb497"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb497-1"><a href="supervised-classification.html#cb497-1" aria-hidden="true" tabindex="-1"></a><span class="co"># c50rPred &lt;- predict(c50r, jm1.train)</span></span>
<span id="cb497-2"><a href="supervised-classification.html#cb497-2" aria-hidden="true" tabindex="-1"></a><span class="co"># table(c50rPred, jm1.train$Defective)</span></span></code></pre></div>
</div>
<div id="distanced-based-methods" class="section level2" number="9.3">
<h2><span class="header-section-number">9.3</span> Distanced-based Methods</h2>
<p>In this case, there is no model as such. Given a new instance to classify, this approach finds the closest <span class="math inline">\(k\)</span>-neighbours to the given instance.</p>
<p><img src="figures/279px-KnnClassification.svg.png" alt="k-NN Classification" />
(Source: Wikipedia - <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm" class="uri">https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm</a>)</p>
<div class="sourceCode" id="cb498"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb498-1"><a href="supervised-classification.html#cb498-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(class)</span>
<span id="cb498-2"><a href="supervised-classification.html#cb498-2" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">knn</span>(<span class="at">train=</span>jm1.train[,<span class="sc">-</span><span class="dv">22</span>], <span class="at">test=</span>jm1.test[,<span class="sc">-</span><span class="dv">22</span>], <span class="at">cl=</span>jm1.train[,<span class="dv">22</span>], <span class="at">k=</span><span class="dv">3</span>)</span>
<span id="cb498-3"><a href="supervised-classification.html#cb498-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb498-4"><a href="supervised-classification.html#cb498-4" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(jm1.test[,<span class="dv">22</span>],m1)</span></code></pre></div>
<pre><code>##    m1
##        N    Y
##   N 2851  282
##   Y  554  149</code></pre>
</div>
<div id="neural-networks" class="section level2" number="9.4">
<h2><span class="header-section-number">9.4</span> Neural Networks</h2>
<div class="figure">
<img src="figures/neuralnet.png" alt="" />
<p class="caption">Neural Networks</p>
</div>
<div class="figure">
<img src="figures/neuralnet2.png" alt="" />
<p class="caption">Neural Networks</p>
</div>
</div>
<div id="support-vector-machine" class="section level2" number="9.5">
<h2><span class="header-section-number">9.5</span> Support Vector Machine</h2>
<p><img src="figures/Kernel_Machine.svg.png" alt="SVM" />
(Source: wikipedia <a href="https://en.wikipedia.org/wiki/Support_vector_machine" class="uri">https://en.wikipedia.org/wiki/Support_vector_machine</a>)</p>
</div>
<div id="probabilistic-methods" class="section level2" number="9.6">
<h2><span class="header-section-number">9.6</span> Probabilistic Methods</h2>
<div id="naive-bayes" class="section level3" number="9.6.1">
<h3><span class="header-section-number">9.6.1</span> Naive Bayes</h3>
<p>Probabilistic graphical model assigning a probability to each possible outcome <span class="math inline">\(p(C_k, x_1,\ldots,x_n)\)</span></p>
<div class="figure">
<img src="figures/classifier_NB.png" alt="" />
<p class="caption">Naive Bayes</p>
</div>
<p>Using the <code>klaR</code> package with <code>caret</code>:</p>
<div class="sourceCode" id="cb500"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb500-1"><a href="supervised-classification.html#cb500-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb500-2"><a href="supervised-classification.html#cb500-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(klaR)</span></code></pre></div>
<pre><code>## Loading required package: MASS</code></pre>
<pre><code>## 
## Attaching package: &#39;MASS&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     select</code></pre>
<pre><code>## The following object is masked from &#39;package:sm&#39;:
## 
##     muscle</code></pre>
<div class="sourceCode" id="cb505"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb505-1"><a href="supervised-classification.html#cb505-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">NaiveBayes</span>(Defective <span class="sc">~</span> ., <span class="at">data =</span> jm1.train)</span>
<span id="cb505-2"><a href="supervised-classification.html#cb505-2" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, jm1.test[,<span class="sc">-</span><span class="dv">22</span>])</span>
<span id="cb505-3"><a href="supervised-classification.html#cb505-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(predictions<span class="sc">$</span>class, jm1.test<span class="sc">$</span>Defective)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    N    Y
##          N 2963  554
##          Y  170  149
##                                         
##                Accuracy : 0.811         
##                  95% CI : (0.799, 0.824)
##     No Information Rate : 0.817         
##     P-Value [Acc &gt; NIR] : 0.815         
##                                         
##                   Kappa : 0.2           
##                                         
##  Mcnemar&#39;s Test P-Value : &lt;2e-16        
##                                         
##             Sensitivity : 0.946         
##             Specificity : 0.212         
##          Pos Pred Value : 0.842         
##          Neg Pred Value : 0.467         
##              Prevalence : 0.817         
##          Detection Rate : 0.772         
##    Detection Prevalence : 0.917         
##       Balanced Accuracy : 0.579         
##                                         
##        &#39;Positive&#39; Class : N             
## </code></pre>
<p>Using the <code>e1071</code> package:</p>
<div class="sourceCode" id="cb507"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb507-1"><a href="supervised-classification.html#cb507-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span> (e1071)</span>
<span id="cb507-2"><a href="supervised-classification.html#cb507-2" aria-hidden="true" tabindex="-1"></a>n1 <span class="ot">&lt;-</span><span class="fu">naiveBayes</span>(jm1.train<span class="sc">$</span>Defective <span class="sc">~</span> ., <span class="at">data=</span>jm1.train)</span>
<span id="cb507-3"><a href="supervised-classification.html#cb507-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb507-4"><a href="supervised-classification.html#cb507-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Show first 3 results using &#39;class&#39;</span></span>
<span id="cb507-5"><a href="supervised-classification.html#cb507-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">predict</span>(n1,jm1.test, <span class="at">type =</span> <span class="fu">c</span>(<span class="st">&quot;class&quot;</span>)),<span class="dv">3</span>) <span class="co"># class by default</span></span></code></pre></div>
<pre><code>## [1] Y Y Y
## Levels: N Y</code></pre>
<div class="sourceCode" id="cb509"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb509-1"><a href="supervised-classification.html#cb509-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show first 3 results using &#39;raw&#39;</span></span>
<span id="cb509-2"><a href="supervised-classification.html#cb509-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">predict</span>(n1,jm1.test, <span class="at">type =</span> <span class="fu">c</span>(<span class="st">&quot;raw&quot;</span>)),<span class="dv">3</span>)</span></code></pre></div>
<pre><code>##            N Y
## [1,] 8.6e-50 1
## [2,] 0.0e+00 1
## [3,] 0.0e+00 1</code></pre>
<p>There are other variants such as TAN and KDB that do not assume the independece condition allowin us more complex structures.</p>
<div class="figure">
<img src="figures/classifier_TAN.png" alt="" />
<p class="caption">Naive Bayes</p>
</div>
<div class="figure">
<img src="figures/classifier_KDB.png" alt="" />
<p class="caption">Naive Bayes</p>
</div>
<p>A comprehensice comparison of</p>
</div>
</div>
<div id="linear-discriminant-analysis-lda" class="section level2" number="9.7">
<h2><span class="header-section-number">9.7</span> Linear Discriminant Analysis (LDA)</h2>
<p>One classical approach to classification is Linear Discriminant Analysis (LDA), a generalization of Fisher’s linear discriminant, as a method used to find a linear combination of features to separate two or more classes.</p>
<div class="sourceCode" id="cb511"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb511-1"><a href="supervised-classification.html#cb511-1" aria-hidden="true" tabindex="-1"></a>ldaModel <span class="ot">&lt;-</span> <span class="fu">train</span> (Defective <span class="sc">~</span> ., <span class="at">data=</span>jm1.train, <span class="at">method=</span><span class="st">&quot;lda&quot;</span>, <span class="at">preProc=</span><span class="fu">c</span>(<span class="st">&quot;center&quot;</span>,<span class="st">&quot;scale&quot;</span>))</span>
<span id="cb511-2"><a href="supervised-classification.html#cb511-2" aria-hidden="true" tabindex="-1"></a>ldaModel</span></code></pre></div>
<pre><code>## Linear Discriminant Analysis 
## 
## 5757 samples
##   21 predictor
##    2 classes: &#39;N&#39;, &#39;Y&#39; 
## 
## Pre-processing: centered (21), scaled (21) 
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 5757, 5757, 5757, 5757, 5757, 5757, ... 
## Resampling results:
## 
##   Accuracy  Kappa
##   0.82      0.164</code></pre>
<p>We can observe that we are training our model using <code>Defective ~ .</code> as a formula were <code>Defective</code> is the class variable separed by <code>~</code> and the ´.´ means the rest of the variables. Also, we are using a filter for the training data to (preProc) to center and scale.</p>
<p>Also, as stated in the documentation about the <code>train</code> method :
&gt; <a href="http://topepo.github.io/caret/training.html" class="uri">http://topepo.github.io/caret/training.html</a></p>
<div class="sourceCode" id="cb513"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb513-1"><a href="supervised-classification.html#cb513-1" aria-hidden="true" tabindex="-1"></a>ctrl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;repeatedcv&quot;</span>,<span class="at">repeats=</span><span class="dv">3</span>)</span>
<span id="cb513-2"><a href="supervised-classification.html#cb513-2" aria-hidden="true" tabindex="-1"></a>ldaModel <span class="ot">&lt;-</span> <span class="fu">train</span> (Defective <span class="sc">~</span> ., <span class="at">data=</span>jm1.train, <span class="at">method=</span><span class="st">&quot;lda&quot;</span>, <span class="at">trControl=</span>ctrl, <span class="at">preProc=</span><span class="fu">c</span>(<span class="st">&quot;center&quot;</span>,<span class="st">&quot;scale&quot;</span>))</span>
<span id="cb513-3"><a href="supervised-classification.html#cb513-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb513-4"><a href="supervised-classification.html#cb513-4" aria-hidden="true" tabindex="-1"></a>ldaModel</span></code></pre></div>
<pre><code>## Linear Discriminant Analysis 
## 
## 5757 samples
##   21 predictor
##    2 classes: &#39;N&#39;, &#39;Y&#39; 
## 
## Pre-processing: centered (21), scaled (21) 
## Resampling: Cross-Validated (10 fold, repeated 3 times) 
## Summary of sample sizes: 5181, 5182, 5181, 5182, 5180, 5181, ... 
## Resampling results:
## 
##   Accuracy  Kappa
##   0.82      0.159</code></pre>
<p>Instead of accuracy we can activate other metrics using <code>summaryFunction=twoClassSummary</code> such as <code>ROC</code>, <code>sensitivity</code> and <code>specificity</code>. To do so, we also need to speficy <code>classProbs=TRUE</code>.</p>
<div class="sourceCode" id="cb515"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb515-1"><a href="supervised-classification.html#cb515-1" aria-hidden="true" tabindex="-1"></a>ctrl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;repeatedcv&quot;</span>,<span class="at">repeats=</span><span class="dv">3</span>, <span class="at">classProbs=</span><span class="cn">TRUE</span>, <span class="at">summaryFunction=</span>twoClassSummary)</span>
<span id="cb515-2"><a href="supervised-classification.html#cb515-2" aria-hidden="true" tabindex="-1"></a>ldaModel3xcv10 <span class="ot">&lt;-</span> <span class="fu">train</span> (Defective <span class="sc">~</span> ., <span class="at">data=</span>jm1.train, <span class="at">method=</span><span class="st">&quot;lda&quot;</span>, <span class="at">trControl=</span>ctrl, <span class="at">preProc=</span><span class="fu">c</span>(<span class="st">&quot;center&quot;</span>,<span class="st">&quot;scale&quot;</span>))</span>
<span id="cb515-3"><a href="supervised-classification.html#cb515-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb515-4"><a href="supervised-classification.html#cb515-4" aria-hidden="true" tabindex="-1"></a>ldaModel3xcv10</span></code></pre></div>
<pre><code>## Linear Discriminant Analysis 
## 
## 5757 samples
##   21 predictor
##    2 classes: &#39;N&#39;, &#39;Y&#39; 
## 
## Pre-processing: centered (21), scaled (21) 
## Resampling: Cross-Validated (10 fold, repeated 3 times) 
## Summary of sample sizes: 5181, 5181, 5181, 5182, 5182, 5181, ... 
## Resampling results:
## 
##   ROC    Sens   Spec 
##   0.708  0.971  0.143</code></pre>
<p>Most methods have parameters that need to be optimised and that is one of the</p>
<div class="sourceCode" id="cb517"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb517-1"><a href="supervised-classification.html#cb517-1" aria-hidden="true" tabindex="-1"></a>plsFit3x10cv <span class="ot">&lt;-</span> <span class="fu">train</span> (Defective <span class="sc">~</span> ., <span class="at">data=</span>jm1.train, <span class="at">method=</span><span class="st">&quot;pls&quot;</span>, <span class="at">trControl=</span><span class="fu">trainControl</span>(<span class="at">classProbs=</span><span class="cn">TRUE</span>), <span class="at">metric=</span><span class="st">&quot;ROC&quot;</span>, <span class="at">preProc=</span><span class="fu">c</span>(<span class="st">&quot;center&quot;</span>,<span class="st">&quot;scale&quot;</span>))</span>
<span id="cb517-2"><a href="supervised-classification.html#cb517-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb517-3"><a href="supervised-classification.html#cb517-3" aria-hidden="true" tabindex="-1"></a>plsFit3x10cv</span></code></pre></div>
<pre><code>## Partial Least Squares 
## 
## 5757 samples
##   21 predictor
##    2 classes: &#39;N&#39;, &#39;Y&#39; 
## 
## Pre-processing: centered (21), scaled (21) 
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 5757, 5757, 5757, 5757, 5757, 5757, ... 
## Resampling results across tuning parameters:
## 
##   ncomp  Accuracy  Kappa 
##   1      0.821     0.0620
##   2      0.821     0.0978
##   3      0.821     0.0992
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was ncomp = 3.</code></pre>
<div class="sourceCode" id="cb519"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb519-1"><a href="supervised-classification.html#cb519-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(plsFit3x10cv)</span></code></pre></div>
<p><img src="DASE_files/figure-html/unnamed-chunk-63-1.png" width="672" /></p>
<p>The parameter <code>tuneLength</code> allow us to specify the number values per parameter to consider.</p>
<div class="sourceCode" id="cb520"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb520-1"><a href="supervised-classification.html#cb520-1" aria-hidden="true" tabindex="-1"></a>plsFit3x10cv <span class="ot">&lt;-</span> <span class="fu">train</span> (Defective <span class="sc">~</span> ., <span class="at">data=</span>jm1.train, <span class="at">method=</span><span class="st">&quot;pls&quot;</span>, <span class="at">trControl=</span>ctrl, <span class="at">metric=</span><span class="st">&quot;ROC&quot;</span>, <span class="at">tuneLength=</span><span class="dv">5</span>, <span class="at">preProc=</span><span class="fu">c</span>(<span class="st">&quot;center&quot;</span>,<span class="st">&quot;scale&quot;</span>))</span>
<span id="cb520-2"><a href="supervised-classification.html#cb520-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb520-3"><a href="supervised-classification.html#cb520-3" aria-hidden="true" tabindex="-1"></a>plsFit3x10cv</span></code></pre></div>
<pre><code>## Partial Least Squares 
## 
## 5757 samples
##   21 predictor
##    2 classes: &#39;N&#39;, &#39;Y&#39; 
## 
## Pre-processing: centered (21), scaled (21) 
## Resampling: Cross-Validated (10 fold, repeated 3 times) 
## Summary of sample sizes: 5181, 5182, 5181, 5182, 5181, 5182, ... 
## Resampling results across tuning parameters:
## 
##   ncomp  ROC    Sens   Spec  
##   1      0.700  0.996  0.0429
##   2      0.703  0.989  0.0710
##   3      0.706  0.990  0.0720
##   4      0.708  0.990  0.0808
##   5      0.708  0.990  0.0808
## 
## ROC was used to select the optimal model using the largest value.
## The final value used for the model was ncomp = 5.</code></pre>
<div class="sourceCode" id="cb522"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb522-1"><a href="supervised-classification.html#cb522-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(plsFit3x10cv)</span></code></pre></div>
<p><img src="DASE_files/figure-html/unnamed-chunk-64-1.png" width="672" /></p>
<p>Finally to predict new cases, <code>caret</code> will use the best classfier obtained for prediction.</p>
<div class="sourceCode" id="cb523"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb523-1"><a href="supervised-classification.html#cb523-1" aria-hidden="true" tabindex="-1"></a>plsProbs <span class="ot">&lt;-</span> <span class="fu">predict</span>(plsFit3x10cv, <span class="at">newdata =</span> jm1.test, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb524"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb524-1"><a href="supervised-classification.html#cb524-1" aria-hidden="true" tabindex="-1"></a>plsClasses <span class="ot">&lt;-</span> <span class="fu">predict</span>(plsFit3x10cv, <span class="at">newdata =</span> jm1.test, <span class="at">type =</span> <span class="st">&quot;raw&quot;</span>)</span>
<span id="cb524-2"><a href="supervised-classification.html#cb524-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span>plsClasses,jm1.test<span class="sc">$</span>Defective)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    N    Y
##          N 3094  652
##          Y   39   51
##                                         
##                Accuracy : 0.82          
##                  95% CI : (0.807, 0.832)
##     No Information Rate : 0.817         
##     P-Value [Acc &gt; NIR] : 0.317         
##                                         
##                   Kappa : 0.091         
##                                         
##  Mcnemar&#39;s Test P-Value : &lt;2e-16        
##                                         
##             Sensitivity : 0.9876        
##             Specificity : 0.0725        
##          Pos Pred Value : 0.8259        
##          Neg Pred Value : 0.5667        
##              Prevalence : 0.8167        
##          Detection Rate : 0.8066        
##    Detection Prevalence : 0.9765        
##       Balanced Accuracy : 0.5300        
##                                         
##        &#39;Positive&#39; Class : N             
## </code></pre>
<div id="predicting-the-number-of-defects-numerical-class" class="section level3" number="9.7.1">
<h3><span class="header-section-number">9.7.1</span> Predicting the number of defects (numerical class)</h3>
<p>From the Bug Prediction Repository (BPR) <a href="http://bug.inf.usi.ch/download.php">http://bug.inf.usi.ch/download.php</a></p>
<p>Some datasets contain CK and other 11 object-oriented metrics for the last version of the system plus categorized (with severity and priority) post-release defects. Using such dataset:</p>
<div class="sourceCode" id="cb526"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb526-1"><a href="supervised-classification.html#cb526-1" aria-hidden="true" tabindex="-1"></a>jdt <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;./datasets/defectPred/BPD/single-version-ck-oo-EclipseJDTCore.csv&quot;</span>, <span class="at">sep=</span><span class="st">&quot;;&quot;</span>)</span>
<span id="cb526-2"><a href="supervised-classification.html#cb526-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb526-3"><a href="supervised-classification.html#cb526-3" aria-hidden="true" tabindex="-1"></a><span class="co"># We just use the number of bugs, so we removed others</span></span>
<span id="cb526-4"><a href="supervised-classification.html#cb526-4" aria-hidden="true" tabindex="-1"></a>jdt<span class="sc">$</span>classname <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb526-5"><a href="supervised-classification.html#cb526-5" aria-hidden="true" tabindex="-1"></a>jdt<span class="sc">$</span>nonTrivialBugs <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb526-6"><a href="supervised-classification.html#cb526-6" aria-hidden="true" tabindex="-1"></a>jdt<span class="sc">$</span>majorBugs <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb526-7"><a href="supervised-classification.html#cb526-7" aria-hidden="true" tabindex="-1"></a>jdt<span class="sc">$</span>minorBugs <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb526-8"><a href="supervised-classification.html#cb526-8" aria-hidden="true" tabindex="-1"></a>jdt<span class="sc">$</span>criticalBugs <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb526-9"><a href="supervised-classification.html#cb526-9" aria-hidden="true" tabindex="-1"></a>jdt<span class="sc">$</span>highPriorityBugs <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb526-10"><a href="supervised-classification.html#cb526-10" aria-hidden="true" tabindex="-1"></a>jdt<span class="sc">$</span>X <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb526-11"><a href="supervised-classification.html#cb526-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb526-12"><a href="supervised-classification.html#cb526-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Caret</span></span>
<span id="cb526-13"><a href="supervised-classification.html#cb526-13" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb526-14"><a href="supervised-classification.html#cb526-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb526-15"><a href="supervised-classification.html#cb526-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Split data into training and test datasets</span></span>
<span id="cb526-16"><a href="supervised-classification.html#cb526-16" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb526-17"><a href="supervised-classification.html#cb526-17" aria-hidden="true" tabindex="-1"></a>inTrain <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="at">y=</span>jdt<span class="sc">$</span>bugs,<span class="at">p=</span>.<span class="dv">8</span>,<span class="at">list=</span><span class="cn">FALSE</span>)</span>
<span id="cb526-18"><a href="supervised-classification.html#cb526-18" aria-hidden="true" tabindex="-1"></a>jdt.train <span class="ot">&lt;-</span> jdt[inTrain,]</span>
<span id="cb526-19"><a href="supervised-classification.html#cb526-19" aria-hidden="true" tabindex="-1"></a>jdt.test <span class="ot">&lt;-</span> jdt[<span class="sc">-</span>inTrain,]</span></code></pre></div>
<div class="sourceCode" id="cb527"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb527-1"><a href="supervised-classification.html#cb527-1" aria-hidden="true" tabindex="-1"></a>ctrl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;repeatedcv&quot;</span>,<span class="at">repeats=</span><span class="dv">3</span>)</span>
<span id="cb527-2"><a href="supervised-classification.html#cb527-2" aria-hidden="true" tabindex="-1"></a>glmModel <span class="ot">&lt;-</span> <span class="fu">train</span> (bugs <span class="sc">~</span> ., <span class="at">data=</span>jdt.train, <span class="at">method=</span><span class="st">&quot;glm&quot;</span>, <span class="at">trControl=</span>ctrl, <span class="at">preProc=</span><span class="fu">c</span>(<span class="st">&quot;center&quot;</span>,<span class="st">&quot;scale&quot;</span>))</span>
<span id="cb527-3"><a href="supervised-classification.html#cb527-3" aria-hidden="true" tabindex="-1"></a>glmModel</span></code></pre></div>
<pre><code>## Generalized Linear Model 
## 
## 798 samples
##  17 predictor
## 
## Pre-processing: centered (17), scaled (17) 
## Resampling: Cross-Validated (10 fold, repeated 3 times) 
## Summary of sample sizes: 719, 718, 718, 718, 718, 718, ... 
## Resampling results:
## 
##   RMSE   Rsquared  MAE  
##   0.936  0.273     0.442</code></pre>
<p>Others such as Elasticnet:</p>
<div class="sourceCode" id="cb529"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb529-1"><a href="supervised-classification.html#cb529-1" aria-hidden="true" tabindex="-1"></a>glmnetModel <span class="ot">&lt;-</span> <span class="fu">train</span> (bugs <span class="sc">~</span> ., <span class="at">data=</span>jdt.train, <span class="at">method=</span><span class="st">&quot;glmnet&quot;</span>, <span class="at">trControl=</span>ctrl, <span class="at">preProc=</span><span class="fu">c</span>(<span class="st">&quot;center&quot;</span>,<span class="st">&quot;scale&quot;</span>))</span>
<span id="cb529-2"><a href="supervised-classification.html#cb529-2" aria-hidden="true" tabindex="-1"></a>glmnetModel</span></code></pre></div>
<pre><code>## glmnet 
## 
## 798 samples
##  17 predictor
## 
## Pre-processing: centered (17), scaled (17) 
## Resampling: Cross-Validated (10 fold, repeated 3 times) 
## Summary of sample sizes: 718, 718, 718, 718, 718, 718, ... 
## Resampling results across tuning parameters:
## 
##   alpha  lambda   RMSE   Rsquared  MAE  
##   0.10   0.00112  1.004  0.249     0.458
##   0.10   0.01120  0.938  0.247     0.447
##   0.10   0.11195  0.840  0.272     0.430
##   0.55   0.00112  1.006  0.249     0.458
##   0.55   0.01120  0.918  0.249     0.444
##   0.55   0.11195  0.825  0.286     0.433
##   1.00   0.00112  1.008  0.248     0.458
##   1.00   0.01120  0.902  0.252     0.442
##   1.00   0.11195  0.831  0.282     0.446
## 
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were alpha = 0.55 and lambda = 0.112.</code></pre>
</div>
</div>
<div id="binary-logistic-regression-blr" class="section level2" number="9.8">
<h2><span class="header-section-number">9.8</span> Binary Logistic Regression (BLR)</h2>
<p>Binary Logistic Regression (BLR) can models fault-proneness as follows</p>
<p><span class="math display">\[fp(X) = \frac{e^{logit()}}{1 + e^{logit(X)}}\]</span></p>
<p>where the simplest form for logit is:</p>
<p><span class="math inline">\(logit(X) = c_{0} + c_{1}X\)</span></p>
<div class="sourceCode" id="cb531"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb531-1"><a href="supervised-classification.html#cb531-1" aria-hidden="true" tabindex="-1"></a>jdt <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;./datasets/defectPred/BPD/single-version-ck-oo-EclipseJDTCore.csv&quot;</span>, <span class="at">sep=</span><span class="st">&quot;;&quot;</span>)</span>
<span id="cb531-2"><a href="supervised-classification.html#cb531-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb531-3"><a href="supervised-classification.html#cb531-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Caret</span></span>
<span id="cb531-4"><a href="supervised-classification.html#cb531-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb531-5"><a href="supervised-classification.html#cb531-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb531-6"><a href="supervised-classification.html#cb531-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the response variable into a boolean variable (0/1)</span></span>
<span id="cb531-7"><a href="supervised-classification.html#cb531-7" aria-hidden="true" tabindex="-1"></a>jdt<span class="sc">$</span>bugs[jdt<span class="sc">$</span>bugs<span class="sc">&gt;=</span><span class="dv">1</span>]<span class="ot">&lt;-</span><span class="dv">1</span></span>
<span id="cb531-8"><a href="supervised-classification.html#cb531-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb531-9"><a href="supervised-classification.html#cb531-9" aria-hidden="true" tabindex="-1"></a>cbo <span class="ot">&lt;-</span> jdt<span class="sc">$</span>cbo</span>
<span id="cb531-10"><a href="supervised-classification.html#cb531-10" aria-hidden="true" tabindex="-1"></a>bugs <span class="ot">&lt;-</span> jdt<span class="sc">$</span>bugs</span>
<span id="cb531-11"><a href="supervised-classification.html#cb531-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb531-12"><a href="supervised-classification.html#cb531-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Split data into training and test datasets</span></span>
<span id="cb531-13"><a href="supervised-classification.html#cb531-13" aria-hidden="true" tabindex="-1"></a>jdt2 <span class="ot">=</span> <span class="fu">data.frame</span>(cbo, bugs)</span>
<span id="cb531-14"><a href="supervised-classification.html#cb531-14" aria-hidden="true" tabindex="-1"></a>inTrain <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="at">y=</span>jdt2<span class="sc">$</span>bugs,<span class="at">p=</span>.<span class="dv">8</span>,<span class="at">list=</span><span class="cn">FALSE</span>)</span>
<span id="cb531-15"><a href="supervised-classification.html#cb531-15" aria-hidden="true" tabindex="-1"></a>jdtTrain <span class="ot">&lt;-</span> jdt2[inTrain,]</span>
<span id="cb531-16"><a href="supervised-classification.html#cb531-16" aria-hidden="true" tabindex="-1"></a>jdtTest <span class="ot">&lt;-</span> jdt2[<span class="sc">-</span>inTrain,]</span></code></pre></div>
<p>BLR models fault-proneness are as follows <span class="math inline">\(fp(X) = \frac{e^{logit()}}{1 + e^{logit(X)}}\)</span></p>
<p>where the simplest form for logit is <span class="math inline">\(logit(X) = c_{0} + c_{1}X\)</span></p>
<div class="sourceCode" id="cb532"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb532-1"><a href="supervised-classification.html#cb532-1" aria-hidden="true" tabindex="-1"></a><span class="co"># logit regression</span></span>
<span id="cb532-2"><a href="supervised-classification.html#cb532-2" aria-hidden="true" tabindex="-1"></a><span class="co"># glmLogit &lt;- train (bugs ~ ., data=jdt.train, method=&quot;glm&quot;, family=binomial(link = logit))       </span></span>
<span id="cb532-3"><a href="supervised-classification.html#cb532-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb532-4"><a href="supervised-classification.html#cb532-4" aria-hidden="true" tabindex="-1"></a>glmLogit <span class="ot">&lt;-</span> <span class="fu">glm</span> (bugs <span class="sc">~</span> ., <span class="at">data=</span>jdtTrain, <span class="at">family=</span><span class="fu">binomial</span>(<span class="at">link =</span> logit))</span>
<span id="cb532-5"><a href="supervised-classification.html#cb532-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(glmLogit)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = bugs ~ ., family = binomial(link = logit), data = jdtTrain)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -3.654  -0.591  -0.515  -0.471   2.150  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -2.20649    0.13900  -15.87   &lt;2e-16 ***
## cbo          0.06298    0.00765    8.23   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 807.98  on 797  degrees of freedom
## Residual deviance: 691.80  on 796  degrees of freedom
## AIC: 695.8
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>Predict a single point:</p>
<div class="sourceCode" id="cb534"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb534-1"><a href="supervised-classification.html#cb534-1" aria-hidden="true" tabindex="-1"></a>newData <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="at">cbo =</span> <span class="dv">3</span>)</span>
<span id="cb534-2"><a href="supervised-classification.html#cb534-2" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(glmLogit, newData, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>##     1 
## 0.117</code></pre>
<p>Draw the results, modified from:
<a href="http://www.shizukalab.com/toolkits/plotting-logistic-regression-in-r" class="uri">http://www.shizukalab.com/toolkits/plotting-logistic-regression-in-r</a></p>
<div class="sourceCode" id="cb536"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb536-1"><a href="supervised-classification.html#cb536-1" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">predict</span>(glmLogit, jdtTest, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb536-2"><a href="supervised-classification.html#cb536-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb536-3"><a href="supervised-classification.html#cb536-3" aria-hidden="true" tabindex="-1"></a><span class="fu">range</span>(jdtTrain<span class="sc">$</span>cbo)</span></code></pre></div>
<pre><code>## [1]   0 156</code></pre>
<div class="sourceCode" id="cb538"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb538-1"><a href="supervised-classification.html#cb538-1" aria-hidden="true" tabindex="-1"></a><span class="fu">range</span>(results)</span></code></pre></div>
<pre><code>## [1] 0.0992 0.9993</code></pre>
<div class="sourceCode" id="cb540"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb540-1"><a href="supervised-classification.html#cb540-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(jdt2<span class="sc">$</span>cbo,jdt2<span class="sc">$</span>bugs)</span>
<span id="cb540-2"><a href="supervised-classification.html#cb540-2" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">predict</span>(glmLogit, <span class="fu">data.frame</span>(<span class="at">cbo=</span>x), <span class="at">type =</span> <span class="st">&quot;response&quot;</span>),<span class="at">add=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="DASE_files/figure-html/unnamed-chunk-73-1.png" width="672" /></p>
<div class="sourceCode" id="cb541"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb541-1"><a href="supervised-classification.html#cb541-1" aria-hidden="true" tabindex="-1"></a><span class="co"># points(jdtTrain$cbo,fitted(glmLogit))</span></span></code></pre></div>
<p>Another type of graph:</p>
<div class="sourceCode" id="cb542"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb542-1"><a href="supervised-classification.html#cb542-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(popbio)</span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;popbio&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:caret&#39;:
## 
##     sensitivity</code></pre>
<div class="sourceCode" id="cb545"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb545-1"><a href="supervised-classification.html#cb545-1" aria-hidden="true" tabindex="-1"></a><span class="fu">logi.hist.plot</span>(jdt2<span class="sc">$</span>cbo,jdt2<span class="sc">$</span>bugs,<span class="at">boxp=</span><span class="cn">FALSE</span>,<span class="at">type=</span><span class="st">&quot;hist&quot;</span>,<span class="at">col=</span><span class="st">&quot;gray&quot;</span>)</span></code></pre></div>
<p><img src="DASE_files/figure-html/unnamed-chunk-74-1.png" width="672" /></p>
</div>
<div id="the-caret-package" class="section level2" number="9.9">
<h2><span class="header-section-number">9.9</span> The caret package</h2>
<p>There are hundreds of packages to perform classification task in R, but many of those can be used throught the ‘caret’ package which helps with many of the data mining process task as described next.</p>
<p>The caret package<a href="http://topepo.github.io/caret/">http://topepo.github.io/caret/</a> provides a unified interface for modeling and prediction with around 150 different models with tools for:</p>
<ul>
<li><p>data splitting</p></li>
<li><p>pre-processing</p></li>
<li><p>feature selection</p></li>
<li><p>model tuning using resampling</p></li>
<li><p>variable importance estimation, etc.</p></li>
</ul>
<p>Website: <a href="http://caret.r-forge.r-project.org">http://caret.r-forge.r-project.org</a></p>
<p>JSS Paper: <a href="www.jstatsoft.org/v28/i05/paper">www.jstatsoft.org/v28/i05/paper</a></p>
<p>Book: <a href="http://AppliedPredictiveModeling.com/">Applied Predictive Modeling</a></p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-FernandezCBA14" class="csl-entry">
Fernández-Delgado, Manuel, Eva Cernadas, Senén Barro, and Dinani Amorim. 2014. <span>“Do We Need Hundreds of Classifiers to Solve Real World Classification Problems?”</span> <em>Journal of Machine Learning Research</em> 15: 3133–81. <a href="http://jmlr.org/papers/v15/delgado14a.html">http://jmlr.org/papers/v15/delgado14a.html</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="preprocessing.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/danrodgar/dasedown/edit/master/400_basicModelBuildingSupervised.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["DASE.pdf", "DASE.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
