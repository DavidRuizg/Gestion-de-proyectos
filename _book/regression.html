<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 10 Regression | Data Analysis in Software Engineering using R</title>
  <meta name="description" content="DASE Data Analysis in Software Engineering" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 10 Regression | Data Analysis in Software Engineering using R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="DASE Data Analysis in Software Engineering" />
  <meta name="github-repo" content="danrodgar/DASE" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 10 Regression | Data Analysis in Software Engineering using R" />
  
  <meta name="twitter:description" content="DASE Data Analysis in Software Engineering" />
  

<meta name="author" content="Daniel Rodriguez and Javier Dolado" />


<meta name="date" content="2021-10-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="supervised-classification.html"/>
<link rel="next" href="unsupervised-or-descriptive-modeling.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Analysis in Software Engineering with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="part"><span><b>I Introduction to the R Language</b></span></li>
<li class="chapter" data-level="1" data-path="r-intro.html"><a href="r-intro.html"><i class="fa fa-check"></i><b>1</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="r-intro.html"><a href="r-intro.html#installation"><i class="fa fa-check"></i><b>1.1</b> Installation</a></li>
<li class="chapter" data-level="1.2" data-path="r-intro.html"><a href="r-intro.html#r-and-rstudio"><i class="fa fa-check"></i><b>1.2</b> R and RStudio</a></li>
<li class="chapter" data-level="1.3" data-path="r-intro.html"><a href="r-intro.html#basic-data-types"><i class="fa fa-check"></i><b>1.3</b> Basic Data Types</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="r-intro.html"><a href="r-intro.html#mising-values"><i class="fa fa-check"></i><b>1.3.1</b> Mising values</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="r-intro.html"><a href="r-intro.html#vectors"><i class="fa fa-check"></i><b>1.4</b> Vectors</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="r-intro.html"><a href="r-intro.html#coercion-for-vectors"><i class="fa fa-check"></i><b>1.4.1</b> Coercion for vectors</a></li>
<li class="chapter" data-level="1.4.2" data-path="r-intro.html"><a href="r-intro.html#vector-arithmetic"><i class="fa fa-check"></i><b>1.4.2</b> Vector arithmetic</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="r-intro.html"><a href="r-intro.html#arrays-and-matrices"><i class="fa fa-check"></i><b>1.5</b> Arrays and Matrices</a></li>
<li class="chapter" data-level="1.6" data-path="r-intro.html"><a href="r-intro.html#factors"><i class="fa fa-check"></i><b>1.6</b> Factors</a></li>
<li class="chapter" data-level="1.7" data-path="r-intro.html"><a href="r-intro.html#lists"><i class="fa fa-check"></i><b>1.7</b> Lists</a></li>
<li class="chapter" data-level="1.8" data-path="r-intro.html"><a href="r-intro.html#data-frames"><i class="fa fa-check"></i><b>1.8</b> Data frames</a></li>
<li class="chapter" data-level="1.9" data-path="r-intro.html"><a href="r-intro.html#r---functions-apply-lapply-sapply-tapply-mapply-vapply"><i class="fa fa-check"></i><b>1.9</b> R - Functions <code>apply()</code>, <code>lapply()</code>, <code>sapply()</code>, <code>tapply()</code>, <code>mapply()</code>, <code>vapply()</code></a></li>
<li class="chapter" data-level="1.10" data-path="r-intro.html"><a href="r-intro.html#environments"><i class="fa fa-check"></i><b>1.10</b> Environments</a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="r-intro.html"><a href="r-intro.html#global-variables-local-variables-and-programming-scope"><i class="fa fa-check"></i><b>1.10.1</b> Global variables, local variables and programming scope</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="r-intro.html"><a href="r-intro.html#reading-data"><i class="fa fa-check"></i><b>1.11</b> Reading Data</a></li>
<li class="chapter" data-level="1.12" data-path="r-intro.html"><a href="r-intro.html#plots"><i class="fa fa-check"></i><b>1.12</b> Plots</a></li>
<li class="chapter" data-level="1.13" data-path="r-intro.html"><a href="r-intro.html#flow-of-control"><i class="fa fa-check"></i><b>1.13</b> Flow of Control</a></li>
<li class="chapter" data-level="1.14" data-path="r-intro.html"><a href="r-intro.html#rattle"><i class="fa fa-check"></i><b>1.14</b> Rattle</a></li>
<li class="chapter" data-level="1.15" data-path="r-intro.html"><a href="r-intro.html#datasets"><i class="fa fa-check"></i><b>1.15</b> Datasets</a></li>
</ul></li>
<li class="part"><span><b>II Introduction to Data Mining</b></span></li>
<li class="chapter" data-level="2" data-path="what-is-data-mining-knowledge-discovery-in-databases-kdd.html"><a href="what-is-data-mining-knowledge-discovery-in-databases-kdd.html"><i class="fa fa-check"></i><b>2</b> What is Data Mining / Knowledge Discovery in Databases (KDD)</a>
<ul>
<li class="chapter" data-level="2.1" data-path="what-is-data-mining-knowledge-discovery-in-databases-kdd.html"><a href="what-is-data-mining-knowledge-discovery-in-databases-kdd.html#the-aim-of-data-analysis-and-statistical-learning"><i class="fa fa-check"></i><b>2.1</b> The Aim of Data Analysis and Statistical Learning</a></li>
<li class="chapter" data-level="2.2" data-path="what-is-data-mining-knowledge-discovery-in-databases-kdd.html"><a href="what-is-data-mining-knowledge-discovery-in-databases-kdd.html#data-science"><i class="fa fa-check"></i><b>2.2</b> Data Science</a></li>
<li class="chapter" data-level="2.3" data-path="what-is-data-mining-knowledge-discovery-in-databases-kdd.html"><a href="what-is-data-mining-knowledge-discovery-in-databases-kdd.html#some-references"><i class="fa fa-check"></i><b>2.3</b> Some References</a></li>
<li class="chapter" data-level="2.4" data-path="what-is-data-mining-knowledge-discovery-in-databases-kdd.html"><a href="what-is-data-mining-knowledge-discovery-in-databases-kdd.html#data-mining-and-data-science-with-r"><i class="fa fa-check"></i><b>2.4</b> Data Mining and Data Science with R</a></li>
<li class="chapter" data-level="2.5" data-path="what-is-data-mining-knowledge-discovery-in-databases-kdd.html"><a href="what-is-data-mining-knowledge-discovery-in-databases-kdd.html#data-mining-with-weka"><i class="fa fa-check"></i><b>2.5</b> Data Mining with Weka</a></li>
</ul></li>
<li class="part"><span><b>III Data Sources and Metrics and Standards in Software Engineering Defect Prediction</b></span></li>
<li class="chapter" data-level="3" data-path="data-sources-in-software-engineering.html"><a href="data-sources-in-software-engineering.html"><i class="fa fa-check"></i><b>3</b> Data Sources in Software Engineering</a></li>
<li class="chapter" data-level="4" data-path="repositories.html"><a href="repositories.html"><i class="fa fa-check"></i><b>4</b> Repositories</a></li>
<li class="chapter" data-level="5" data-path="open-toolsdashboards-to-extract-data.html"><a href="open-toolsdashboards-to-extract-data.html"><i class="fa fa-check"></i><b>5</b> Open Tools/Dashboards to extract data</a>
<ul>
<li class="chapter" data-level="5.1" data-path="open-toolsdashboards-to-extract-data.html"><a href="open-toolsdashboards-to-extract-data.html#issues"><i class="fa fa-check"></i><b>5.1</b> Issues</a></li>
<li class="chapter" data-level="5.2" data-path="open-toolsdashboards-to-extract-data.html"><a href="open-toolsdashboards-to-extract-data.html#effort-estimation-data-in-software-engineering"><i class="fa fa-check"></i><b>5.2</b> Effort Estimation Data in Software Engineering</a></li>
</ul></li>
<li class="part"><span><b>IV Exploratory and Descriptive Data analysis</b></span></li>
<li class="chapter" data-level="6" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html"><i class="fa fa-check"></i><b>6</b> Exploratory Data Analysis</a>
<ul>
<li class="chapter" data-level="6.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#descriptive-statistics"><i class="fa fa-check"></i><b>6.1</b> Descriptive statistics</a></li>
<li class="chapter" data-level="6.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#basic-plots"><i class="fa fa-check"></i><b>6.2</b> Basic Plots</a></li>
<li class="chapter" data-level="6.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#normality"><i class="fa fa-check"></i><b>6.3</b> Normality</a></li>
<li class="chapter" data-level="6.4" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#using-a-running-example-to-visualise-the-different-plots"><i class="fa fa-check"></i><b>6.4</b> Using a running Example to visualise the different plots</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#example-with-the-china-dataset"><i class="fa fa-check"></i><b>6.4.1</b> Example with the China dataset</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#correlation"><i class="fa fa-check"></i><b>6.5</b> Correlation</a></li>
<li class="chapter" data-level="6.6" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#confidence-intervals.-bootstrap"><i class="fa fa-check"></i><b>6.6</b> Confidence Intervals. Bootstrap</a></li>
<li class="chapter" data-level="6.7" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#nonparametric-bootstrap"><i class="fa fa-check"></i><b>6.7</b> Nonparametric Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="classical-hypothesis-testing.html"><a href="classical-hypothesis-testing.html"><i class="fa fa-check"></i><b>7</b> Classical Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="7.1" data-path="classical-hypothesis-testing.html"><a href="classical-hypothesis-testing.html#p-values"><i class="fa fa-check"></i><b>7.1</b> p-values</a></li>
</ul></li>
<li class="part"><span><b>V Preprocessing</b></span></li>
<li class="chapter" data-level="8" data-path="preprocessing.html"><a href="preprocessing.html"><i class="fa fa-check"></i><b>8</b> Preprocessing</a>
<ul>
<li class="chapter" data-level="8.1" data-path="preprocessing.html"><a href="preprocessing.html#data"><i class="fa fa-check"></i><b>8.1</b> Data</a></li>
<li class="chapter" data-level="8.2" data-path="preprocessing.html"><a href="preprocessing.html#missing-values"><i class="fa fa-check"></i><b>8.2</b> Missing values</a></li>
<li class="chapter" data-level="8.3" data-path="preprocessing.html"><a href="preprocessing.html#noise"><i class="fa fa-check"></i><b>8.3</b> Noise</a></li>
<li class="chapter" data-level="8.4" data-path="preprocessing.html"><a href="preprocessing.html#outliers"><i class="fa fa-check"></i><b>8.4</b> Outliers</a></li>
<li class="chapter" data-level="8.5" data-path="preprocessing.html"><a href="preprocessing.html#feature-selection"><i class="fa fa-check"></i><b>8.5</b> Feature selection</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="preprocessing.html"><a href="preprocessing.html#fselector-package-in-r"><i class="fa fa-check"></i><b>8.5.1</b> FSelector package in R</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="preprocessing.html"><a href="preprocessing.html#instance-selection"><i class="fa fa-check"></i><b>8.6</b> Instance selection</a></li>
<li class="chapter" data-level="8.7" data-path="preprocessing.html"><a href="preprocessing.html#discretization"><i class="fa fa-check"></i><b>8.7</b> Discretization</a></li>
<li class="chapter" data-level="8.8" data-path="preprocessing.html"><a href="preprocessing.html#correlation-coefficient-and-covariance-for-numeric-data"><i class="fa fa-check"></i><b>8.8</b> Correlation Coefficient and Covariance for Numeric Data</a></li>
<li class="chapter" data-level="8.9" data-path="preprocessing.html"><a href="preprocessing.html#normalization-1"><i class="fa fa-check"></i><b>8.9</b> Normalization</a>
<ul>
<li class="chapter" data-level="8.9.1" data-path="preprocessing.html"><a href="preprocessing.html#min-max-normalization"><i class="fa fa-check"></i><b>8.9.1</b> Min-Max Normalization</a></li>
<li class="chapter" data-level="8.9.2" data-path="preprocessing.html"><a href="preprocessing.html#z-score-normalization"><i class="fa fa-check"></i><b>8.9.2</b> Z-score normalization</a></li>
</ul></li>
<li class="chapter" data-level="8.10" data-path="preprocessing.html"><a href="preprocessing.html#transformations"><i class="fa fa-check"></i><b>8.10</b> Transformations</a>
<ul>
<li class="chapter" data-level="8.10.1" data-path="preprocessing.html"><a href="preprocessing.html#linear-transformations-and-quadratic-trans-formations"><i class="fa fa-check"></i><b>8.10.1</b> Linear Transformations and Quadratic Trans formations</a></li>
<li class="chapter" data-level="8.10.2" data-path="preprocessing.html"><a href="preprocessing.html#box-cox-transformation"><i class="fa fa-check"></i><b>8.10.2</b> Box-cox transformation</a></li>
<li class="chapter" data-level="8.10.3" data-path="preprocessing.html"><a href="preprocessing.html#nominal-to-binary-tranformations"><i class="fa fa-check"></i><b>8.10.3</b> Nominal to Binary tranformations</a></li>
</ul></li>
<li class="chapter" data-level="8.11" data-path="preprocessing.html"><a href="preprocessing.html#preprocessing-in-r"><i class="fa fa-check"></i><b>8.11</b> Preprocessing in R</a>
<ul>
<li class="chapter" data-level="8.11.1" data-path="preprocessing.html"><a href="preprocessing.html#the-dplyr-package"><i class="fa fa-check"></i><b>8.11.1</b> The <code>dplyr</code> package</a></li>
</ul></li>
<li class="chapter" data-level="8.12" data-path="preprocessing.html"><a href="preprocessing.html#other-libraries-and-tricks"><i class="fa fa-check"></i><b>8.12</b> Other libraries and tricks</a></li>
</ul></li>
<li class="part"><span><b>VI Supervised Models</b></span></li>
<li class="chapter" data-level="9" data-path="supervised-classification.html"><a href="supervised-classification.html"><i class="fa fa-check"></i><b>9</b> Supervised Classification</a>
<ul>
<li class="chapter" data-level="9.1" data-path="supervised-classification.html"><a href="supervised-classification.html#classification-trees"><i class="fa fa-check"></i><b>9.1</b> Classification Trees</a></li>
<li class="chapter" data-level="9.2" data-path="supervised-classification.html"><a href="supervised-classification.html#rules"><i class="fa fa-check"></i><b>9.2</b> Rules</a></li>
<li class="chapter" data-level="9.3" data-path="supervised-classification.html"><a href="supervised-classification.html#distanced-based-methods"><i class="fa fa-check"></i><b>9.3</b> Distanced-based Methods</a></li>
<li class="chapter" data-level="9.4" data-path="supervised-classification.html"><a href="supervised-classification.html#neural-networks"><i class="fa fa-check"></i><b>9.4</b> Neural Networks</a></li>
<li class="chapter" data-level="9.5" data-path="supervised-classification.html"><a href="supervised-classification.html#support-vector-machine"><i class="fa fa-check"></i><b>9.5</b> Support Vector Machine</a></li>
<li class="chapter" data-level="9.6" data-path="supervised-classification.html"><a href="supervised-classification.html#probabilistic-methods"><i class="fa fa-check"></i><b>9.6</b> Probabilistic Methods</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="supervised-classification.html"><a href="supervised-classification.html#naive-bayes"><i class="fa fa-check"></i><b>9.6.1</b> Naive Bayes</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="supervised-classification.html"><a href="supervised-classification.html#linear-discriminant-analysis-lda"><i class="fa fa-check"></i><b>9.7</b> Linear Discriminant Analysis (LDA)</a>
<ul>
<li class="chapter" data-level="9.7.1" data-path="supervised-classification.html"><a href="supervised-classification.html#predicting-the-number-of-defects-numerical-class"><i class="fa fa-check"></i><b>9.7.1</b> Predicting the number of defects (numerical class)</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="supervised-classification.html"><a href="supervised-classification.html#binary-logistic-regression-blr"><i class="fa fa-check"></i><b>9.8</b> Binary Logistic Regression (BLR)</a></li>
<li class="chapter" data-level="9.9" data-path="supervised-classification.html"><a href="supervised-classification.html#the-caret-package"><i class="fa fa-check"></i><b>9.9</b> The caret package</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>10</b> Regression</a>
<ul>
<li class="chapter" data-level="10.1" data-path="regression.html"><a href="regression.html#linear-regression-modeling"><i class="fa fa-check"></i><b>10.1</b> Linear Regression modeling</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="regression.html"><a href="regression.html#regression-galton-data"><i class="fa fa-check"></i><b>10.1.1</b> Regression: Galton Data</a></li>
<li class="chapter" data-level="10.1.2" data-path="regression.html"><a href="regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>10.1.2</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="10.1.3" data-path="regression.html"><a href="regression.html#least-squares"><i class="fa fa-check"></i><b>10.1.3</b> Least Squares</a></li>
<li class="chapter" data-level="10.1.4" data-path="regression.html"><a href="regression.html#linear-regression-in-r"><i class="fa fa-check"></i><b>10.1.4</b> Linear regression in R</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="regression.html"><a href="regression.html#linear-regression-diagnostics"><i class="fa fa-check"></i><b>10.2</b> Linear Regression Diagnostics</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="regression.html"><a href="regression.html#simulation-example"><i class="fa fa-check"></i><b>10.2.1</b> Simulation example</a></li>
<li class="chapter" data-level="10.2.2" data-path="regression.html"><a href="regression.html#diagnostics-fro-assessing-the-regression-line"><i class="fa fa-check"></i><b>10.2.2</b> Diagnostics fro assessing the regression line</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="regression.html"><a href="regression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>10.3</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="regression.html"><a href="regression.html#partial-least-squares"><i class="fa fa-check"></i><b>10.3.1</b> Partial Least Squares</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="regression.html"><a href="regression.html#linear-regression-in-software-effort-estimation"><i class="fa fa-check"></i><b>10.4</b> Linear regression in Software Effort estimation</a></li>
<li class="chapter" data-level="10.5" data-path="regression.html"><a href="regression.html#references"><i class="fa fa-check"></i><b>10.5</b> References</a></li>
</ul></li>
<li class="part"><span><b>VII Unsupervised Models</b></span></li>
<li class="chapter" data-level="11" data-path="unsupervised-or-descriptive-modeling.html"><a href="unsupervised-or-descriptive-modeling.html"><i class="fa fa-check"></i><b>11</b> Unsupervised or Descriptive modeling</a>
<ul>
<li class="chapter" data-level="11.1" data-path="unsupervised-or-descriptive-modeling.html"><a href="unsupervised-or-descriptive-modeling.html#clustering"><i class="fa fa-check"></i><b>11.1</b> Clustering</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="unsupervised-or-descriptive-modeling.html"><a href="unsupervised-or-descriptive-modeling.html#k-means"><i class="fa fa-check"></i><b>11.1.1</b> k-Means</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="unsupervised-or-descriptive-modeling.html"><a href="unsupervised-or-descriptive-modeling.html#association-rules"><i class="fa fa-check"></i><b>11.2</b> Association rules</a></li>
</ul></li>
<li class="part"><span><b>VIII Evaluation</b></span></li>
<li class="chapter" data-level="12" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html"><i class="fa fa-check"></i><b>12</b> Evaluation of Models</a>
<ul>
<li class="chapter" data-level="12.1" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#building-and-validating-a-model"><i class="fa fa-check"></i><b>12.1</b> Building and Validating a Model</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#holdout-approach"><i class="fa fa-check"></i><b>12.1.1</b> Holdout approach</a></li>
<li class="chapter" data-level="12.1.2" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#cross-validation-cv"><i class="fa fa-check"></i><b>12.1.2</b> Cross Validation (CV)</a></li>
<li class="chapter" data-level="12.1.3" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#leave-one-out-cross-validation-loo-cv"><i class="fa fa-check"></i><b>12.1.3</b> Leave-One-Out Cross-Validation (LOO-CV)</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#evaluation-of-classification-models"><i class="fa fa-check"></i><b>12.2</b> Evaluation of Classification Models</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#prediction-in-probabilistic-classifiers"><i class="fa fa-check"></i><b>12.2.1</b> Prediction in probabilistic classifiers</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#other-metrics-used-in-software-engineering-with-classification"><i class="fa fa-check"></i><b>12.3</b> Other Metrics used in Software Engineering with Classification</a></li>
<li class="chapter" data-level="12.4" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#graphical-evaluation"><i class="fa fa-check"></i><b>12.4</b> Graphical Evaluation</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#receiver-operating-characteristic-roc"><i class="fa fa-check"></i><b>12.4.1</b> Receiver Operating Characteristic (ROC)</a></li>
<li class="chapter" data-level="12.4.2" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#precision-recall-curve-prc"><i class="fa fa-check"></i><b>12.4.2</b> Precision-Recall Curve (PRC)</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#numeric-prediction-evaluation"><i class="fa fa-check"></i><b>12.5</b> Numeric Prediction Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="evaluationSE.html"><a href="evaluationSE.html"><i class="fa fa-check"></i><b>13</b> Measures of Evaluation in Software Engineering</a>
<ul>
<li class="chapter" data-level="13.1" data-path="evaluationSE.html"><a href="evaluationSE.html#effort-estimation-evaluation-metrics"><i class="fa fa-check"></i><b>13.1</b> Effort estimation evaluation metrics</a></li>
<li class="chapter" data-level="13.2" data-path="evaluationSE.html"><a href="evaluationSE.html#evaluation-of-the-model-in-the-testing-data"><i class="fa fa-check"></i><b>13.2</b> Evaluation of the Model in the Testing data</a></li>
<li class="chapter" data-level="13.3" data-path="evaluationSE.html"><a href="evaluationSE.html#building-a-linear-model-on-the-telecom1-dataset"><i class="fa fa-check"></i><b>13.3</b> Building a Linear Model on the Telecom1 dataset</a></li>
<li class="chapter" data-level="13.4" data-path="evaluationSE.html"><a href="evaluationSE.html#building-a-linear-model-on-the-telecom1-dataset-with-all-observations"><i class="fa fa-check"></i><b>13.4</b> Building a Linear Model on the Telecom1 dataset with all observations</a></li>
<li class="chapter" data-level="13.5" data-path="evaluationSE.html"><a href="evaluationSE.html#standardised-accuracy.-marp0-using-the-china-test-dataset"><i class="fa fa-check"></i><b>13.5</b> Standardised Accuracy. MARP0 using the China Test dataset</a></li>
<li class="chapter" data-level="13.6" data-path="evaluationSE.html"><a href="evaluationSE.html#standardised-accuracy.-marp0-using-the-telecom1-dataset"><i class="fa fa-check"></i><b>13.6</b> Standardised Accuracy. MARP0 using the Telecom1 dataset</a>
<ul>
<li class="chapter" data-level="13.6.1" data-path="evaluationSE.html"><a href="evaluationSE.html#marp0-using-the-atkinson-dataset"><i class="fa fa-check"></i><b>13.6.1</b> MARP0 using the Atkinson dataset</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="evaluationSE.html"><a href="evaluationSE.html#exact-marp0"><i class="fa fa-check"></i><b>13.7</b> Exact MARP0</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="wbl-simple-r-code-to-calculate-shepperd-and-macdonells-marp0-exactly.html"><a href="wbl-simple-r-code-to-calculate-shepperd-and-macdonells-marp0-exactly.html"><i class="fa fa-check"></i><b>14</b> WBL simple R code to calculate Shepperd and MacDonell’s MARP0 exactly</a>
<ul>
<li class="chapter" data-level="14.1" data-path="wbl-simple-r-code-to-calculate-shepperd-and-macdonells-marp0-exactly.html"><a href="wbl-simple-r-code-to-calculate-shepperd-and-macdonells-marp0-exactly.html#computing-the-bootstraped-confidence-interval-of-the-mean-for-the-test-observations-of-the-china-dataset"><i class="fa fa-check"></i><b>14.1</b> Computing the bootstraped confidence interval of the mean for the Test observations of the China dataset:</a></li>
<li class="chapter" data-level="14.2" data-path="wbl-simple-r-code-to-calculate-shepperd-and-macdonells-marp0-exactly.html"><a href="wbl-simple-r-code-to-calculate-shepperd-and-macdonells-marp0-exactly.html#defect-prediction-evaluation-metrics"><i class="fa fa-check"></i><b>14.2</b> Defect prediction evaluation metrics</a></li>
</ul></li>
<li class="part"><span><b>IX Advanced Topics</b></span></li>
<li class="chapter" data-level="15" data-path="feature-selection-1.html"><a href="feature-selection-1.html"><i class="fa fa-check"></i><b>15</b> Feature Selection</a>
<ul>
<li class="chapter" data-level="15.1" data-path="feature-selection-1.html"><a href="feature-selection-1.html#instance-selection-1"><i class="fa fa-check"></i><b>15.1</b> Instance Selection</a></li>
<li class="chapter" data-level="15.2" data-path="feature-selection-1.html"><a href="feature-selection-1.html#missing-data-imputation"><i class="fa fa-check"></i><b>15.2</b> Missing Data Imputation</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="feature-selection-example.html"><a href="feature-selection-example.html"><i class="fa fa-check"></i><b>16</b> Feature Selection Example</a></li>
<li class="chapter" data-level="17" data-path="advanced-models.html"><a href="advanced-models.html"><i class="fa fa-check"></i><b>17</b> Advanced Models</a>
<ul>
<li class="chapter" data-level="17.1" data-path="advanced-models.html"><a href="advanced-models.html#genetic-programming-for-symbolic-regression"><i class="fa fa-check"></i><b>17.1</b> Genetic Programming for Symbolic Regression</a></li>
<li class="chapter" data-level="17.2" data-path="advanced-models.html"><a href="advanced-models.html#genetic-programming-example"><i class="fa fa-check"></i><b>17.2</b> Genetic Programming Example</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="advanced-models.html"><a href="advanced-models.html#load-data"><i class="fa fa-check"></i><b>17.2.1</b> Load Data</a></li>
<li class="chapter" data-level="17.2.2" data-path="advanced-models.html"><a href="advanced-models.html#genetic-programming-for-symbolic-regression-china-dataset."><i class="fa fa-check"></i><b>17.2.2</b> Genetic Programming for Symbolic Regression: China dataset.</a></li>
<li class="chapter" data-level="17.2.3" data-path="advanced-models.html"><a href="advanced-models.html#genetic-programming-for-symbolic-regression.-telecom1-dataset."><i class="fa fa-check"></i><b>17.2.3</b> Genetic Programming for Symbolic Regression. Telecom1 dataset.</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="advanced-models.html"><a href="advanced-models.html#neural-networks-1"><i class="fa fa-check"></i><b>17.3</b> Neural Networks</a></li>
<li class="chapter" data-level="17.4" data-path="advanced-models.html"><a href="advanced-models.html#support-vector-machines"><i class="fa fa-check"></i><b>17.4</b> Support Vector Machines</a></li>
<li class="chapter" data-level="17.5" data-path="advanced-models.html"><a href="advanced-models.html#ensembles"><i class="fa fa-check"></i><b>17.5</b> Ensembles</a>
<ul>
<li class="chapter" data-level="17.5.1" data-path="advanced-models.html"><a href="advanced-models.html#bagging"><i class="fa fa-check"></i><b>17.5.1</b> Bagging</a></li>
<li class="chapter" data-level="17.5.2" data-path="advanced-models.html"><a href="advanced-models.html#boosting"><i class="fa fa-check"></i><b>17.5.2</b> Boosting</a></li>
<li class="chapter" data-level="17.5.3" data-path="advanced-models.html"><a href="advanced-models.html#rotation-forests"><i class="fa fa-check"></i><b>17.5.3</b> Rotation Forests</a></li>
<li class="chapter" data-level="17.5.4" data-path="advanced-models.html"><a href="advanced-models.html#boosting-in-r"><i class="fa fa-check"></i><b>17.5.4</b> Boosting in R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="further-classification-models.html"><a href="further-classification-models.html"><i class="fa fa-check"></i><b>18</b> Further Classification Models</a>
<ul>
<li class="chapter" data-level="18.1" data-path="further-classification-models.html"><a href="further-classification-models.html#multilabel-classification"><i class="fa fa-check"></i><b>18.1</b> Multilabel classification</a></li>
<li class="chapter" data-level="18.2" data-path="further-classification-models.html"><a href="further-classification-models.html#semi-supervised-learning"><i class="fa fa-check"></i><b>18.2</b> Semi-supervised Learning</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="social-network-analysis-in-se.html"><a href="social-network-analysis-in-se.html"><i class="fa fa-check"></i><b>19</b> Social Network Analysis in SE</a></li>
<li class="chapter" data-level="20" data-path="text-mining-software-engineering-data.html"><a href="text-mining-software-engineering-data.html"><i class="fa fa-check"></i><b>20</b> Text Mining Software Engineering Data</a>
<ul>
<li class="chapter" data-level="20.1" data-path="text-mining-software-engineering-data.html"><a href="text-mining-software-engineering-data.html#terminology"><i class="fa fa-check"></i><b>20.1</b> Terminology</a></li>
<li class="chapter" data-level="20.2" data-path="text-mining-software-engineering-data.html"><a href="text-mining-software-engineering-data.html#example-of-classifying-bugs-from-bugzilla"><i class="fa fa-check"></i><b>20.2</b> Example of classifying bugs from Bugzilla</a></li>
<li class="chapter" data-level="20.3" data-path="text-mining-software-engineering-data.html"><a href="text-mining-software-engineering-data.html#extracting-data-from-twitter"><i class="fa fa-check"></i><b>20.3</b> Extracting data from Twitter</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="time-series.html"><a href="time-series.html"><i class="fa fa-check"></i><b>21</b> Time Series</a>
<ul>
<li class="chapter" data-level="21.1" data-path="time-series.html"><a href="time-series.html#web-tutorials-about-time-series"><i class="fa fa-check"></i><b>21.1</b> Web tutorials about Time Series:</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references-1.html"><a href="references-1.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Analysis in Software Engineering using R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regression" class="section level1" number="10">
<h1><span class="header-section-number">Chapter 10</span> Regression</h1>
<div id="linear-regression-modeling" class="section level2" number="10.1">
<h2><span class="header-section-number">10.1</span> Linear Regression modeling</h2>
<ul>
<li><p><em>Linear Regression</em> is one of the oldest and most known predictive methods. As its name says, the idea is to try to fit a linear equation between a dependent variable and an independent, or explanatory, variable. The idea is that the independent variable <span class="math inline">\(x\)</span> is something the experimenter controls and the dependent variable <span class="math inline">\(y\)</span> is something that the experimenter measures. The line is used to predict the value of <span class="math inline">\(y\)</span> for a known value of <span class="math inline">\(x\)</span>. The variable <span class="math inline">\(x\)</span> is the predictor variable and <span class="math inline">\(y\)</span> the response variable.</p></li>
<li><p><em>Multiple linear regression</em> uses 2 or more independent variables for building a model. See <a href="https://www.wikipedia.org/wiki/Linear_regression" class="uri">https://www.wikipedia.org/wiki/Linear_regression</a>.</p></li>
<li><p>First proposed many years ago but still very useful…</p></li>
</ul>
<div class="figure">
<img src="figures/galton.png" alt="" />
<p class="caption">Galton Data</p>
</div>
<ul>
<li>The equation takes the form <span class="math inline">\(\hat{y}=b_0+b_1 * x\)</span></li>
<li>The method used to choose the values <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> is to minimize the sum of the squares of the residual errors.</li>
</ul>
<div id="regression-galton-data" class="section level3" number="10.1.1">
<h3><span class="header-section-number">10.1.1</span> Regression: Galton Data</h3>
<p>Not related to Software Engineering but …</p>
<div class="sourceCode" id="cb546"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb546-1"><a href="regression.html#cb546-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(UsingR)</span>
<span id="cb546-2"><a href="regression.html#cb546-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(galton)</span>
<span id="cb546-3"><a href="regression.html#cb546-3" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb546-4"><a href="regression.html#cb546-4" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(galton<span class="sc">$</span>child,<span class="at">col=</span><span class="st">&quot;blue&quot;</span>,<span class="at">breaks=</span><span class="dv">100</span>)</span>
<span id="cb546-5"><a href="regression.html#cb546-5" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(galton<span class="sc">$</span>parent,<span class="at">col=</span><span class="st">&quot;blue&quot;</span>,<span class="at">breaks=</span><span class="dv">100</span>)</span></code></pre></div>
<p><img src="DASE_files/figure-html/unnamed-chunk-75-1.png" width="672" /></p>
<div class="sourceCode" id="cb547"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb547-1"><a href="regression.html#cb547-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(galton<span class="sc">$</span>parent,galton<span class="sc">$</span>child,<span class="at">pch=</span><span class="dv">1</span>,<span class="at">col=</span><span class="st">&quot;blue&quot;</span>, <span class="at">cex=</span><span class="fl">0.4</span>)</span>
<span id="cb547-2"><a href="regression.html#cb547-2" aria-hidden="true" tabindex="-1"></a>lm1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(galton<span class="sc">$</span>child <span class="sc">~</span> galton<span class="sc">$</span>parent)</span>
<span id="cb547-3"><a href="regression.html#cb547-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(galton<span class="sc">$</span>parent,lm1<span class="sc">$</span>fitted,<span class="at">col=</span><span class="st">&quot;red&quot;</span>,<span class="at">lwd=</span><span class="dv">3</span>)</span>
<span id="cb547-4"><a href="regression.html#cb547-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(galton<span class="sc">$</span>parent,lm1<span class="sc">$</span>residuals,<span class="at">col=</span><span class="st">&quot;blue&quot;</span>,<span class="at">pch=</span><span class="dv">1</span>, <span class="at">cex=</span><span class="fl">0.4</span>)</span>
<span id="cb547-5"><a href="regression.html#cb547-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>),<span class="at">col=</span><span class="st">&quot;red&quot;</span>,<span class="at">lwd=</span><span class="dv">3</span>)</span></code></pre></div>
<p><img src="DASE_files/figure-html/unnamed-chunk-75-2.png" width="672" /></p>
<div class="sourceCode" id="cb548"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb548-1"><a href="regression.html#cb548-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(galton<span class="sc">$</span>child)</span></code></pre></div>
<p><img src="DASE_files/figure-html/unnamed-chunk-75-3.png" width="672" /></p>
</div>
<div id="simple-linear-regression" class="section level3" number="10.1.2">
<h3><span class="header-section-number">10.1.2</span> Simple Linear Regression</h3>
<ul>
<li><p>Given two variables <span class="math inline">\(Y\)</span> (response) and <span class="math inline">\(X\)</span> (predictor), the assumption is that there is an approximate (<span class="math inline">\(\approx\)</span>) <em>linear</em> relation between those variables.</p></li>
<li><p>The mathematical model of the observed data is described as (for the case of simple linear regression):
<span class="math display">\[ Y \approx \beta_0 + \beta_1 X\]</span></p></li>
<li><p>the parameter <span class="math inline">\(\beta_0\)</span> is named the <em>intercept</em> and <span class="math inline">\(\beta_1\)</span> is the <em>slope</em></p></li>
<li><p>Each observation can be modeled as</p></li>
</ul>
<p><span class="math display">\[y_i = \beta_0 + \beta_1 x_i + \epsilon_i;
\epsilon_i \sim N(0,\sigma^2)\]</span>
- <span class="math inline">\(\epsilon_i\)</span> is the <em>error</em>
- This means that the variable <span class="math inline">\(y\)</span> is normally distributed:
<span class="math display">\[ y_i \sim N( \beta_0 + \beta_1 x_i, \sigma^2) \]</span></p>
<ul>
<li>The <em>predictions</em> or <em>estimations</em> of this model are obtained by a linear equation of the form <span class="math inline">\(\hat{Y}=\hat{\beta_0} + \hat{\beta}_1X\)</span>, that is, each new prediction is computed with
<span class="math display">\[\hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1x_i \]</span>.</li>
<li>The actual parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are unknown</li>
<li>The parameters <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> of the linear equation can be estimated with different methods.</li>
</ul>
</div>
<div id="least-squares" class="section level3" number="10.1.3">
<h3><span class="header-section-number">10.1.3</span> Least Squares</h3>
<ul>
<li>One of the most used methods for computing <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> is the criterion of “least squares” minimization.</li>
<li>The data is composed of <span class="math inline">\(n\)</span> pairs of observations <span class="math inline">\((x_i, y_i)\)</span></li>
<li>Given an observation <span class="math inline">\(y_i\)</span> and its corresponding estimation <span class="math inline">\(\hat{y_i})\)</span> the <em>residual</em> <span class="math inline">\(e_i\)</span> is defined as <span class="math display">\[e_i= y_i - \hat{y_i}\]</span></li>
<li>the Residual Sum of Squares is defined as <span class="math display">\[RSS=e_1^2+\dots + e_i^2+\dots+e_n^2\]</span></li>
<li>the Least Squares Approach minimizes the RSS</li>
<li>as result of that minimizitation, it can be obtained, by means of calculus, the estimation of <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> as <span class="math display">\[\hat{\beta}_1=\frac{\sum_{i=1}^{n}{(x_i-\bar{x})(y_i-\bar{y})}}{\sum_{i=1}^{n}(x_i-\bar{x})^2}\]</span> and <span class="math display">\[\hat{\beta}_0=\bar{y}-\hat{\beta}_1\bar{x} \]</span> where <span class="math inline">\(\bar{y}\)</span> and <span class="math inline">\(\bar{x}\)</span> are the sample means.</li>
<li>the variance <span class="math inline">\(\sigma^2\)</span> is estimated by
<span class="math display">\[\hat\sigma^2 = {RSS}/{(n-2)}\]</span> where n is the number of observations</li>
<li>The <em>Residual Standard Error</em> is defined as <span class="math display">\[RSE = \sqrt{{RSS}/{(n-2)}}\]</span></li>
<li>The equation <span class="math display">\[ Y = \beta_0 + \beta_1 X + \epsilon\]</span> defines the linear model, i.e., the <em>population regression line</em></li>
<li>The <em>least squares line</em> is <span class="math inline">\(\hat{Y}=\hat{\beta_0} + \hat{\beta}_1X\)</span></li>
<li><em>Confidence intervals</em> are computed using the <em>standard errors</em> of the intercept and the slope.</li>
<li>The <span class="math inline">\(95\%\)</span> confidence interval for the slope is computed as <span class="math display">\[[\hat{\beta}_1 - 2 \cdot SE(\hat{\beta}_1), \hat{\beta}_1+SE(\hat{\beta}_1)]\]</span></li>
<li>where <span class="math display">\[ SE(\hat{\beta}_1) = \sqrt{\frac{\sigma^2}{\sum_{i=1}^{n}(x_i-\bar{x})^2}}\]</span></li>
</ul>
</div>
<div id="linear-regression-in-r" class="section level3" number="10.1.4">
<h3><span class="header-section-number">10.1.4</span> Linear regression in R</h3>
<p>The following are the basic commands in R:</p>
<ul>
<li>The basic function is <code>lm()</code>, that returns an object with the model.</li>
<li>Other commands: <code>summary</code> prints out information about the regression, <code>coef</code> gives the coefficients for the linear model, <code>fitted</code> gives the predictd value of <span class="math inline">\(y\)</span> for each value of <span class="math inline">\(x\)</span>, <code>residuals</code> contains the differences between observed and fitted values.</li>
<li><a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/predict.lm.html"><code>predict</code></a> will generate predicted values of the response for the values of the explanatory variable.</li>
</ul>
</div>
</div>
<div id="linear-regression-diagnostics" class="section level2" number="10.2">
<h2><span class="header-section-number">10.2</span> Linear Regression Diagnostics</h2>
<ul>
<li>Several plots help to evaluate the suitability of the linear regression
<ul>
<li><em>Residuals vs fitted</em>: The residuals should be randomly distributed around the horizontal line representing a residual error of zero; that is, there should not be a distinct trend in the distribution of points.</li>
<li><em>Standard Q-Q plot</em>: residual errors are normally distributed</li>
<li><em>Square root of the standardized residuals vs the fitted values</em>: there should be no obvious trend. This plot is similar to the residuals versus fitted values plot, but it uses the square root of the standardized residuals.</li>
<li><em>Leverage</em>: measures the importance of each point in determining the regression result. Smaller values means that removing the observation has little effect on the regression result.</li>
</ul></li>
</ul>
<div id="simulation-example" class="section level3" number="10.2.1">
<h3><span class="header-section-number">10.2.1</span> Simulation example</h3>
<div id="simulate-a-dataset" class="section level4" number="10.2.1.1">
<h4><span class="header-section-number">10.2.1.1</span> Simulate a dataset</h4>
<div class="sourceCode" id="cb549"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb549-1"><a href="regression.html#cb549-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3456</span>)</span>
<span id="cb549-2"><a href="regression.html#cb549-2" aria-hidden="true" tabindex="-1"></a><span class="co"># equation is  y = -6.6 + 0.13 x +e</span></span>
<span id="cb549-3"><a href="regression.html#cb549-3" aria-hidden="true" tabindex="-1"></a><span class="co"># range x 100,400</span></span>
<span id="cb549-4"><a href="regression.html#cb549-4" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fl">6.6</span></span>
<span id="cb549-5"><a href="regression.html#cb549-5" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fl">0.13</span></span>
<span id="cb549-6"><a href="regression.html#cb549-6" aria-hidden="true" tabindex="-1"></a>num_obs <span class="ot">&lt;-</span> <span class="dv">60</span></span>
<span id="cb549-7"><a href="regression.html#cb549-7" aria-hidden="true" tabindex="-1"></a>xmin <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb549-8"><a href="regression.html#cb549-8" aria-hidden="true" tabindex="-1"></a>xmax <span class="ot">&lt;-</span> <span class="dv">400</span></span>
<span id="cb549-9"><a href="regression.html#cb549-9" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">seq</span>(<span class="at">from=</span>xmin, <span class="at">to =</span> xmax, <span class="at">by =</span><span class="dv">1</span>), <span class="at">size=</span> num_obs, <span class="at">replace=</span><span class="cn">FALSE</span>)</span>
<span id="cb549-10"><a href="regression.html#cb549-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb549-11"><a href="regression.html#cb549-11" aria-hidden="true" tabindex="-1"></a>sderror <span class="ot">&lt;-</span> <span class="dv">9</span> <span class="co"># sigma for the error term in the model</span></span>
<span id="cb549-12"><a href="regression.html#cb549-12" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(num_obs, <span class="dv">0</span>, sderror) </span>
<span id="cb549-13"><a href="regression.html#cb549-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb549-14"><a href="regression.html#cb549-14" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> a <span class="sc">+</span> b <span class="sc">*</span> x <span class="sc">+</span> e</span>
<span id="cb549-15"><a href="regression.html#cb549-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb549-16"><a href="regression.html#cb549-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb549-17"><a href="regression.html#cb549-17" aria-hidden="true" tabindex="-1"></a>newlm <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>x)</span>
<span id="cb549-18"><a href="regression.html#cb549-18" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(newlm)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -26.518  -5.645   0.363   5.695  18.392 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -7.9060     3.3922   -2.33    0.023 *  
## x             0.1331     0.0132   10.05  2.6e-14 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8.48 on 58 degrees of freedom
## Multiple R-squared:  0.635,  Adjusted R-squared:  0.629 
## F-statistic:  101 on 1 and 58 DF,  p-value: 2.57e-14</code></pre>
<div class="sourceCode" id="cb551"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb551-1"><a href="regression.html#cb551-1" aria-hidden="true" tabindex="-1"></a>cfa1 <span class="ot">&lt;-</span> <span class="fu">coef</span>(newlm)[<span class="dv">1</span>]</span>
<span id="cb551-2"><a href="regression.html#cb551-2" aria-hidden="true" tabindex="-1"></a>cfb2 <span class="ot">&lt;-</span> <span class="fu">coef</span>(newlm)[<span class="dv">2</span>]</span>
<span id="cb551-3"><a href="regression.html#cb551-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y, <span class="at">xlab=</span><span class="st">&quot;x axis&quot;</span>, <span class="at">ylab=</span> <span class="st">&quot;y axis&quot;</span>, <span class="at">xlim =</span> <span class="fu">c</span>(xmin, xmax), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">60</span>), <span class="at">sub =</span> <span class="st">&quot;Line in black is the actual model&quot;</span>)</span>
<span id="cb551-4"><a href="regression.html#cb551-4" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="at">main =</span> <span class="fu">paste</span>(<span class="st">&quot;Line in blue is the Regression Line for &quot;</span>, num_obs, <span class="st">&quot; points.&quot;</span>))</span>
<span id="cb551-5"><a href="regression.html#cb551-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb551-6"><a href="regression.html#cb551-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> cfa1, <span class="at">b =</span> cfb2, <span class="at">col=</span> <span class="st">&quot;blue&quot;</span>, <span class="at">lwd=</span><span class="dv">3</span>)</span>
<span id="cb551-7"><a href="regression.html#cb551-7" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> a, <span class="at">b =</span> b, <span class="at">col=</span> <span class="st">&quot;black&quot;</span>, <span class="at">lwd=</span><span class="dv">1</span>) <span class="co">#original line</span></span></code></pre></div>
<p><img src="DASE_files/figure-html/unnamed-chunk-76-1.png" width="672" /></p>
<div id="subset-a-set-of-points-from-the-same-sample" class="section level5" number="10.2.1.1.1">
<h5><span class="header-section-number">10.2.1.1.1</span> Subset a set of points from the same sample</h5>
<div class="sourceCode" id="cb552"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb552-1"><a href="regression.html#cb552-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sample from  the same  x     to compare least squares lines </span></span>
<span id="cb552-2"><a href="regression.html#cb552-2" aria-hidden="true" tabindex="-1"></a><span class="co"># change the denominator in newsample to see how the least square lines changes accordingly. </span></span>
<span id="cb552-3"><a href="regression.html#cb552-3" aria-hidden="true" tabindex="-1"></a>newsample <span class="ot">&lt;-</span> <span class="fu">as.integer</span>(num_obs<span class="sc">/</span><span class="dv">8</span>) <span class="co"># number of pairs x,y</span></span>
<span id="cb552-4"><a href="regression.html#cb552-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb552-5"><a href="regression.html#cb552-5" aria-hidden="true" tabindex="-1"></a>idxs_x1 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>num_obs, <span class="at">size =</span> newsample, <span class="at">replace =</span> <span class="cn">FALSE</span>) <span class="co">#sample indexes</span></span>
<span id="cb552-6"><a href="regression.html#cb552-6" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> x[idxs_x1]</span>
<span id="cb552-7"><a href="regression.html#cb552-7" aria-hidden="true" tabindex="-1"></a>e1 <span class="ot">&lt;-</span> e[idxs_x1]</span>
<span id="cb552-8"><a href="regression.html#cb552-8" aria-hidden="true" tabindex="-1"></a>y1 <span class="ot">&lt;-</span> a <span class="sc">+</span> b <span class="sc">*</span> x1 <span class="sc">+</span> e1</span>
<span id="cb552-9"><a href="regression.html#cb552-9" aria-hidden="true" tabindex="-1"></a>xy_obs <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(x1, y1)</span>
<span id="cb552-10"><a href="regression.html#cb552-10" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(xy_obs) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;x_obs&quot;</span>, <span class="st">&quot;y_obs&quot;</span>)</span>
<span id="cb552-11"><a href="regression.html#cb552-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb552-12"><a href="regression.html#cb552-12" aria-hidden="true" tabindex="-1"></a>newlm1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y1<span class="sc">~</span>x1)</span>
<span id="cb552-13"><a href="regression.html#cb552-13" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(newlm1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y1 ~ x1)
## 
## Residuals:
##      1      2      3      4      5      6      7 
##  3.968 -8.537  3.141 -8.723  7.294 -0.235  3.092 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)   2.9107     7.7166    0.38    0.722  
## x1            0.0913     0.0328    2.79    0.039 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.89 on 5 degrees of freedom
## Multiple R-squared:  0.609,  Adjusted R-squared:  0.53 
## F-statistic: 7.77 on 1 and 5 DF,  p-value: 0.0385</code></pre>
<div class="sourceCode" id="cb554"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb554-1"><a href="regression.html#cb554-1" aria-hidden="true" tabindex="-1"></a>cfa21 <span class="ot">&lt;-</span> <span class="fu">coef</span>(newlm1)[<span class="dv">1</span>]</span>
<span id="cb554-2"><a href="regression.html#cb554-2" aria-hidden="true" tabindex="-1"></a>cfb22 <span class="ot">&lt;-</span> <span class="fu">coef</span>(newlm1)[<span class="dv">2</span>]</span>
<span id="cb554-3"><a href="regression.html#cb554-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb554-4"><a href="regression.html#cb554-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x1,y1, <span class="at">xlab=</span><span class="st">&quot;x axis&quot;</span>, <span class="at">ylab=</span> <span class="st">&quot;y axis&quot;</span>, <span class="at">xlim =</span> <span class="fu">c</span>(xmin, xmax), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">60</span>))</span>
<span id="cb554-5"><a href="regression.html#cb554-5" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="at">main =</span> <span class="fu">paste</span>(<span class="st">&quot;New line in red with &quot;</span>, newsample, <span class="st">&quot; points in sample&quot;</span>))</span>
<span id="cb554-6"><a href="regression.html#cb554-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb554-7"><a href="regression.html#cb554-7" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> a, <span class="at">b =</span> b, <span class="at">col=</span> <span class="st">&quot;black&quot;</span>, <span class="at">lwd=</span><span class="dv">1</span>)  <span class="co"># True line</span></span>
<span id="cb554-8"><a href="regression.html#cb554-8" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> cfa1, <span class="at">b =</span> cfb2, <span class="at">col=</span> <span class="st">&quot;blue&quot;</span>, <span class="at">lwd=</span><span class="dv">1</span>)  <span class="co">#sample</span></span>
<span id="cb554-9"><a href="regression.html#cb554-9" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> cfa21, <span class="at">b =</span> cfb22, <span class="at">col=</span> <span class="st">&quot;red&quot;</span>, <span class="at">lwd=</span><span class="dv">2</span>) <span class="co">#new line</span></span></code></pre></div>
<p><img src="DASE_files/figure-html/unnamed-chunk-77-1.png" width="672" /></p>
</div>
<div id="compute-a-confidence-interval-on-the-original-sample-regression-line" class="section level5" number="10.2.1.1.2">
<h5><span class="header-section-number">10.2.1.1.2</span> Compute a confidence interval on the original sample regression line</h5>
<div class="sourceCode" id="cb555"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb555-1"><a href="regression.html#cb555-1" aria-hidden="true" tabindex="-1"></a>newx <span class="ot">&lt;-</span> <span class="fu">seq</span>(xmin, xmax)</span>
<span id="cb555-2"><a href="regression.html#cb555-2" aria-hidden="true" tabindex="-1"></a>ypredicted <span class="ot">&lt;-</span> <span class="fu">predict</span>(newlm, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">x=</span>newx), <span class="at">interval=</span> <span class="st">&quot;confidence&quot;</span>, <span class="at">level=</span> <span class="fl">0.90</span>, <span class="at">se =</span> <span class="cn">TRUE</span>)</span>
<span id="cb555-3"><a href="regression.html#cb555-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb555-4"><a href="regression.html#cb555-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y, <span class="at">xlab=</span><span class="st">&quot;x axis&quot;</span>, <span class="at">ylab=</span> <span class="st">&quot;y axis&quot;</span>, <span class="at">xlim =</span> <span class="fu">c</span>(xmin, xmax), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">60</span>))</span>
<span id="cb555-5"><a href="regression.html#cb555-5" aria-hidden="true" tabindex="-1"></a><span class="co"># points(x1, fitted(newlm1))</span></span>
<span id="cb555-6"><a href="regression.html#cb555-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(newlm)</span>
<span id="cb555-7"><a href="regression.html#cb555-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb555-8"><a href="regression.html#cb555-8" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(newx,ypredicted<span class="sc">$</span>fit[,<span class="dv">2</span>],<span class="at">col=</span><span class="st">&quot;red&quot;</span>,<span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb555-9"><a href="regression.html#cb555-9" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(newx,ypredicted<span class="sc">$</span>fit[,<span class="dv">3</span>],<span class="at">col=</span><span class="st">&quot;red&quot;</span>,<span class="at">lty=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="DASE_files/figure-html/unnamed-chunk-78-1.png" width="672" /></p>
<div class="sourceCode" id="cb556"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb556-1"><a href="regression.html#cb556-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the residuals or errors</span></span>
<span id="cb556-2"><a href="regression.html#cb556-2" aria-hidden="true" tabindex="-1"></a>ypredicted_x <span class="ot">&lt;-</span> <span class="fu">predict</span>(newlm, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">x=</span>x))</span>
<span id="cb556-3"><a href="regression.html#cb556-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y, <span class="at">xlab=</span><span class="st">&quot;x axis&quot;</span>, <span class="at">ylab=</span> <span class="st">&quot;y axis&quot;</span>, <span class="at">xlim =</span> <span class="fu">c</span>(xmin, xmax), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">60</span>), <span class="at">sub =</span> <span class="st">&quot;&quot;</span>, <span class="at">pch=</span><span class="dv">19</span>, <span class="at">cex=</span><span class="fl">0.75</span>)</span>
<span id="cb556-4"><a href="regression.html#cb556-4" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="at">main =</span> <span class="fu">paste</span>(<span class="st">&quot;Residuals or errors&quot;</span>, num_obs, <span class="st">&quot; points.&quot;</span>))</span>
<span id="cb556-5"><a href="regression.html#cb556-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(newlm)</span>
<span id="cb556-6"><a href="regression.html#cb556-6" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(x, y, x, ypredicted_x)</span></code></pre></div>
<p><img src="DASE_files/figure-html/unnamed-chunk-78-2.png" width="672" /></p>
</div>
<div id="take-another-sample-from-the-model-and-explore" class="section level5" number="10.2.1.1.3">
<h5><span class="header-section-number">10.2.1.1.3</span> Take another sample from the model and explore</h5>
<div class="sourceCode" id="cb557"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb557-1"><a href="regression.html#cb557-1" aria-hidden="true" tabindex="-1"></a><span class="co"># equation is  y = -6.6 + 0.13 x +e</span></span>
<span id="cb557-2"><a href="regression.html#cb557-2" aria-hidden="true" tabindex="-1"></a><span class="co"># range x 100,400</span></span>
<span id="cb557-3"><a href="regression.html#cb557-3" aria-hidden="true" tabindex="-1"></a>num_obs <span class="ot">&lt;-</span> <span class="dv">35</span></span>
<span id="cb557-4"><a href="regression.html#cb557-4" aria-hidden="true" tabindex="-1"></a>xmin <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb557-5"><a href="regression.html#cb557-5" aria-hidden="true" tabindex="-1"></a>xmax <span class="ot">&lt;-</span> <span class="dv">400</span></span>
<span id="cb557-6"><a href="regression.html#cb557-6" aria-hidden="true" tabindex="-1"></a>x3 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">seq</span>(<span class="at">from=</span>xmin, <span class="at">to =</span> xmax, <span class="at">by =</span><span class="dv">1</span>), <span class="at">size=</span> num_obs, <span class="at">replace=</span><span class="cn">FALSE</span>)</span>
<span id="cb557-7"><a href="regression.html#cb557-7" aria-hidden="true" tabindex="-1"></a>sderror <span class="ot">&lt;-</span> <span class="dv">14</span> <span class="co"># sigma for the error term in the model</span></span>
<span id="cb557-8"><a href="regression.html#cb557-8" aria-hidden="true" tabindex="-1"></a>e3 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(num_obs, <span class="dv">0</span>, sderror) </span>
<span id="cb557-9"><a href="regression.html#cb557-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb557-10"><a href="regression.html#cb557-10" aria-hidden="true" tabindex="-1"></a>y3 <span class="ot">&lt;-</span> a <span class="sc">+</span> b <span class="sc">*</span> x3 <span class="sc">+</span> e3</span>
<span id="cb557-11"><a href="regression.html#cb557-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb557-12"><a href="regression.html#cb557-12" aria-hidden="true" tabindex="-1"></a>newlm3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y3<span class="sc">~</span>x3)</span>
<span id="cb557-13"><a href="regression.html#cb557-13" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(newlm3)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y3 ~ x3)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -40.87  -9.20  -2.28  12.08  47.17 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)  -0.9284     8.7458   -0.11   0.9161   
## x3            0.1193     0.0345    3.45   0.0015 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 17.2 on 33 degrees of freedom
## Multiple R-squared:  0.266,  Adjusted R-squared:  0.243 
## F-statistic: 11.9 on 1 and 33 DF,  p-value: 0.00153</code></pre>
<div class="sourceCode" id="cb559"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb559-1"><a href="regression.html#cb559-1" aria-hidden="true" tabindex="-1"></a>cfa31 <span class="ot">&lt;-</span> <span class="fu">coef</span>(newlm3)[<span class="dv">1</span>]</span>
<span id="cb559-2"><a href="regression.html#cb559-2" aria-hidden="true" tabindex="-1"></a>cfb32 <span class="ot">&lt;-</span> <span class="fu">coef</span>(newlm3)[<span class="dv">2</span>]</span>
<span id="cb559-3"><a href="regression.html#cb559-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x3,y3, <span class="at">xlab=</span><span class="st">&quot;x axis&quot;</span>, <span class="at">ylab=</span> <span class="st">&quot;y axis&quot;</span>, <span class="at">xlim =</span> <span class="fu">c</span>(xmin, xmax), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">60</span>))</span>
<span id="cb559-4"><a href="regression.html#cb559-4" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="at">main =</span> <span class="fu">paste</span>(<span class="st">&quot;Line in red is the Regression Line for &quot;</span>, num_obs, <span class="st">&quot; points.&quot;</span>))</span>
<span id="cb559-5"><a href="regression.html#cb559-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> cfa31, <span class="at">b =</span> cfb32, <span class="at">col=</span> <span class="st">&quot;red&quot;</span>, <span class="at">lwd=</span><span class="dv">3</span>)</span>
<span id="cb559-6"><a href="regression.html#cb559-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> a, <span class="at">b =</span> b, <span class="at">col=</span> <span class="st">&quot;black&quot;</span>, <span class="at">lwd=</span><span class="dv">2</span>) <span class="co">#original line</span></span>
<span id="cb559-7"><a href="regression.html#cb559-7" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> cfa1, <span class="at">b =</span> cfb2, <span class="at">col=</span> <span class="st">&quot;blue&quot;</span>, <span class="at">lwd=</span><span class="dv">1</span>) <span class="co">#first sample</span></span>
<span id="cb559-8"><a href="regression.html#cb559-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb559-9"><a href="regression.html#cb559-9" aria-hidden="true" tabindex="-1"></a><span class="co"># confidence intervals for the new sample</span></span>
<span id="cb559-10"><a href="regression.html#cb559-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb559-11"><a href="regression.html#cb559-11" aria-hidden="true" tabindex="-1"></a>newx <span class="ot">&lt;-</span> <span class="fu">seq</span>(xmin, xmax)</span>
<span id="cb559-12"><a href="regression.html#cb559-12" aria-hidden="true" tabindex="-1"></a>ypredicted <span class="ot">&lt;-</span> <span class="fu">predict</span>(newlm3, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">x3=</span>newx), <span class="at">interval=</span> <span class="st">&quot;confidence&quot;</span>, <span class="at">level=</span> <span class="fl">0.90</span>, <span class="at">se =</span> <span class="cn">TRUE</span>)</span>
<span id="cb559-13"><a href="regression.html#cb559-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb559-14"><a href="regression.html#cb559-14" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(newx,ypredicted<span class="sc">$</span>fit[,<span class="dv">2</span>],<span class="at">col=</span><span class="st">&quot;red&quot;</span>,<span class="at">lty=</span><span class="dv">2</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb559-15"><a href="regression.html#cb559-15" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(newx,ypredicted<span class="sc">$</span>fit[,<span class="dv">3</span>],<span class="at">col=</span><span class="st">&quot;red&quot;</span>,<span class="at">lty=</span><span class="dv">2</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="DASE_files/figure-html/unnamed-chunk-79-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="diagnostics-fro-assessing-the-regression-line" class="section level3" number="10.2.2">
<h3><span class="header-section-number">10.2.2</span> Diagnostics fro assessing the regression line</h3>
<div id="residual-standard-error" class="section level4" number="10.2.2.1">
<h4><span class="header-section-number">10.2.2.1</span> Residual Standard Error</h4>
<ul>
<li>It gives us an idea of the typical or average error of the model. It is the estimated standard deviation of the residuals.</li>
</ul>
</div>
<div id="r2-statistic" class="section level4" number="10.2.2.2">
<h4><span class="header-section-number">10.2.2.2</span> <span class="math inline">\(R^2\)</span> statistic</h4>
<ul>
<li>This is the proportion of variability in the data that is explained by the model. Best values are those close to 1.</li>
</ul>
</div>
</div>
</div>
<div id="multiple-linear-regression" class="section level2" number="10.3">
<h2><span class="header-section-number">10.3</span> Multiple Linear Regression</h2>
<div id="partial-least-squares" class="section level3" number="10.3.1">
<h3><span class="header-section-number">10.3.1</span> Partial Least Squares</h3>
<ul>
<li>If several predictors are highly correlated, the least squares approach has high variability.</li>
<li>PLS finds linear combinations of the predictors, that are called <em>components</em> or <em>latent</em> variables.</li>
</ul>
</div>
</div>
<div id="linear-regression-in-software-effort-estimation" class="section level2" number="10.4">
<h2><span class="header-section-number">10.4</span> Linear regression in Software Effort estimation</h2>
<p>Fitting a linear model to log-log
- the predictive power equation is <span class="math inline">\(y= e^{b_0}*x^{b_1}\)</span>, ignoring the bias corrections. Note: depending how the error term behaves we could try another general linear model (GLM) or other model that does not rely on the normality of the residuals (quantile regression, etc.)
- First, we are fitting the model to the whole dataset. But it is not the right way to do it, because of overfitting.</p>
<div class="sourceCode" id="cb560"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb560-1"><a href="regression.html#cb560-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(foreign)</span>
<span id="cb560-2"><a href="regression.html#cb560-2" aria-hidden="true" tabindex="-1"></a>china <span class="ot">&lt;-</span> <span class="fu">read.arff</span>(<span class="st">&quot;./datasets/effortEstimation/china.arff&quot;</span>)</span>
<span id="cb560-3"><a href="regression.html#cb560-3" aria-hidden="true" tabindex="-1"></a>china_size <span class="ot">&lt;-</span> china<span class="sc">$</span>AFP</span>
<span id="cb560-4"><a href="regression.html#cb560-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(china_size)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##       9     100     215     487     438   17518</code></pre>
<div class="sourceCode" id="cb562"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb562-1"><a href="regression.html#cb562-1" aria-hidden="true" tabindex="-1"></a>china_effort <span class="ot">&lt;-</span> china<span class="sc">$</span>Effort</span>
<span id="cb562-2"><a href="regression.html#cb562-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(china_effort)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##      26     704    1829    3921    3826   54620</code></pre>
<div class="sourceCode" id="cb564"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb564-1"><a href="regression.html#cb564-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb564-2"><a href="regression.html#cb564-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(china_size, <span class="at">col=</span><span class="st">&quot;blue&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Adjusted Function Points&quot;</span>, <span class="at">main=</span><span class="st">&quot;Distribution of AFP&quot;</span>)</span>
<span id="cb564-3"><a href="regression.html#cb564-3" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(china_effort, <span class="at">col=</span><span class="st">&quot;blue&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;Effort&quot;</span>, <span class="at">main=</span><span class="st">&quot;Distribution of Effort&quot;</span>)</span></code></pre></div>
<p><img src="DASE_files/figure-html/unnamed-chunk-80-1.png" width="672" /></p>
<div class="sourceCode" id="cb565"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb565-1"><a href="regression.html#cb565-1" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span>(china_size)</span>
<span id="cb565-2"><a href="regression.html#cb565-2" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span>(china_effort)</span></code></pre></div>
<p><img src="DASE_files/figure-html/unnamed-chunk-80-2.png" width="672" /></p>
<div class="sourceCode" id="cb566"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb566-1"><a href="regression.html#cb566-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(china_size)</span>
<span id="cb566-2"><a href="regression.html#cb566-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qqline</span>(china_size)</span>
<span id="cb566-3"><a href="regression.html#cb566-3" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(china_effort)</span>
<span id="cb566-4"><a href="regression.html#cb566-4" aria-hidden="true" tabindex="-1"></a><span class="fu">qqline</span>(china_effort)</span></code></pre></div>
<p><img src="DASE_files/figure-html/unnamed-chunk-80-3.png" width="672" /></p>
<p>Applying the <code>log</code> function (it computes natural logarithms, base <span class="math inline">\(e\)</span>)</p>
<p><img src="DASE_files/figure-html/unnamed-chunk-81-1.png" width="672" /><img src="DASE_files/figure-html/unnamed-chunk-81-2.png" width="672" /></p>
<div class="sourceCode" id="cb567"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb567-1"><a href="regression.html#cb567-1" aria-hidden="true" tabindex="-1"></a>linmodel_logchina <span class="ot">&lt;-</span> <span class="fu">lm</span>(logchina_effort <span class="sc">~</span> logchina_size)</span>
<span id="cb567-2"><a href="regression.html#cb567-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb567-3"><a href="regression.html#cb567-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(logchina_size, logchina_effort)</span>
<span id="cb567-4"><a href="regression.html#cb567-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(linmodel_logchina, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span><span class="dv">3</span>)</span></code></pre></div>
<p><img src="DASE_files/figure-html/unnamed-chunk-82-1.png" width="672" /></p>
<div class="sourceCode" id="cb568"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb568-1"><a href="regression.html#cb568-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb568-2"><a href="regression.html#cb568-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(linmodel_logchina, <span class="at">ask =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="DASE_files/figure-html/unnamed-chunk-82-2.png" width="672" /><img src="DASE_files/figure-html/unnamed-chunk-82-3.png" width="672" /></p>
<div class="sourceCode" id="cb569"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb569-1"><a href="regression.html#cb569-1" aria-hidden="true" tabindex="-1"></a>linmodel_logchina</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = logchina_effort ~ logchina_size)
## 
## Coefficients:
##   (Intercept)  logchina_size  
##         3.301          0.768</code></pre>
</div>
<div id="references" class="section level2" number="10.5">
<h2><span class="header-section-number">10.5</span> References</h2>
<ul>
<li>The New Statistics with R, Andy Hector, 2015</li>
<li>An Introduction to R, W.N. Venables and D.M. Smith and the R Development Core Team</li>
<li>Practical Data Science with R, Nina Zumel and John Mount</li>
<li>G. James et al, An Introduction to Statistical Learning with Applications in R, Springer, 2013</li>
</ul>

</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="supervised-classification.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="unsupervised-or-descriptive-modeling.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/danrodgar/dasedown/edit/master/417_regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["DASE.pdf", "DASE.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
